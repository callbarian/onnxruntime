[33m306c42c373[m[33m ([m[1;36mHEAD -> [m[1;32mMD.AI[m[33m, [m[1;31morigin/MD.AI[m[33m)[m Revert "minuscule"
[33m092cd184ba[m minuscule
[33m6e6782ba2c[m Merge tag 'v1.13.1' into MD.AI
[33m68d464f69a[m 1.Exhaustively searched Algo is cached after the first Run(), 2.Save cached algo through session->SaveOptimizedModel()
[33mb353e0b41d[m[33m ([m[1;33mtag: v1.13.1[m[33m)[m Bumping up version number. (#13403)
[33m95bd0e7d28[m rel 1.13.1 cherry pick round 2 (#13390)
[33m8042f724b8[m Cjian/rel 1.13.1 cherry pick round 1 (#13372)
[33mffca781909[m fix jetson build break caused by https://github.com/microsoft/onnxrunâ€¦ (#13343)
[33mf4b944e1ab[m increase timeout to 5 hours (#13226) (#13232)
[33m832a9b26a1[m Cjian/1.13 cherry pick round 2 (#13206)
[33mc0bb9d5e26[m Cherry Picking 13124 (#13132)
[33m43766ee36d[m Fix OLive build pipeline (#13114)
[33m94e34ace15[m Bugfix for SimplifiedLayerNormalization (#12975)
[33m237ccc01c7[m Remove one last nuphar reference (#13111)
[33mb25437ec41[m Upgrade  protobuf version (#13100)
[33m073dbba784[m skip the placeholder inputs while adding node inputs as sub-graph inputs (#13106)
[33mc746083344[m use parameter names to specify argument mapping (#13108)
[33me3bdba37a8[m Mitigate prefast static analysis warnings (#13032)
[33m77a066c700[m Drop nuphar from java API (#13107)
[33m0e98fb4e9b[m Fix Build Error for CUDA113 Introduced by 6efa9d9 (#13089)
[33mb62ba0b5a7[m Remove old enable_linux_gpu_tests parameter from template invocation. (#13102)
[33me9b1bbc6a5[m fix Numpy array None judgement bug (#13103)
[33ma83a9ed6b0[m Remove miscellaneous nuphar configs (#13070)
[33m44c14e8cbb[m Adding test case for conv per channel with QDQ format (#13041)
[33m2ae33b3613[m fix CuDNN lib path for Windows (#12974)
[33mce2ea44a56[m Try to fix GitHub labeling action (#12999)
[33m7116825aef[m Add CMAKE_CUDA_ARCHITECTURES list to python packaging pipeline (#13081)
[33made0d29174[m Updated Dockerfile.ubuntu_openvino with OV 2022.2 official release (#13069)
[33m365a01397d[m Bump protobuf from 3.17.0 to 3.18.3 in /tools/ci_build
[33mb820256f34[m Add check that bias and scale sizes match norm_size in LayerNormalization (#13060)
[33m19c51376c4[m Introduce QDQ transformer fusion tools for ordered quantized ops (#12661)
[33m6587a85f8f[m Bump protobuf from 3.18.1 to 3.18.3 in /tools/ci_build/github/linux/tvm
[33mc1ff4b468d[m Bump protobuf in /tools/ci_build/github/linux/docker/scripts/manylinux
[33m9abd6e3a30[m setup.py: use packaging instead of wheel.vendored.packaging (#13083)
[33m2cc4e7e5c2[m [Build] Fix broken AMD CI (#13082)
[33m63c3b21902[m Bump protobuf from 3.18.1 to 3.18.3 in /tools/ci_build/github/linux/docker/inference/x64/python/cpu/scripts (#13080)
[33m8e2528bad2[m More LayoutNormalization opset 17 changes (#13066)
[33m9e21ffb649[m Add license header to some files. (#13074)
[33mbcc93ab17c[m Deprecate ORTTrainer (#13022)
[33m6f27659ceb[m Fix prefast warnings (#13017)
[33m8bb16ab900[m Propagate environment variable to docker image (#13031)
[33m6efa9d9e10[m Add more qordered int8 operators for CUDA provider (#12949)
[33m5f611b63a1[m Make classes IKernelTypeStrResolver and IKernelLookup have protected destructors. (#13059)
[33m2ef1f8b93e[m [ROCm] add tunable SkipLayerNorm for ROCm EP (#12817)
[33meafd67b8fd[m Update CUDA version to 11.6 and refactor python packaging pipeline (#13002)
[33m92237567d3[m add opset17 node test data (#13062)
[33ma24b41d92e[m Move all TunableOp related falicilities to EP level directory (#12857)
[33m8fb3f05cd6[m Add cgmanifest file in codeowner list (#13042)
[33m394c249c7c[m Add ONNX LayerNormalization(17)  (#12978)
[33m952c99304a[m Add CANN EP (#12416)
[33m078ceab1db[m Use full ORT package for onnxruntime-react-native. (#13037)
[33mc4a7e88fc8[m QuantizeBFP and DequantizeBFP (#12833)
[33m057567f39f[m Fix bug in Attention Fusion (#13050)
[33mcccbe90764[m Openvino ep 2022.2 v4.2 (#13023)
[33m6ea8780886[m Replace std::exclusive_scan() with for loop because std::exclusive_scan() is not implemented in GCC 7. (#13045)
[33mc7a4093db8[m Fix prefast static analysis warning by not calling delete explicilty. (#13048)
[33m2f9b358d16[m Replace the source of TRT version and fix the build  (#13046)
[33m2f9b559391[m Declutter pull_request_template (#13026)
[33m851b0ce936[m [js/web][Fix] - updating the C API to catch non-tensor data (#12811)
[33m8de5535e9c[m Reduce test warning spew due to CPU fallback (#13035)
[33m051a0a67a5[m Cjian/per channels not working (#13038)
[33m6248b69795[m Fixes bug which makes quantized_input_names = [] (#13029)
[33m240aeadf1a[m Update engine hash id generator with model name/model content/metadata (#13015)
[33m39e20686a0[m [EP Perf Dashboard] Fix incorrect calls to trtexec with fp16 inputs (#13018)
[33m3810effe6e[m [NNAPI EP] Remove/Refactor shaper inference calculation code (#12618)
[33m8356e3b9b0[m Add onnx single node test data to tests (#12822)
[33ma5d70d8609[m Allow bert_perf_test.py make some noise by log_severity option (#13024)
[33me9d91cac55[m Fix hipify not running if the pwd is not the root of onnxruntime repo (#12941)
[33mb2b4f703a5[m Move Linux GPU CI pipeline to T4 (#12996)
[33mbee49dd112[m[33m ([m[1;31morigin/user/dwayner/ReduceWarningNoise[m[33m)[m Add limit input rank <= 4 in NNAPI EP Sigmoid op support checker (#13019)
[33m40749124b1[m Fix Deferred Release and Add New Test Framework for CUDA EP-specific Tests (#13016)
[33m4113df0e21[m use constexpr (#12953)
[33mdd39f0293d[m fix static analysis: integer_gemm and attention_quantization (#13004)
[33m454f77cd94[m Update kernel matching logic: decouple from op schemas and remove kernel def hashes (#12791)
[33m32878a1e58[m Fix log timestamps being off by one hour when DST is in effect. (#11385)
[33m1245c6397e[m Remove usage of torch.onnx symbolic_registry (#13011)
[33m189aef2bea[m [ADD] add skip layernorm to kernel explorer for ROCm EP (#12816)
[33mffeba98a9d[m Allow gemm profile by pass args from commandline (#12991)
[33mf26054deca[m [XNNPACK] Support running in multi-thread with seperate pthreadpool (#11762)
[33ma8b0f57d1a[m Fix eager mode pipeline to accommodate recent allocator change. (#13000)
[33m0ddf4efbd9[m Make PythonOp report dtype mismatch by name, instead of by using enum index (#13007)
[33m77b567df66[m test qdq loss presence (#12928)
[33m3cd2d4a7a1[m Merge pull request #13013 from microsoft/prathikrao/setuptools-version-bug-fix
[33m8ea742b507[m downgrade setuptools
[33m14eb3cf485[m Ignore settings.json in git (#12988)
[33m14365b67a0[m Fix hipify due to CUDA EP tensorrt_fused_multihead_attention optimization (#12990)
[33me02bea2e3f[m Fix some warnings (#12918)
[33m4ed5a5b2a8[m[33m ([m[1;31morigin/vgg16_ort_fp16_fail[m[33m)[m Disable local versions based on environment variable (#12997)
[33mb48f71fcfc[m fix bug: quantization shape inference (#12983)
[33m1a684152cc[m Fix C6011: dereferencing NULL pointer with_data (and external_data) (#12982)
[33m12aab3c01d[m Fix TSA warnings (#12950)
[33m268bfe2a5d[m python training api bindings (#12610)
[33m2b5b11d373[m [C#][TVM EP] Fix issues related to using TVM EP in C# front-end (#12958)
[33m85546255c4[m make nhwc transformer only apply to CPU ep.  (#11882)
[33mab45ac311f[m Merge pull request #12980 from microsoft/WindowsAI
[33mb935524e22[m Revert reverse setup of allocators + create/register allocator in CPU EP only when needed. (#12954)
[33m94d9e9ad6d[m [Issue labeler] Separate out C# api as separate label (#12951)
[33m709254949a[m DML EP temporarily fall back to CPU for LayerNorm when Bias is not present (#12987)
[33m3c427a8946[m Fix an arithmetic overflow warning (#12961)
[33m739b5675c8[m remove legacy compile api (#12932)
[33m203f63c224[m Publish WinML Nuget package to ORT-Nightly ADO feed (#12904)
[33m9f6646f11d[m Merge branch 'master' into WindowsAI
[33m363c695dad[m Update DML 1.9.0 to 1.9.1 (#12966)
[33m08af88e3e2[m Assign generate document job to CPU pool. (#12973)
[33m647e09cc39[m [FIX] skip layer norm for ROCm EP (#12803)
[33md2aa2109c0[m Make TunableOp follow stream semantics (#12856)
[33m248f72e972[m fix VC++ Static Code Analysis warnings (#12940)
[33m10f9a69707[m Use CMake EXCLUDE_FROM_ALL for composable kernels to avoid building of conv related kernels (#12855)
[33md819b56fba[m Consume ONNX 1.12.1 to prevent vulnerability issue while loading external file (#12915)
[33m3f456a1847[m [Update] update rocm5.2.3 (#12942)
[33m5099dda42f[m Lint updates csharp docs (#12962)
[33mbc2df1bf95[m Remove previously deprecated API (#12935)
[33m1ef1029163[m Skip 2 tests in windows gpu workflow (#12956)
[33mb8e34fbd91[m Split topk implementation into per-type translation units to speed up compilation (#12861)
[33mda07c83948[m SoftmaxCrossEntropyLossInternalGrad and Sum Fusion (#12746)
[33m568950e28c[m Warn on node EP silent fallback from preferred provider (#10831)
[33m78bc53f91d[m fix prefast:Warning C26814 in non_max_suppression.cc (#12934)
[33mbb98922cc8[m Delete nuphar docker file (#12944)
[33m95c4fc6877[m [CUDA] Add TensorRT fused attention fp16 v2 kernels (#12814)
[33m1016c33519[m Fix prefast warning in upsample.cc. (#12938)
[33m626d94aa23[m Refactor python packaging pipeline and nuget packaging pipeline (#12945)
[33m9edc9465f0[m Fix some prefast warnings (#12936)
[33m64466c2d62[m Remove nuphar provider folder (#12939)
[33m28e27ee7f7[m Changes for AIX compilation to get CPU of running thread. hz is interâ€¦ (#12744)
[33m31a1403e06[m Add --output_dir option to convert_onnx_models_to_ort.py. (#12844)
[33ma433f22f17[m Softmax interface update (#12469)
[33m30ebc9e00a[m Useless Cast removal after converting model from float32 to float16 (#12871)
[33md8636c2be8[m Add enable_onnx_tests in windows nuget test step (#12926)
[33mf78ed1388a[m Fixed build break: inbox version of WindowsAI repo
[33mbcdddb47ba[m Merge remote-tracking branch 'origin/main' into WindowsAI
[33m5e978f351c[m [DML EP] LayerNorm Kernel (#12809)
[33m1e34440c37[m Fix ORT crash when loading BeamSearch model (#12872)
[33m022d9e2d0c[m Get files for XNNPACK wasm build from BUILD.bazel. (#12892)
[33me561a7cf29[m Adding QuantConfig Class (#12810)
[33m8e4eb24648[m Update operator kernel table to include DML operators (#12887)
[33m05c65a54b3[m [DML EP] Contrib Op: FusedMatMul (#12898)
[33m0b235b2763[m Disable QOrderedMatMul with bias tests on Windows (#12901)
[33mb5327595f3[m Fix [prefast:Warning]: C26814 (#12897)
[33m5d55b0730e[m [Java] JNI refactor for OrtJniUtil (#12516)
[33m60e4d012e0[m Fix unused variable warning from reduced ops build (#12889)
[33m28f2e57de5[m Use CUDA callback to release deferred-release buffers (#12883)
[33m55c745eefd[m Add support for ORTModule Torch cpp CUDA extension build within docker (#12868)
[33m6ebb7b91eb[m Re-apply fix for mkl issue for eager mode (#12881)
[33mff52d6a6bf[m Delete Dockerfile.ubuntu (#12888)
[33ma811c7629f[m Remove "Build Python Documentation" from py-packaging-stage.yml  (#12890)
[33mb1984278d9[m Enable blank issues (#12885)
[33m4765e5c382[m Using ORTModule to wrap a evaluation model should not change the mode (#12747)
[33md3b684cd9e[m Drop nuphar (#11555)
[33macc8bdc6c5[m Splitting quantize_tensor and quantize_input (#12873)
[33m535b0835f2[m User/sheilk/dft fixes (#12862)
[33mf63bd0765d[m New GitHub templates (#12777)
[33mad69aac491[m Introduce ordered quantization ops for the CUDA EP [1/n] (#12582)
[33m69f7cc6494[m Add pybind support for all memory config options in OrtArenaCfg (#12658)
[33m8004db4bf1[m fix python import sequence warning (#12864)
[33m400195a10a[m raise an exception when TreeEnsemble request a feature out of boundaries (#12859)
[33mf856be162e[m fix xnnpack wasm build (#12845)
[33m437409c343[m Add DONT_VECTORIZE flag to cmake (#12169)
[33m706e03c63d[m Add azp run helper (#12832)
[33mc571b99336[m Refactor setup_test_data (#12818)
[33m726251609a[m increase max memory to 4G for wasm (#12798)
[33md19955fd89[m fix transformers script issues (#12802)
[33m54360c88d2[m Disable two warnings raised by tensorboard on Visual Studio (#12773)
[33m9ad5b95e4f[m Fix math domain error with log10 (#12841)
[33m8cedafe250[m [xnnpack] Have `Initializer` in Mobile related EPs in Minimal_build and creating EP specific dynamic-schema (#12555)
[33mac4f1bf960[m Update max opset for NNAPI and CoreML.  (#12831)
[33m9e47eb68e0[m Remove unused orttraining amd dockerfiles and scripts (#12707)
[33m76d17b0f48[m Add java API for xnnpack (#12788)
[33m295bd26980[m Remove orttraining-distributed CI pipeline (#12738)
[33m27dde0b51f[m Csharp bindings for on-device training APIs (#12404)
[33m2fe919c3ad[m Adding Split Fusion (#12732)
[33m56bae3b196[m[33m ([m[1;31morigin/alejandro/quant_tool[m[33m)[m Use InplaceClipGradNorm for offline processing for on-device training (#12603)
[33m98b2b7f5bb[m Update csharp documentation (#12830)
[33m548938fb97[m Update stale.yml (#12813)
[33mca5af24765[m Update Sdl.ruleset to remove C26812 from the rules (#12695)
[33m931c8b0147[m Resolve GH issue 12706 (#12815)
[33m6fe712b587[m Create codeql.yml to replace LGTM (#12790)
[33m349469c381[m Enable way to extract all parameters to and from a contiguous buffer. (#12674)
[33m52ce6a90b4[m Props file cleanup (#12782)
[33m0125e15281[m Fix include order build failure training build (#12425)
[33me3b501125d[m DFT on DirectML (#12710)
[33m5dd9afe75a[m python lint (#12825)
[33madbc0757ad[m [UPDATE] update ROCm ci pipeline to ROCm5.2.3 (#12799)
[33m262a597e2a[m [CUDA] BiasSoftmax and Dropout Fusion (#12667)
[33m7e1e0f5c9e[m fix build error for generation debug code (#12801)
[33ma48b115540[m Remove reference to the deprecated variable in `torch.onnx.symbolic_helper` (#12452)
[33mf59a44e24f[m Build VS 2022 no Abseil adjustment (#12780)
[33mcc94ba7740[m Update C# API docs workflow  (#12796)
[33m6b148e15e1[m Disable QGEMM, s8 A, s8 B (Packed) bench for AMD64 (#12765)
[33ma52543ecd8[m Generate windows training package (#12789)
[33m82a28cc2c3[m upgrade emsdk to 3.1.19 (#12690)
[33m1a402a3f25[m replace 'master' branch ref to 'main' for onnx repo (#12678)
[33m9aefcc251f[m fix some prefast warnings (#12730)
[33m9680ffd842[m Fix rocm build caused by #12699 (#12787)
[33mb4f6dad7c9[m increase timeout limit of mac silicon package workflow (#12784)
[33m9907b59a1e[m Change cuda and rocm error checking helpers to return Status (#12699)
[33ma0c25e5c2f[m Fix segment fault for alltoall (#12701)
[33m19ca2a0089[m [ADD] python package pipeline for ROCm5.2.3  (#12770)
[33md761a7ceb3[m Pre-processing of Quantization (#12729)
[33m1ce14e752b[m Increase timeout for clean-build-docker-image-cache-pipeline. (#12776)
[33m17ccd6fa02[m Fix shape-related issues in FuseConv (#12410)
[33m233f8c210e[m Handle initializers in subgraphs when inlining (#12758)
[33m4f244e48d5[m fix CalculateHash for Big Endian platforms. (#12752)
[33mb83ea3c2ff[m Address prefast static analysis warnings (#12756)
[33m27304d9082[m gcc should not less than 7 (#12771)
[33m3e57cd88fc[m Csharp docfx update (#12755)
[33m80c8d934b8[m Add debug option to packaging pipeline (#12685)
[33m817dc94345[m Add first pass of rocm kernel profiler (#10911)
[33mee543a47f6[m upgrade cuda version on ci pipelines (training CI pipelines) (#12708)
[33m64e8806148[m Address some static analysis warnings.
[33mc270ea148a[m Move 'using common::Status;' from common.h to status.h.
[33m3ff75fa05f[m Address static analysis warnings (#12711)
[33m34d90dd5bd[m mac-objc-static-analysis-ci-pipeline increase timeout (#12737)
[33mc9fd193ef6[m Make TRT EP fully support control flow op and its subgraphs (#12692)
[33ma972db06bf[m Disable SYMMQGEMM benchmark for CPU other than ARM (#12739)
[33m5bdb1d4146[m Add Tunable GEMM composed from rocblas and composable kernels (#12599)
[33m46c074a6c8[m Update composable kernel and enable experimental inter wave scheduling (#12626)
[33m3bb5fb0f90[m moving training pipelines from cuda 11.5 to 11.6 and deprecating 11.3 (packaging pipeline) (#12688)
[33mf76b40aa5b[m Change TunableOp to use a type erased interface (#12597)
[33mbaf141a084[m Enable xnnpack EP in Android AAR package (#12720)
[33m8483b9c6e3[m MacOS pipeline and MAUI CoreML fixes (#12724)
[33mebff15d743[m Pinning manual seed (#12714)
[33me85dce8cea[m Add csharp docfx (#12596)
[33m5104c7dbd3[m Fix Prefast Warnings (#12717)
[33m5be3e87c71[m [js] upgrade minimist@1.2.6 (#12689)
[33mcde504ebbf[m Fix/Suppress some VC static analyzer warnings (#12713)
[33mdee2fdffb0[m Remove debug build/test in Mac CPU training (#12698)
[33md91f017da1[m remove redundant publish unit test results (#12697)
[33meba4f77d00[m enable xnnpack in default_full_aar_build_settings (#12682)
[33mf1528ea50f[m Fix arithmetic overflow warning. (#12712)
[33m7927d525a7[m Remove CUDNN path from CI build scripts (#12671)
[33m3f47119f33[m DML EP Fix InstanceNormalization with 3D tensors (#12693)
[33m94f76b944e[m nightly pipeline build using PTCA image. (#12605)
[33m0757d51334[m Fix Java api docs broken link (#12686)
[33m53ecb9e635[m Update Supporting DS Version to 0.7.1 for ORTModule (#12696)
[33mde3d772995[m Check GCC version (#12680)
[33m8d657de4b2[m Update Newtonsoft.Json version to 13.0.1. (#12691)
[33m73e5741a9a[m Enabling softmax grad and logsoftmax grad on ORT (#12614)
[33mcb2601c5ea[m Update mac-ci.yml to increase macOS build jobs' timeout value to 3 hours (#12675)
[33m8d78f96dfe[m [CUDA] Fuse add bias and transpose into one kernel in Attention (#12670)
[33m6246662b1d[m [Dup] Fix SAME_UPPER/SAME_LOWER (auto_pad attribute) in ConvTranspose (#12537)
[33mc144acc534[m Replace 'master' branch ref to 'main' in the code (#12547)
[33md93e6533b7[m Format bert or transformers code (#12646)
[33mdc486d146b[m Make ORT callable from various Pytorch compilers (LazyTensor, TorchDynamo, etc) (#10460)
[33m53090f620e[m Fix attribute renaming bug in function inliner (#12445)
[33ma078c8d99b[m Update Supporting Deepspeed Version of ORTModule's FP16_Optimizer (#12668)
[33m8456f5fd97[m qdq_util bug fix (#12647)
[33m2102b8f67c[m Avoid duplicate symbol error between ONNX and ORT for ostream operator<< with TensorShapeProto  (#12651)
[33mf40e90c33f[m [js/web] fix incorrect shader for 'Resize' (#12588)
[33mbfdd191eec[m [wasm] use same export name for SIMD/NOSIMD build (#12545)
[33maa85092b51[m DML EP squeeze all axes when empty (#12649)
[33mb270334e1e[m Update numpy version from 1.21.0 to 1.21.6 to avoid building it from source (#12644)
[33m56dd0176a1[m QDQ debugger - Adding Error Calculator (#12632)
[33m81b128b5e9[m Qlinearsoftmax take FLOAT lookup-table (#12574)
[33m82b724fa5e[m [oneDNN] Improve DequantizeLinear operator performance. (#12611)
[33md1ba801570[m Add BuildError for --gen_doc and --enable_training (#12630)
[33m9481893b58[m Replace to lock_guard as lighter class for locking (#12616)
[33mf2db6bb293[m weight matching (#12607)
[33m8a038b9b0c[m Fix a build error (#12600)
[33mce01ed02da[m Improve LongformerAttention performance: AddBiasTranspose and New weight format (#12448)
[33m7df2e8c5cc[m Refactor with std::variant (on device training) (#12383)
[33mcaabfcd920[m Replace references to onnxruntime 'master' with 'main' in Dockerfiles. (#12550)
[33m9d10badc55[m Add build option to link TensorRT prebuilt parser (#12602)
[33m733db31420[m [Java] JNI refactor for OrtSession (#12496)
[33meb6aa861cf[m QDQ debugger - activations compare (#12544)
[33m30ee5a4f79[m release calibrator before deleting temporary files (#12601)
[33m19a9690885[m ppc64le: fix MlasQLinearMulKernel's VSX code to work with inputs of 32 bits (#12441)
[33m616677104a[m ONNX Protobuf natvis with some google::protobuf (#12580)
[33mf5e3517c39[m Add Learning Rate Scheduler C API (#11957)
[33m73da3f3705[m Add TRT uint8 support (#12570)
[33m95f2a3e7e0[m[33m ([m[1;31morigin/vNext[m[33m)[m [js/web] update branch name for pull:wasm (#12548)
[33mcc9b3e1c37[m[33m ([m[1;31morigin/leca/undoCommit[m[33m)[m Automate generation of javadocs and create PR with changes (#12515)
[33m0b0c51e028[m Support direct usage of ORT format model flatbuffer for initializers (#12465)
[33mbc353c7afe[m Add FusedConv Op to ROCm (#11792)
[33meb827bd3e5[m [ROCm] NGramRepeatBlock, LongformerAttention and DecoderAttention Ops (#11971)
[33m95df5dac51[m do not quantize Relu/Clip if their inputs are not quantized (#12565)
[33m67f6b7ce29[m DirectML GEMM broken in opset 11 and 13 when optional tensor C not provided (#12568)
[33m580f2294bc[m Adding w_zero_point to conv_integer_test.cc (#12423)
[33m3d009cdde3[m Updating binary ops in eager mode to support broadcasting. (#12560)
[33m24eab921be[m Enable PythonOp for --enable_training_torch_interop build (#12539)
[33mb59ccbc75b[m Add big endian support to murmurhash3 (#12549)
[33m018fba9b74[m Fix Compile Warning (#12552)
[33mac7538b909[m Remove CUDA 10.2 support (#12541)
[33m819c36701f[m [xnnpack]  basic QDQ operators support (#11912)
[33m3e78f3cf1f[m Add win-ci pipeline for on-device training (#12513)
[33mb2382dc43a[m fix qdq relu removal bug (#12542)
[33mc10704a501[m Use alignas instead of naive padding to avoid false cache sharing (#12514)
[33m25032f1756[m Add default to TRT datatype switch statement (#12533)
[33mc0d396d176[m Restrict "Component Detection" task to Lotus project only (#12536)
[33me810480403[m Replace the occurrences of  "master" to "main" in yaml files (#12534)
[33m64e991a9fc[m [Qlinearsoftmax] contrib cpu (#12177)
[33m0c6037b5ab[m Bugfix for BiasSoftmax Fusion (#12517)
[33m0d9a02e647[m Eager Mode - Support Concatenation via aten::cat.out (#12527)
[33m47b787c28f[m Python module for dumping activation tensors when running an ONNX model (#12474)
[33m2681648f5b[m Load checkpoint in cpp (#12352)
[33mee3b757492[m Add codeowners for requirement files (#12512)
[33m2bed0d4abb[m [CUDA] SoftmaxCrossEntropy Kernels Refactor (#12482)
[33mcfa09d16d9[m [CUDA] Mod Op Kernel (#12499)
[33ma2dc3e9eac[m Improve the compilation speed when compiling for multiple architectures. (#12490)
[33m56bd96a3f5[m Incrementally free initializers while saving to OrtValue instances (#12485)
[33m730240d2a5[m remove the link the comments (#12510)
[33m8a86b346a5[m [Java] JNI refactor for ONNX Tensor (#12281)
[33m8c5c283471[m new quantized operators split (#12495)
[33m9c05577021[m Fix various warning in kernel explorer (#12501)
[33mbdd6b00c9a[m set zero point to 0 if all value are 0.0 (#12470)
[33mddea1e48df[m Avoid false-positive dependent name lookup error by not depending on auto keyword (#12483)
[33meb90b52a75[m DML EP fix training build error (#12461)
[33me85e31ee80[m Update ORTModule Default Opset Version to 15 (#12419)
[33ma7d6290774[m CUDA kernel for ClipGradNorm for TensorSeq gradients (#12412)
[33m3e1b0ac4b3[m [DELETE] delete python package rocm4.3.1 (#12480)
[33mb879dca51c[m Fix Python Packaging CI (Rocm) (#12477)
[33m8d830adf24[m Rework parts of Graph::Resolve to reduce memory usage (#12176)
[33mf39354d7cb[m Add composable kernel GEMM baseline for kernel explorer (#12364)
[33m37995a7245[m [CUDA] BiasSoftmax Supporting New Pattern (#12361)
[33md452462b5e[m Lironkesem/unsqueeze_and_squeeze (#12421)
[33ma4ef0e7f7b[m Remove dynamic allocation for ThreadPool ParallelSection (#12429)
[33mac10f33d2d[m Enable quant op to share quantization parameter between input and ouput (#12408)
[33m52d4699788[m Minor doc fixes (#12388)
[33m3efd9a73bb[m Refactor InferenceSession Load member functions. (#12430)
[33m97268e023c[m[33m ([m[1;31morigin/FirstBranch[m[33m)[m dev notes for layout transformer (#12396)
[33ma3de1bbf7d[m Update script to find optimizers that potentially need supported opset updates (#12330)
[33m77cab7a3a5[m [ROCm] Add AveragePool, GlobalAveragePool, MaxPool, GlobalMaxPool Ops (#11968)
[33md1497bdf62[m [oneDNN EP] Optimized DynamicQuantizeLinear operator (#12403)
[33m7f58bd7236[m Perform graph transformations during offline tooling (#12422)
[33mdc984a03d5[m Container and memory allocation guidelines (#12387)
[33m97a340bf48[m Fix integer overflow in LongformerAttention (#12435)
[33m44ec2cf088[m Update publish-python-apidocs.yml (#12433)
[33mb622e5fa9b[m Support vocab_mask/prefix_vocab_mask/no_repeat_number in greedysearch op (#12327)
[33m70481649e3[m[33m ([m[1;33mtag: v1.12.1[m[33m, [m[1;31morigin/rel-1.12.1[m[33m)[m Cherry picks for 1.12.1 (#12418)
[33m01f3a197d7[m [ROCm] InstanceNormalization, BatchNormalization and LRN Ops (#11972)
[33m99d2a63e1a[m Set Fix Seed For SoftmaxCrossEntoryLoss Related UTs (#12432)
[33m26dc09417b[m [oneDNN ep] matmulinteger postop fusion (#12354)
[33m5d610bc8eb[m Disable CG task in PR pipelines (#12426)
[33mfeed5da435[m [js] loosen test timeout (#12427)
[33m54d5e86981[m Add cast before copy for dissimilar scalar type (#12391)
[33mc9e0d0f8b6[m [js/node] upgrade terser version (#12351)
[33m1a64b94f60[m Fix a small issue in nuget packaging pipeline (#12405)
[33meebaf5f270[m Adjust and fixx abseil-cpp debugging visualization (#12415)
[33mca6b4221fe[m [js] Bug fix - permission issue with ensureSymlinkSync (#12369)
[33mb39257a5e6[m Enable support of multi-level nested control flow ops model for TRT EP (#12147)
[33mde3a91d85d[m Revert TRT EP cache refactoring  (#12376)
[33m5d1173fe68[m Run IOS pipeline concurrently (#12400)
[33m63d64636f6[m Add the comment linking to wiki (#12398)
[33m315e006532[m  adding a comment on nll_loss_forward.output that can not be implemented (#12406)
[33mdd8e2922ca[m update version to 1.12.1
[33m62922f4c3c[m Eager Mode generator: add comments, rename functions (#12385)
[33mf77ab4fea6[m Manually add optimization flag for Android Release builds. (#12390)
[33m6bb807ef74[m add cuda compute 8.7 to Cmakelists.txt to support Nvidia Orin devices (#12377)
[33m3f66297499[m code clean (#12392)
[33m1a4868e5c4[m [TVM EP] Hot fix of build on Windows of TVM EP with ipp-crypto (#12381)
[33m8b4ad77ea2[m pipeline can use last run's artifacts (#12379)
[33m6d1eb9509e[m Refine gradient accumulation (on device training) (#12363)
[33m7b4ce0c1e1[m Delete the build scripts that were copied from manylinux project (#12358)
[33md5a1c01b38[m Add C++ Session ctor taking model bytes and OrtPrepackedWeightsContainer (#12333)
[33mdf8dd41a8e[m Automatically run workflows to generate API docs PRs (#11749)
[33m9559d25da9[m ORT Eager Mode Generator - make smaller functions (#12371)
[33mf1a04078e9[m Update CODEOWNERS to add a line for yaml files (#12378)
[33mc579497134[m Fix TRT custom op issue (#12283)
[33m6514069749[m Make memory profiler work with multiple session runs. (#12317)
[33me4bd41fb3b[m [ROCm] Enable Einsum for inferencing perf (#12360)
[33m9c0fa65110[m Scope CreateFileMapping2 to valid API partitions (#12374)
[33m0e85af6990[m Add MAUI csharp\sample\InferenceSample\ project (#12356)
[33m805aa297fc[m Remove preview keyword from DirectML pacakge (#12368)
[33m7a7e372b9f[m Remove training cuda 10.2 pipeline (#12347)
[33m6e892a95b4[m Use specific Android NDK version in CI builds. (#12350)
[33m73919a6756[m Convert DQ node with const weight tensor int8 to uint8 (#12331)
[33me2423bb55c[m [TVM EP] Build on Windows with ipp-crypto support (#12336)
[33m7a298c916a[m Add Pow-15 for LayerNorm Fusion and FastGelu Fusion (#12314)
[33m186ba6e9f2[m [js/rn] upgrade package react-native@^0.69.1 (#12155)
[33me6bb447101[m Change native folder name for java macos arm64 (#12335)
[33m148b1efe5e[m [js/web] add ConvTranspose2D to WebGL backend (#11990)
[33md2b25a7c1c[m Reduce CI noise from Python lint (#12270)
[33m9cf6912bba[m Fix ORT Eager Mode to work with Pytorch 1.12 (#12323)
[33me2eeffeafb[m Cosmetic fix to AttentionFusion (#12329)
[33m1163294699[m Fixing up some python warnings. (#12319)
[33m1dd65b9ae3[m Use memory mapped data for external data initializers with Cuda fix (#11789)
[33m4df4471d5e[m add missing build_java in Android testing stage. (#12187)
[33m2b2367efbf[m Fix orttraining-linux-gpu-ci-pipeline (fairscale dependency) (#12320)
[33m51a799802a[m Move initializers from subgraph to the main graph to reduce memory (#12310)
[33mf3dcbf539a[m Checkpoint load inference (#12168)
[33mde57daaab0[m Eager mode: binary ops more complete behavior and testing. (#12293)
[33m3e014a5e5d[m Fix C header to stop people accidentally copying the OrtApi by value (#12297)
[33mc40f73ae0c[m Remove aten::binary_cross_entropy_with_logits from ATen Fallback (#12301)
[33m3bf614fd47[m Eliminate memory allocations per recent profiling (#12225)
[33m972bb9676c[m Bump terser from 5.7.0 to 5.14.2 in /js/common (#12248)
[33mddb45e9126[m On device training CI pipeline (#11987)
[33m8d0e86dec8[m[33m ([m[1;31morigin/users/msftlincoln/orteager/empty[m[33m)[m Apply project formatting rules to ort_aten.cpp (#12294)
[33m0fa3aeb65c[m [CUDA] Add Strided Tensor Support for Expand->GatherElements for Training (#11976)
[33m75bda9f267[m CPU AdamW implementation (#11978)
[33m564dc32304[m Initialize generated tensor data in onnxruntime_perf_test. (#12275)
[33m89ac61f4d4[m support gpt2 model with greedy search (#12068)
[33mcb351388d0[m Minor fixes (#12276)
[33m0264a9c29b[m Bump ort version number (#11948)
[33ma71f7d3339[m [NNAPI EP] Add some support for MatMul with batch inputs (#12261)
[33m4f57da78cf[m OrtModule fix pytorch version comparison (#12280)
[33mfeabafe58b[m Fix memory consumption discrepancy (#12266)
[33mf2533d3084[m Remove two lines in the Dockerfile for Github Codespace (#12278)
[33mceb76429db[m Merge pull request #12056 from microsoft/bmeswani/merge-training_dev/on_device_poc
[33m7194ec1894[m fix bug: output of Concat is quantized twice in qdq format (#12254)
[33ma18b080513[m clean up calibration model (#12255)
[33m45c0be8a25[m Modify generator for eager to use all inputs for determining promote type. (#12268)
[33m30ac6e87fa[m Bump terser from 5.10.0 to 5.14.2 in /js/web (#12253)
[33meb3b49b6a1[m [CoreML EP] Remove batch=1 restriction in depthtospace op support (#12258)
[33m108b860dc1[m Add dev container / codespace configuration (#12256)
[33m03dfcb0e87[m [ROCm] Enable int8 for MatMulInteger Op (#11776)
[33mcbf08c7a7b[m Make GetTrainingApi as a part of the OrtApis, add Training API documentation and address other pull request review comments
[33m3d2bcb3386[m Use unregister_custom_op_symbolic to unregister torch symbolics (#12146)
[33m496618594f[m Update supported ops md for NNAPI/CoreML EP (#12245)
[33m7dc45bc311[m Implementing aten::gt.Scalar_out and aten::lt.Scalar_out (#12181)
[33m007ef42749[m Fix: Test coverage is undercounting and profiling errors (#12260)
[33m5066ef1185[m Fix a bug in beam search custom attention mask allocation (#12240)
[33m0c78b71352[m prepare test folder from GitHub (#12220)
[33mf466364176[m[33m ([m[1;33mtag: v1.12.0[m[33m, [m[1;31morigin/rel-1.12.0[m[33m)[m add release note url (#12259)
[33m568d08994f[m fix test_optimizer.py (#12219)
[33mc72bb8aaa9[m [js/web] add OffscreenCanvas support to WebGL backend (#12159)
[33m471dbfc250[m [NNAPI] Add int32_t as supported input data type and other minor gather op updates (#12171)
[33m5651d91c32[m Fix onnx version comparison (#12223)
[33m43e1e89453[m Update aarch64 building pool to aiinfra-linux-ARM64-CPU-2019 (#12243)
[33m424120d0fa[m cpplint & Eager mode: refactor and add comments to empty_* functions, general lint cleanup in ort_aten (#12238)
[33m72c689a502[m [CUDA] Use dim3.z to Handle Large Input For GatherGrad (#12250)
[33mebfd81e67e[m Fix BiasGeluGrad bug (#12200)
[33m3cdc6d7775[m [ORTModule] Bugfix of torch.chunk's Custom Symbolic when chunks==1 (#12249)
[33ma0074ba9bc[m Add baseline gemm for kernel explorer (#12050)
[33madd631410a[m [ROCm] Re-enable ReduceL1, L2 and related tests (#12209)
[33m9b6ef17c5f[m Eager opgen support for in-place operations with variadic args (#12125)
[33m5e2109f7ef[m [ROCm] Enable GridSample Op. (#11969)
[33m4f106d2b3b[m Eliminate unnecessary status lock acquisition in TP (#12196)
[33m972e5e7300[m Improve symbolic shape inference in transformers tools (#12217)
[33m975bb56e8c[m Eager mode - argmax_out: set output tensor (#12233)
[33m555e88982f[m Fix GH issue 12208 (#12224)
[33m2cb642927b[m Simplify get_docker_image.py  (#12166)
[33m0c319d6e94[m Exclude implicit inputs from dump of encoder feeds in beam search (#12222)
[33m0d4f0f8ad2[m Cherry for release 1.12.0 final (#12218)
[33m66978c7ef5[m [TVM EP][CI] Added TVMso EP testing into CI (#12188)
[33m4235ebc161[m Add eager mode support for mm.out (matrix multiplication). (#12214)
[33mbb5bd08545[m [ROCM] Navi21 fixes pr (#11368)
[33m173bcdbc71[m [CUDA] Split/Concat Kernel Optimization (#12175)
[33mced7c2deac[m [js/web] use windowed Chrome for perf mode (#12157)
[33mb81b652608[m Add --disable_shape_inference option to optimizer.py (#12215)
[33m93229949d4[m Fix bug where onnxruntime_USE_NCCL flag would default to ON (#12195)
[33m17b84c78f7[m remove identity in transformers model graph fusion (#12194)
[33m4d38b84e26[m Add file mapping for windows platform. (#12183)
[33m09af4a7fdd[m remove wrong placed libs (#12201)
[33md31db1aa57[m [TVM EP][CI] Integrate TVM EP into ORT public CI on Windows (#12161)
[33m52095fb042[m Fix line spacing/break issue, extend existing tests (#12191)
[33ma2dc6d32fc[m OnnxRuntime Eager: Implement log_softmax with ONNX Ops (#12190)
[33m9bca8405aa[m bitwise_and ONNX support (#12189)
[33m89bf6c9b5d[m Simple eager training models (#12180)
[33mfafb24142f[m add comment to explain local scalar dense (#12179)
[33m05c31a036d[m fixing positions for beam search gpt2 (#12156)
[33m9ebef91a6f[m Update eager Readme.md (#12170)
[33m7b53b223b8[m [UPDATE] update AMD CI pipeline to Rocm5.2 with torch1.11 (#12162)
[33ma7eb9fe3ac[m Remove Apex Dependency For Deepspeed FP16_Optimizer (#12077)
[33m5da1e5d36d[m Eager mode: Fix some python warnings. (#12167)
[33m51f8456c4d[m ppc64le: Optimizing the MlasQLinearMulKernel() to use VSX instructions (#12051)
[33m040c2f4517[m x86/64 U8S8 Gemm Precision Fix (#12088)
[33m48647bc7d7[m Fix NonZero eager impl. (#12143)
[33m3b0aaa9e0e[m [TVM EP] support build on Windows (#11851)
[33m75cf5dc2c9[m Fix GH issue 12151 by using inverse perms for updating DQ axis attribute (#12158)
[33m785f74979b[m Rework cmake for kernel_explorer (#12079)
[33m5579d81fc8[m [add] Add operator gemmfastgelu for ROCM (#12101)
[33ma9d0d3323e[m Use updated symbolic_helper.check_training_mode (#11900)
[33m178a413ca1[m List 3.10 as supported python version and remove 3.6 (#12141)
[33me0ed9f0f2f[m [java] First part of the JNI error handling rewrite (#12013)
[33ma6fd1a3b85[m Eager mode generator improvements for multiple onnx operators and extra test cases (#12111)
[33m6e051016c1[m Add Python package to perf test pipeline. (#12135)
[33m9647a3be40[m Add tests for all unary aten ops supported in eager mode (#12087)
[33m73310b2a0f[m Fix Reduced Ops build pipeline (#12144)
[33mc675c4750a[m include coreml_provider_factory.h in macos build instead of coreml_exâ€¦ (#12138)
[33m742f843efc[m RoiAlign CPU EP add warning for max mode with samples != 1 (#12136)
[33mf1047e0456[m Fix minor python and cpp  warnings from previous PR. (#12140)
[33m99a370dd02[m Update readme for OVEP  (#12122)
[33m418cfdc766[m Update create_ort_attribute to set the tensor dimension and value correctly. Implement eager fill_ (#12018)
[33m1c39d22f4e[m [ADD]  Rocm5.2 for Rocm python packaging pipeline (#12129)
[33mc6732c079b[m pin protobuf version to be compatible with onnx (#12132)
[33md45c1a144e[m [js/rn] Support UINT8 type for onnxruntime-react-native on Android (#12112)
[33mc04afae9a9[m Add eager ops for unary ops with out. (#12106)
[33m2dd69cc3d9[m Prevent unbounded growth of command allocator memory (#12114)
[33m3ce25db7eb[m [js/rn] optimize exception message on Android (#12113)
[33mb50239251d[m [FIX] Add required variable for Rocm packaging ci pileine  (#12118)
[33ma9b9c7f69f[m Add autotuning support to FastGelu (#12093)
[33mdbcf54aa41[m Add hipified SkipLayerNorm code for ROCmEP (#12107)
[33m62226d030f[m Cherry-pick tagged commits to 1.12.0 release candidate (#12097)
[33m97b03fedff[m[33m ([m[1;31morigin/user/linneamay/ri-7-6[m[33m)[m check consumers of dq node before swap dq and transpose (#12099)
[33m446f899fed[m [ROCm] Temp disable AMD UT (#12105)
[33mbd76e21fb3[m Add pipeline for building perf test binaries. (#12067)
[33m1948b7c726[m Add eager support for eq and ne ops. (#12031)
[33m07b0469a23[m Fix unused function warning for decodeMIDR(). (#12069)
[33m835ecb264d[m Leverage vectorized load/write for SkipLayerNorm  (#11803)
[33m7b8f45dd60[m [ROCm] Enable build option for autograd (#11945)
[33m32a8751dc4[m DML EP Update to DML 1.9 (#12090)
[33m3446a3750c[m generate quantization parameter for outputs (#12089)
[33m3d53ce5e7b[m Remove ROCM macro for InPlaceAccumulatorV2 test
[33m1aa27e127c[m Resolve build conflicts with master
[33m479e71a7a8[m[33m ([m[1;31morigin/rashuai/test[m[33m)[m enable the extensions custom build for java and android (#11823)
[33mc20cbf0c97[m Add undocumented attribute to disable generation of Java bindings from the Android AAR. (#12075)
[33mddb6202df7[m Add op tuning functionality and an example for vector add. (#12060)
[33mdf712d80ca[m Add data type check in ConvAddRelu fusion (#12058)
[33m57ac3d0a61[m Disable DML command list reuse for Xbox (#12063)
[33m4a335e979f[m Add kernel def hash for inplaceaccumulatorv2
[33mae88f43550[m Eager mode: structure for supporting out= operators (#12066)
[33m8dc8d44087[m remove --disable_iobinding for trt ep benchmark (#12053)
[33m043816f895[m Make C# runtest.sh automatically set latest opset (#12039)
[33m02b9b12127[m Fix DML custom operators which set descriptor heap to command list (#12059)
[33mbfe1eca10c[m Add targets files for new .net6 frameworks (#12016)
[33m3e6b8d159a[m Eager mode: implement resize_ operation (#12004)
[33mb858c2f725[m Extend lifetime of KernelDef when creating a standalone op (#12057)
[33ma457ddc41d[m Merge branch 'master' of https://github.com/microsoft/onnxruntime into bmeswani/merge_pr
[33m2e27a7e330[m Skip Constant Folding for ops producing an optional type output (#11839)
[33m0fa2041f68[m Add eager support for aten:: equal. (#12020)
[33m0ee0b8cf18[m Disable sequence-type tests since C# infra doesn't support well (#12037)
[33mda133ad3d8[m Add FastGelu to kernel explorer for profiling. (#11995)
[33mfdf12a5c35[m Fix windows eager build break by pinning to torch version 1.11.0 (#12033)
[33m04f7c2deda[m FP16_Optimizer Support for more Deepspeed Versions (#12046)
[33mecca6f4d16[m Move beamsearch shared initializers from subgraphs to main graph (#12025)
[33m9f260fb60f[m resolve comments
[33m100aebbd26[m resolve comments
[33m2295b24cd5[m support optimizer opt for deepspeed 0.5.9
[33m102d01b206[m update roialign cuda impl to onnx opset16 (#12036)
[33m0ce14c7068[m[33m ([m[1;31morigin/training_dev/on_device_poc[m[33m)[m Fix windows cpu build VS2022 (#12032)
[33m6e8edfff0c[m Separate training apis from shared core apis (#12027)
[33mc8cd36da01[m Resize optimization for all architectures (#11956)
[33m4eb54ff9a5[m Add warning about future computation change for ConvTranspose with auto_pad (#11984)
[33m8ba8146650[m [TVM] handshake mechanism for support of TVMso EP (#11437)
[33mc0dd9be7ba[m Bump electron from 13.6.6 to 15.5.5 in /js/web (#11884)
[33m0702364d7a[m [js/web][bugfix] fix negative axes for unsqueeze (#11944)
[33m9be2b6046b[m convert_beam_search supports large gpt2 model (#11989)
[33m4552dd38c6[m [DML EP] Pad operator: Handle negative pad counts (#11974)
[33md5fcb432fa[m Generalize native op creation (#11539)
[33mfc0143fe68[m DML EP ResNet50 opset 15 fails in ONNX checker for FusedBatchNormalization lacking training_mode attribute (#12010)
[33mf045994389[m [NNAPI EP] Update NNAPI headers (#11954)
[33m466b2d9f3d[m [C# Tests] Add support for double tensor output in TestPreTrainedModels. (#12008)
[33m7d712c8f8b[m Fix WinML Tests are still targetting deprecated (deleted) experimental signal op definitions (#12006)
[33mbd973bcf1e[m [js/rn] upgrade dependencies for e2e test (#11863)
[33m8cd02508c8[m Include opset 15 in Conv+BatchNormalization fusion (#11960)
[33m68afa2d362[m Bump async from 2.6.3 to 2.6.4 in /js/react_native/e2e (#11280)
[33m9583841ef7[m Improve performance of BiasGelu on oneDNN execution provider (#11935)
[33mf72288b453[m Fix a couple of typos (#11943)
[33mdc5d6b9515[m register signal ops for opset 17 (#11778)
[33md25cf4df26[m Merge branch 'master' into training_dev/on_device_poc
[33mf4ba199bad[m Optimize FastGelu with float2 and float4 vectorized kernels on ROCm (#11491)
[33m088bc7494b[m Deprecate APIs returning raw ptrs and provide replacements (#11922)
[33mb1411c8357[m Restructure function inliner (#11731)
[33mc2fd5ccbe9[m Redesign InPlaceAccumulator op (#11842)
[33m0d6cbc6e57[m fix memory profile for partial graph run (#11911)
[33mfa7f80c847[m Eager mode: Argmax and fixup max and min. (#11861)
[33m2c4e4b6afc[m MT5 onnx conversion for beam search (#11958)
[33m607b7df060[m Allow saving on CPU usage for infrequent inference requests by reducing thread spinning (#11841)
[33mc398ad513f[m Fix orttraining-linux-ci-pipeline - Symbolic shape infer (#11965)
[33m17a8ecee6f[m fix win build errors (on device training) (#11844)
[33me24349b8f2[m Optimize t5 encoder in beam search (#11926)
[33mf6d2fe8311[m MeanVarianceNormalization CPU EP axes attribute validation (#11925)
[33mf54476a42f[m Dll version fix ovep4.1 (#11953)
[33mfac8dae9df[m Add support for gradient clipping, AdamWOptimizer and tensorseq as inputs (#11697)
[33mf14f0e19ec[m Fix trainer (#11933)
[33m2229c48547[m[33m ([m[1;31morigin/test-branch-creation[m[33m, [m[1;31morigin/rashuai/rel-1.12.0[m[33m)[m fix mpi in training build  (#11855)
[33m03beed0ceb[m Remove Cast before and after Gelu (#11885)
[33ma36e92d86e[m Offline tooling readme (#11920)
[33m4bf22e2a40[m[33m ([m[1;31morigin/rashuai/rel-1.12.0-reset[m[33m)[m Update ONNX to 1.12 (#11924)
[33m64f95d400a[m[33m ([m[1;31morigin/rashuai/release_test[m[33m)[m Update DML 1.9 Nuget package to fix WindowsAI nuget pipeline build issue (#11934)
[33m3b1224dc08[m Add .net6 support to the C# nuget package. (#11908)
[33m8c8a781cdb[m fix: handle setBindingDimensions return value in TensorRT EP (#11929)
[33m5646410f65[m Enable Pad test cases with initializer inputs only when building NNAPI EP on Android. (#11932)
[33m61a74f2f4d[m Mohsin/enable dynamic shapes (#11867)
[33mb20daeda81[m Update Linux Multi GPU TensorRT pipeline to TensorRT 8.4 (#11923)
[33m859ef277a0[m apply zcode changes to the beam search op (#11880)
[33mcefceff5c9[m Mark the end of APIs for release 1.12 (#11914)
[33mca35ea417a[m[33m ([m[1;31morigin/user/dwayner/FixRoiAlign2[m[33m)[m [EP-Perf] Install new wheel>=0.35.1 dependency (#11917)
[33m7f1e9e8c67[m Bash: there should be a whitespace after not operator. (#11910)
[33m457ce6cb89[m Make symbolic shape inference script support external weight (#11909)
[33mc1577d08ca[m[33m ([m[1;31morigin/user/dwayner/WindowsAIUpdate20220620b[m[33m)[m DML EP QuantizeLinear defer axis validation for test_quantizelinear_cpu (#11906)
[33m0736c604c7[m Fix building DNNL EP with GCC 12 (#11667)
[33m267a424e52[m Retry Rework execution frame to reduce memory allocations (#11897)
[33m6ee2c1b5fc[m Remove temperature input from BeamSearch operator (#11896)
[33meb41bfb7b5[m Fix graph viewer to proto (#11862)
[33m52f2b3bf89[m [DML EP] Remove suffix removal adhoc logic for fusedNodeArgNames (#11879)
[33ma3ec2d6d15[m changes to c api + bug fix (#11858)
[33mf97bd38c4f[m UEP 4.1 release (#11834)
[33ma93fe7824a[m Update EP compile API deprecation warning message. (#11808)
[33mf70201c801[m Make sure the command works in both centos and ubuntu. (#11894)
[33m1494120423[m [NNAPI EP] Unsqueeze op support (#11864)
[33m4ac72e305c[m NHWC Resize optimization (#11825)
[33madcf7e66c8[m [NNAPI EP] Pad Op (#11860)
[33mad4abbd75e[m [EP-Perf-Dashboard] Add support for TensorRT 8.4 to EP Perf Dashboard (#11876)
[33m8bb0062873[m add manylinux_2_27 CPU wheel (#11886)
[33md2cbae3a04[m Revert "Refactor ExecutionFrame and SessionState to reduce memory allâ€¦ (#11888)
[33mbd65acd08d[m Share execution context memory between TensorRT subgraphs (#11859)
[33m10478a09ca[m Revert "add manylinux_2_27 wheel (#11832)"
[33m2ecba6fd25[m Refactor ExecutionFrame and SessionState to reduce memory allocations and improve data locality (#11804)
[33m3d99f16e98[m Merge pull request #11827 from microsoft/user/dwayner/DmlEp1.9
[33mdf5ee6aa4e[m [TensorRT EP] support TensorRT 8.4 (#11866)
[33mfe7b8b80ae[m[33m ([m[1;31morigin/user/dwayner/WindowsAIUpdate20220620[m[33m)[m Revert BatchNormalization change for now, falling back to CPU on mixed types until a more advanced solution is written
[33mbabd6e3fcd[m Update DirectML preview package with unmangled names
[33m3f8c9146d5[m ppc64le: specialize generic 'mlas' functions to use VSX instructions (#11845)
[33md64f23fec0[m EP factory creation cleanup and enhancements. (#11798)
[33mf63e28c92f[m C API version 0.001 (#11758)
[33m1a1c360a80[m [NNAPI EP] Add Gather op support (#11824)
[33m02457ec30a[m [CUDA] GatherElements[Grad]/ScatterElements Bugfix and Perf Improve (#11374)
[33ma805a49363[m Move OrtValueVector from onnxruntime-training to onnxruntime (#11176)
[33mff8b173286[m Typo in DirectML.Debug.dll
[33m508c76a246[m Add missing DirectML.Debug.dll
[33me3ec30efb6[m Add missing GELU to ApiHelpers.h
[33m4c1a410d54[m Unmangle DML preview package filenames
[33mbbace23d0c[m add manylinux_2_27 wheel (#11832)
[33m51ed27cf22[m Delete win-gpu-cuda-10-2-pipeline.yml (#11847)
[33m3cbbf9dcae[m Fix wasm static lib in sub-project (#11671)
[33me8b0d24071[m Support per-test tolerances for ONNX tests (#11775)
[33md936751aad[m QlinearConv threading adjustments (#11228)
[33m80d8c4c7ff[m add data type check before quantizing (#11840)
[33m607afbe1c0[m fix valgrind warnings:Conditional jump or move depends on uninitialisâ€¦ (#11822)
[33m52f6db19da[m Python backend: use packaging.version to parse ONNX version (#11800)
[33mf6d2b629a0[m Add kernel explorer (#11779)
[33m6bf6bac1fd[m Add patching of xnnpack CMakeLists.txt to allow building with Emscripten. (#11829)
[33m63c483a998[m 1.12.0 is the right TBD instead of released 1.11.0 (#11817)
[33maef53e2b0d[m Support uploading EP perf data to a configurable database. (#11819)
[33ma93ebd2503[m Move tvm pipeline to Github Actions (#11721)
[33mb0e027c661[m Add aten::_softmax to eager ops. (#11820)
[33m7582644f57[m cmake changes for SNPE EP (#11821)
[33m04dd6639de[m And appease the time wasting formatting tool now -_-...
[33m2bc487a816[m Appease flaky flake tool
[33m50e0a193c8[m Merge branch 'master' into user/dwayner/DmlEp1.9
[33m76024b8a6a[m Update DirectML.dll to 1.9.0 Preview
[33m0869f4f4ea[m ppc64le: optimizing the MlasRequantizeOutput() with VSX (#11659)
[33mfb88efbe18[m End to end run pass (on device training) (#11694)
[33mdef78a1b81[m Support T5 in BeamSearch operator (#11450)
[33mc1b5f34362[m DML EP BatchNormalization-15 (#11814)
[33m768b9cfb60[m Fix GetDirNameFromFilePath to support forward slash in windows (#11793)
[33ma61c38e4f4[m Add ability to author float initializers (#11752)
[33m5562b47f06[m missing #include <thrust/count.h> in non_max_suppression_impl.cu (#11730)
[33md4ea59654c[m make xnnpack build for ort-web (#11745)
[33mf745eb1d3f[m fix gradient ut (#11797)
[33m5ecfaef042[m ATen Fallback for Inference (#11597)
[33m927bac0f86[m Rework allocator sharing to work for multiple devices. (#11700)
[33m5e54611427[m DML EP add Trilu-14 and Resize-13 nearest mode and others (#11782)
[33m0f0b640b4b[m Reformat build.py for WindowsAI branch (#11794)
[33m8156b9370c[m [Abseil] Adding URL_HASH so that an existing archive can be used from disk (#11690)
[33m540935aace[m lr scheduler implementation (on device training) (#11714)
[33m913100885b[m Remove the redundant black check in CI (#11790)
[33m79db92f8fe[m clang-format signal_defs.cc (#11767)
[33mf5fe4f253c[m Registered Softmax/Hardmax/LogSoftmax-13 as Versioned Operator (#11787)
[33m750cb42f87[m Bump protobufjs from 6.10.2 to 6.11.3 in /js/node (#11722)
[33mbc4c771078[m Bump protobufjs from 6.10.2 to 6.11.3 in /js/web (#11723)
[33meeeb249a27[m Update onnxruntime_providers.cmake to remove the reference of "onnxruntime_tvm_dependencies" (#11780)
[33m331c387f4a[m [TVM EP][DOC] Documentation update for TVM EP due to the addition of precompiled model support. (#11743)
[33m7f8d0ba824[m Update comments in Android workflow (#11311)
[33mf6f457aa57[m not remove relu/clip for symmetric activation (#11696)
[33maa3a825816[m Added Softmax/Hardmax/LogSoftmax-13 (#11772)
[33m40f4304c7d[m [Fix #11447] Use correct type for tensor shape vectors (#11448)
[33mb4f1e769c0[m Add Mac Silicon/M1 Wheel (#11591)
[33m40d2c98e4d[m [js/web] fix ORT Web dependency version mismatch
[33m8fb38e8a54[m fix cmake warning (#11742)
[33m9e33bfd29b[m Bump simple-plist from 1.3.0 to 1.3.1 in /js/react_native/e2e (#11712)
[33m908e19dc16[m [FIX] using torch.version.cuda/hip to ensure build ORTModule Torch C++ CUDA extension for docker build (#11675)
[33m981d45d8d5[m Add binary comparators to the OneDNN (dnnl) execution provider (#11641)
[33m4296968f20[m [TVM EP] update set input method for VirtualMachine (#11674)
[33md5e34acb82[m Remove git and python packages from the docker images used by Zip-Nuget-Java-Nodejs Packaging Pipeline (#11651)
[33m3c1dd9514d[m Revert "fixed point based requantization on arm64 (#11540)" (#11732)
[33mef64b2ee52[m Fix clash between QDQ propagation and TransposeOptimizer (#11636)
[33m95a16c1ffe[m Snpe ep (#11665)
[33m98960c53fe[m Replace ORT's function shape inference with ONNX's (#11538)
[33mec05313cd9[m Split the GPU pipeline to 3 different machine pools (#11724)
[33m4445dd6bc1[m XNNPACK EP (#11445)
[33mce4ac6d328[m Optimizer - add missing supported version for BiasSoftmaxFusion (#11616)
[33m196cd7aed1[m Pylint fix after #11647 (#11704)
[33m1f2c92673b[m fixed point based requantization on arm64 (#11540)
[33m453c57f92f[m Revert "Directly use memory mapped data for external data initializers  (#11127)" (#11650)
[33m54d1573d2f[m [ORTModule] Enable SimplifiedLayerNormalization Fusion (#11580)
[33m03abcb0640[m Correctly unpack tensor values (#11639)
[33m2ac3649752[m Update requirements.txt (#11682)
[33mf437945926[m fix output shape of ReduceMin/ReduceMax in calibration tool (#11647)
[33m004560f1fe[m [js/rn] upgrade dependency packages' version (#11586)
[33m74bc4c07f6[m Fix C# and numbering (#11643)
[33m1c316d0e39[m Parameter,Module and Optimizer changes (#11494)
[33m3076061aca[m Fix a comment in test_op_reshape.py (#11606)
[33m22739137c4[m Update signal op defs to match onnx17 defs, and add more tests (#11631)
[33me1c63cb06a[m Merge branch 'master' of https://github.com/microsoft/onnxruntime into training_dev/on_device_poc
[33mc318b19307[m Add support for BCEWithLogitsLoss (#11630)
[33m4fabc400de[m Fix CUDA 11.6 build error on Windows (#11578)
[33m7e6d052275[m Add better error message for subgraph output coming directly from outer scope value. (#11638)
[33ma7fa735286[m Merge remote-tracking branch 'origin/master' into WindowsAI
[33mb67c0f639c[m Remove filter_mode input from pyflakes GitHub action (#11644)
[33m44f7b1bf2c[m MTA AdamWOptimizer (#11506)
[33m02724c54ff[m [CUDA] Implement BitmaskDropout, BitmaskBiasDropout and BitmaskDropoutGrad (#11534)
[33meadb1a3128[m Speed Up GradientChecker Running (#11579)
[33m6a45f9f059[m Pin protobuf version to 3.18.1 (#11645)
[33m006597b9b8[m Microsoft mandatory file (#11619)
[33mf0dff6bb74[m [js/rn] add expo config plugin support (#11556)
[33md03d7afef8[m Fix build errors when building with enable_memory_profile (#11617)
[33m6e65bac5c2[m Memory usage optimization in LongFormer Attention (#11611)
[33m883e4bc341[m Update the 'Linux-GPU-EP-Perf' pipeline to build ORT from source by default. (#11610)
[33m427230431a[m Fix torch cpp ext build when CPU wheel is installed but GPU card is present (#11608)
[33m147a1737f9[m MatMul postop fusion for dnnl ep (#11565)
[33m4e9ad7b6ae[m Update .flake8 to exclude .git directory (#11615)
[33m3a22a866a1[m On device training offline tooling (#11520)
[33me3a2d5cca8[m Add additional python requirements (#11522)
[33m69aaf03345[m allow catch all exceptions (#11498)
[33ma67994316a[m Update rocm ci to ROCm5.1.1 + torch1.10.0
[33mabecb56832[m fix buid break (#11492)
[33md2519ec0c2[m DirectML EP add CastLike-15 and Reshape-14 (#11568)
[33m436c4f9b79[m Add BFloat16 (bf16) support for ATen (#11546)
[33m3a867d83d5[m DirectML opset14 type updates for Add/Sub/Mul/Div and Relu/PRelu (#11560)
[33me45197fa8c[m [trt-ep-perf] Fix upload time of EP perf data (#11531)
[33m8092d9f9a2[m[33m ([m[1;31morigin/enhance_graph_viewer_to_proto[m[33m)[m [TVM EP] Support inference by shared library created by TVM (#11389)
[33m48efeca66c[m [trt-ep-perf] Fix bug that suppresses latency gain reporting (#11321)
[33m782f9e394d[m [CoreML EP] Fix condition in PRelu op supported check. (#11543)
[33mdeef214772[m Update gather to use multiple threads (#11524)
[33m5eaa893936[m [CoreML EP] Add support for PRelu (#11474)
[33md9c9adb78b[m Add python static type checking in CI checks (#11518)
[33mc556f5f22f[m Add AMD python package ROCm5.1.1+torch1.11 (#11516)
[33m6255194659[m All LearningModelSessions created from a common LearningModelDevice should share the same thread pool (#11457)
[33m5709ed2e16[m Fix shellcheck warning (#11489)
[33mb14c1fd479[m POWER: Optimize MlasQLinearAddKernelHelper() (#11454)
[33m09590f013a[m fix windows ci debug build break (#11495)
[33m4aef7e3aab[m [CoreML EP] Add DepthToSpace op support (#11468)
[33ma3f05da338[m Revert "[TVM EP] update set input to remove excess copying inside TVM (#11247)" (#11504)
[33mece1274ffa[m revert safeint version (#11500)
[33mf94b25933a[m ci(cpplint): Ignore runtime/references warnings (#11499)
[33m2660eb8364[m[33m ([m[1;31morigin/user/dwayner/AddSubMulDivTypes[m[33m)[m DML EP: Gelu (#11483)
[33m6f85d3e5c8[m fix(onnx_export): Extract arg value from torch Value (#11471)
[33mf5473596fa[m Change longformer default kernel (#11470)
[33m48ae27d578[m Update protobuf-java to 3.20.1 (#10420)
[33m207ad7eef9[m Remove spdlog from cgmanifest.json
[33m027fc1d391[m Completely delete ORT server
[33m903743e823[m Delete unused TRT docker files (#11486)
[33m205b61c5d8[m Fix bad merge in build.py
[33mf82946c4a0[m Merge branch 'master' into user/dwayner/WindowsRiTest2
[33m0ac2e6e546[m Update install-entrypoint.sh: add version lock for NCCL (#11475)
[33md8a1531c37[m CKPT API Implementation (On Device Training) (#11261)
[33m3437967e63[m [js/rn] fix CI packaging for react native E2E test (#11463)
[33m738d9b153c[m Consolidate several types into onnxruntime::ArgType. (#11430)
[33m288892335e[m [NNAPI EP] Add support for DepthToSpace Op (#11354)
[33m3b16fb2000[m Delete java-test-final-jar-step.yml (#8894)
[33mc541063245[m Format coding conventions documentation (#11405)
[33mc2de603c10[m Contrib ops for TRT plugin: Disentangled Attention Plugin (#11287)
[33m70e501866b[m Revert "[TensorRT EP] reduce CI pipelines test execution time (#11440)" (#11460)
[33m69b2fab810[m Update DirectML from 1.8.0 to 1.8.2 (#11459)
[33m8467af832f[m Fix reduced pipeline by excluding test case standalone op (#11458)
[33m3624f7c5a5[m Update samples (#11420)
[33m2a90922f01[m Using vectorized loads (float2) for fp16 to improve performance (#11390)
[33md2ae0f49b2[m Make Graph::InlineFunction be able to process initializers (#11443)
[33m8d6ade9e08[m [TensorRT EP] reduce CI pipelines test execution time (#11440)
[33m3f3c5fcd68[m Unify the Compile API for mobile build and normal build (#10632)
[33meca4cbc419[m Avoid using word 'crazy' (#11396)
[33m5ae461ec0a[m [TVM EP] update set input to remove excess copying inside TVM (#11247)
[33m084165c748[m Change MinGrad/MaxGrad to Use Distributed Logic (#11388)
[33m860ba8820b[m [js/rn] fix ORTRN for iOS (#11425)
[33m963e1ace4e[m Fix SAL annotations for custom op (#11432)
[33ma1f9847b23[m [Fix] Add the extra param to match gelu in PyTorch in the contrib symbolic function (#11318)
[33m1aad59fa49[m Increase timeout for IOS packaging pipeline (#11431)
[33m57b51e72d7[m Linux CI: uninstall onnx before installing it (#11428)
[33maf21a04977[m [js] upgrade async@3.2.3 /js/ (#11421)
[33m85fa168dc1[m Add optional dft_length input to the DFT and IDFT operators. (#11427)
[33mae043e3963[m Support ort device tensor in ortmodule's inference (#11112)
[33m8d69b9398b[m APIs for custom op to invoke ort operator directly (#10713)
[33ma3e38d7c90[m [js] upgrade async@3.2.3 /js/web/ (#11426)
[33m253c8b41ed[m Move some of the transpose kernel code to onnxruntime_framework.lib (#11380)
[33m308b605047[m [wasm] increase timeout for Web Assembly static lib CI (#11306)
[33md306e00351[m [js/rn] set minSdkVersion to 21 for ORT-RN Android (#11403)
[33m5023f6750b[m Revert "Call pluggable EP's shutdown function in Environment::~Environment() (#11120)" (#11393)
[33m92cc1b4542[m Update GPT2 notebook (#11371)
[33m024747bff4[m Allow int32 as shape type (#11345)
[33m49d7050b88[m[33m ([m[1;31morigin/hari/experimentationv2[m[33m)[m Create Checkout Submodules Script (#11344)
[33m80a950cde1[m Create OV EP Signing Pipeline (#11391)
[33m4b875e3543[m Re-implment the function support in onnxruntime (#11167)
[33me194a01787[m Update SafeInt version. (#11379)
[33m11e681f46a[m[33m ([m[1;31morigin/stevenlix/deberta[m[33m)[m [ep-perf] Fix the order of onnx and onnxruntime imports. (#11383)
[33mc6a3c149de[m Fix formatting. (#11386)
[33mc8270c2940[m Add ATen export and gradient for torch.max/min (#11275)
[33m1c64351e09[m Create Tensor with Strides (#11294)
[33m6f218105ed[m [FIX] amd ci pipeline timeout (#11387)
[33m833ded4b0e[m Update setup.py to include config files used by model analysis in wheel. (#11381)
[33m6cd1931a93[m Specify list/map capacity when initializing where possible (#11110)
[33m87a628a602[m [NNAPI EP] Add support for PRelu op (#11303)
[33m9e7753c109[m Speed up GatherElements CPU Op (#11349)
[33md64769c38e[m Set black's target version (#11370)
[33mf6526af23d[m Add LGTM config for c++ and c# (#11365)
[33m20ee399be4[m Include layout transformation ops in extended minimal build and above. (#11355)
[33m88ff48910d[m Perf Bug Fix: Keep First Run for Random Input (#11366)
[33ma7d0158c24[m Introduce a way to disable Abseil library (#11353)
[33m63d4f45186[m Add stub implementation of the NNAPI interface  (#11288)
[33ma937920e24[m Update sequence_op.h (#11361)
[33mcbc7bd1d2a[m Introduce parameterized as a dev dependency (#11364)
[33m14a2b2518e[m[33m ([m[1;31morigin/try_downgrade[m[33m)[m [NNAPI QDQ] add qdq gemm/matmul op support (#11089)
[33m4ec5fe5c8a[m Github action: Inline lint python / js / cpp (#11328)
[33m0292356bd7[m TensorRT EP engine cache serialization/deserialization refactor (#11045)
[33m81d78706fe[m Add location planning logic for implicit inputs which are graph inputs  (#11320)
[33mfdce4fa6af[m Format all python files under onnxruntime with black and isort (#11324)
[33m13f86e7d56[m print mac agent info (#11338)
[33maaa583e776[m Refactor the model tests code in onnxruntime_test_all.exe (#11300)
[33m6fb29f5b9a[m Add python docstring linting in vscode settings (#11316)
[33m532e2536cc[m increase timeout in PR build  (#11319)
[33mf069951835[m [trt-perf-test] Pass TensorRT/CUDA EP options via dictionary argument (#11231)
[33mba1e9a218e[m increase timeout (#11310)
[33mdaf87fd0dd[m specify the path for gpt2_helper in onnx_exporter.py (#11301)
[33m23b01258b5[m Fix how the output tensor is created in CUDA SpaceDepth ops (#11302)
[33m86cdabbcfd[m Add OpenVINO Pipeline Status to README (#11299)
[33m4d0214f851[m Move Contains() helper function to a higher common.h. (#11289)
[33m7aa4af238a[m Add strict_shape_type_inference config option (#11081)
[33mc5de493a8a[m Exclude EPs that aren't available on mobile to try and fix Xamarin build error on M1. (#11267)
[33m4854a09340[m Consolidate utils::ToTensorProtoElementType, TypeToDataType, and data_types_internal::ToTensorDataType. (#9824)
[33m2cacd18d51[m Fix an SAL annotation error
[33m1d96cbec73[m Move gpt2 script to models\gpt2 sub-directory (#11256)
[33mcb46d79108[m Model tests refactor (#11194)
[33maf249943a1[m Increase the timeout so the packaging pipeline stops failing.
[33m013306c940[m [MinBuild] 132KB minimal build binary size reduction via dummy __cxa_demangle (#11071)
[33m180b3f7cc2[m Update QDQFinalCleanup transformer to also handle removing DQ/Q node pairs. (#11219)
[33me3ff4a6bfa[m Fix NNAPI EP error when handling external node adjacent to partition. (#11233)
[33m70d97bdf53[m Support only one input in QLinearConcat (#11265)
[33m2e6c2177af[m remove deprecated quantize api (#11263)
[33macb555c4c7[m ppc64le: Optimizing the MlasMaximumPool() to use VSX instructions (#11216)
[33mbab9b80f1f[m auto mixed precision for t5 (#11252)
[33m5ee8e2e491[m [js] use NPM and yarn to upgrade package version (#11059)
[33m06026fe8e6[m SizeInBytes Fix for Strided Tensor (#11224)
[33m3dac66698b[m Add option to specify onnxruntime repo URL in tools/android_custom_build/build_custom_android_package.py. (#11250)
[33mefb0928e2b[m Fix find_package for benchmark
[33m98faaa7e2f[m Scoped GIL release in run_with_iobinding (#11248)
[33mdec99657a1[m Improve onnx shape inference in quant tool (#11106)
[33m9765ef8b4e[m fix build warnings (#11213)
[33m0bad5b1b5a[m [CUDA] Rollback TileMemcpy and TileBatchedMemcpy when Block Size is Small (#11187)
[33m8ee8fdd59b[m Add training api test runner (#10972)
[33md9eeb48393[m One dnn v2.6 update (#11220)
[33m227bc7264e[m Fixed compilation error for ARM architecture (#11223)
[33mbc296c706e[m MatMulScaleFusion - handling scale input (#11121)
[33m94032357e2[m use int storage (#11185)
[33m63ff391b16[m add AppendExecutionProvider_CUDA_V2 to the C++ api (#11153)
[33mc2b4054c74[m Fix typos
[33m5216a43c9d[m Consolidate TensorRT subgraphs to reduce inference overhead (#11211)
[33ma00d24066a[m Fix CITATION.cff and add automatic validation of your citation metadata (#10478)
[33m9707181257[m fix build error (#11199)
[33m3b3b23bcf9[m Add new python helper dirs to wheel. (#11196)
[33m0d0edc071f[m Detecting ARM64 CPU core micro-architectures in Windows (#11145)
[33mddb17294b2[m Fix gradient builder for Cast (#11008)
[33me84c338989[m minor improvements to CONTRIBUTING doc (#11080)
[33m5337972f92[m Update to use teams instead of individual GH handles (#11163)
[33m9435369550[m[33m ([m[1;31morigin/user/dwayner/WindowsAiBackup[m[33m, [m[1;31morigin/user/dwayner/WindowsAIBackup[m[33m)[m Option to build with DML as an external project (#11180)
[33m38e67e66a2[m Add script and Dockerfile to build custom Android package (#11144)
[33me397d8e63e[m POWER: Optimize MlasTranspose functions (#11172)
[33m833f5d5604[m Remove dependancy on EP TVM in unit test project (#11170)
[33m625cc0ab99[m Add Initialize() to shared providers to allow for reload (#11066)
[33m8237568b65[m Fix the rocm packaging pipeline package upload problem (#11174)
[33m04fe1bd2ed[m Bump electron from 12.2.3 to 13.6.6 in /js/web (#10978)
[33mae243c2bb5[m Pull Nightly Wheel File and Cleanup Perf (#11164)
[33m749c0ddd1e[m Upsample support NHWC (#10824)
[33m269be2fe63[m Remove unnecessary option from convert_onnx_models_to_ort.py, fix old instructions. (#11088)
[33m00b595e389[m move longformer and t5 to models subdirectory (#11161)
[33mf24523e0eb[m Enable LayerNorm and SkipLayerNorm in OneDNN EP (#11128)
[33md96230065e[m fix code error in function.cc (#11148)
[33m12c687f594[m Rework initializer.cc to eliminate code duplication (#11131)
[33mbcc62e0cbf[m move some process out of training step (#11150)
[33m4c37f15c1b[m Find boost, nsync, json, cpuinfo system libs with CMake option onnxruntime_PREFER_SYSTEM_LIB (#11146)
[33m0aaf3a676a[m Update reduce norm1/norm2 and layernorm kernels with ROCm 4.3.1 (#9399)
[33m1b664e6d4c[m Link cpuinfo only if supported (#11147)
[33m541eff8d89[m Directly use memory mapped data for external data initializers  (#11127)
[33m5637f17189[m Remove python frontend codeowners (#11143)
[33m7609694464[m Enable building with a GDK (#11126)
[33m4983d6e5d6[m Call pluggable EP's shutdown function in Environment::~Environment() (#11120)
[33m2700261f7c[m Provide an API to supply external initializers data from user buffers (#11109)
[33meec5187801[m Remove Rocm 4.2 from CI Build (#11130)
[33me612018127[m [CUDA] Tile Kernel Optimization (#11053)
[33m26fceca90f[m[33m ([m[1;31morigin/leqiao/fix_openvino_version[m[33m)[m Update tools/ci_build/upload_python_package_to_azure_storage.py to not use the azure blob storage python package (#11114)
[33m81fa28bc56[m OpenVINO-EP v4.0 Release PR with OpenVINO 2022.1 (#11025)
[33m3f42665a40[m Improve transfered time from ort to torch (#9610)
[33m58d97691ac[m Set dims for constant with multiple values (#11116)
[33m91c940b619[m adding fill scalar for torch ones direct initialization on ort device  (#10898)
[33m2c2408814f[m Add function body for SoftmaxCrossEntropyLossGrad (#10779)
[33m20fbf603d3[m[33m ([m[1;31morigin/pull[m[33m)[m Fix ARM64EC build breaks (#11111)
[33m25fdf8b167[m Add Dequantize Linear operator on OneDNN EP (#11036)
[33m8db180c245[m orttraining cuda 10.2 to not build for compute_80 (#11103)
[33m01631893cd[m [cmake] Re-factor pre-compile header usage (#11093)
[33mfc7fe0012f[m Fix: nodejs installer file name is wrong (#11097)
[33m872ed91d8a[m Perf FasterRCNN + MaskRCNN (#11102)
[33m112dec6565[m Added code for FusedMatMul inside matmul op primitive (#11077)
[33mea004e953f[m [cmake] Export multi targets in static build (#11063)
[33m2dfd81b9bb[m [cmake] Add option onnxruntime_ENABLE_CPUINFO (#11084)
[33m25398cc5fe[m Add cleanup instruction to run_dockerbuild.sh (#11079)
[33mf9940f17b1[m Remove extra-index-url to avoid nuget security analysis vulnerability (#11082)
[33mb9279f637d[m update How_To_Update_ONNX_Dev_Notes with right paths (#11074)
[33m588a66e221[m Add cleanup steps to the build jobs which run in Linux CPU machine pool (#11078)
[33m249c4dec7f[m Update orttraining release pipelines to use torch 1.11.0 (#11018)
[33m8e6dbad287[m FIX: Nuget pipeline doesn't report binary size for Linux ARM64
[33m11a4ca741d[m fuse Conv+Add+activation for CPU from different op-branch (#10987)
[33m79e4ed8064[m Bump pytorch-lightning
[33meab7c0d5bf[m Fixing optimizer failure due to missing provider list (#10497)
[33mbfcd5bd4a2[m remove hardcoded library name (#11058)
[33m8dcadba670[m [js] aggregation of recent dependabot security warnings fix (#11060)
[33me9c68d57ca[m Bump minimist from 1.2.5 to 1.2.6 in /js/web (#11033)
[33m6c7090a829[m [js/web] fix output type mapping (#11049)
[33m9505e8c6c1[m fix json format (#11046)
[33m9616ad483f[m [Java] Support configuring CUDA and TensorRT execution providers (#10697)
[33m179406bd25[m [JS] upgrade package-lock.json from v1 to v2 (#11039)
[33m998bf0fdb6[m Remove advice to use IO Binding for this scenario (#11006)
[33mc37d2728bf[m Implement TreeEnsemble for opset(ai.onnx.ml)==3 (#10821)
[33m1424b796ff[m [js/web] disable test_tan temorarily (#11048)
[33md1bdd2cd94[m allow trailing slash in directory (#11001)
[33m5868413caf[m fix seg fault (#11038)
[33m8f456735d1[m Remove unused variable. (#11043)
[33m6c005bfdbc[m Enabled Cast operator on OneDNN EP (#11023)
[33m6a6840d5c6[m Fuse LayerNormalization for Apex O2 (#10233)
[33m3b6cee8059[m [CUDA] Optimize Conv and ConvGrad for Training (#10999)
[33m8ba52b0a05[m Bump master version to 1.12 (#10797)
[33m9371401746[m Move node EP assignment for ORT format into SessionState::FinalizeSessionState() (#10944)
[33m9c6cc018a9[m Add utility to get the gradient graph from GradientGraphBuilder (#10995)
[33mdc72159105[m Symmetric Quant indirect Conv kernel for ARMv8 A55 chip (#10862)
[33m8ddc45f52d[m Add linux and macos arm64 java aritifacts (#10981)
[33md1be71eaa3[m [cmake] Add keyword STATIC to add_library in function onnxruntime_add_static_library (#10998)
[33mcb31b7eab1[m Fixed creation of ORT_Value to pass offset of 0 (#11004)
[33m47c09e6701[m Clarify usage of kOnnxDomainAlias. (#10962)
[33m89ef987ab1[m Improve NonZero on CUDA/ROCM (#10307)
[33m1e917c879e[m Adding support for saving and loading train step info properties in the state dict and checkpoint file. (#10569)
[33m989e640009[m Update docstrings in quantize.py (#10952)
[33m3c5853dcbc[m register custom_op_symbolic for squeeze (#10970)
[33m7ee52fb8a0[m amdmigraphx_ep-add ops to be supported by migraphx and fixed a bug in check ops to be supported (#10496)
[33mae08f9666d[m Fix type constraints in registration of DequantizeLinear (#10986)
[33m938f3857a5[m Set the default for the STFT onesided attribute to 1, which tests expect (#10984)
[33m07201726ed[m Fixed macros for graph transformer registration. (#10983)
[33mde384805cd[m Custom parameters (#10964)
[33m9a3be9b46a[m use #include <hiprand/hiprand.h>, not deprecated #include <hiprand.h> (#10966)
[33m0efbe92296[m fix coverage report error in master build (#10969)
[33m480c793125[m Update training packages to Pytorch 1.11.0 (#10851)
[33m565318ce86[m Support ORT WASM compilation with the training flag (#10973)
[33mb28e5064f3[m Ignore DequantizeLinear nodes in CommonSubexpressionElimination optimizer (#10934)
[33mb88fb68fac[m Adds missing numpy type when looking for the ort correspondance (#10943)
[33mdce5d719c5[m add build flag for emscripten settings (#10963)
[33m027565b3b2[m Add multi-dim dft test, and fix complex idft (#10947)
[33m2da82fd0b9[m allows multiple '--cmake_extra_defines' flags (#10953)
[33m6d19c295d0[m use lf as eol for node package (#10965)
[33mb34d9f6867[m [js/wasm] Add WebAssembly static library build into web CI pipeline (#10959)
[33m4a5b5328a4[m Added support to Eager CodeGen for multiple in-place parameters. (#10945)
[33m1cc2cfb7b8[m Move #ifndef ORT_CXX_API_THROW to the no exceptions case. (#10937)
[33ma6ea278502[m add python3.10 support  (#10848)
[33m8703d37517[m Extend DropoutGrad function to support bfloat16 (#10662)
[33m91722e2bc4[m Fix typos (#10935)
[33mc1e37e4ebf[m Android CI Pipeline: Fix post coverage bug (#10949)
[33mfe6ab719f3[m Fix a typo in quantization tools (#10940)
[33meabb14788a[m [perf_metric] added inferences per second metric (#10921)
[33m3897b93606[m optimize Android CI (#10938)
[33m2dea7dc27f[m Skip python arena shrinkage test on ppc (#10901)
[33mde06d95096[m [parallel_inference] added support for parallel inference with timed duration perf test (#10922)
[33m5cbacec854[m Maintain aspect ratio by doing resize + crop in image_to_pb tool (#10887)
[33mf058c59407[m Performance: add io_binding support for bert benchmark util (#10907)
[33mc29d94383d[m Update CODEOWNERS (#10932)
[33mee05c591e5[m Fix benchmark bugs and add Pytorch version control  (#10928)
[33m6f844522c8[m Follow up update for python API checking if `vcruntime140_1.dll` is available (#10927) (#10933)
[33m8860fded02[m Disable Some Einsum ORTModule Tests Due to Issue from PyTorch Exporter (#10906)
[33m5ed2f4ad5f[m Remove Windows Store specific code
[33ma3eeb7b0f7[m Update orttraining-linux-external-custom-ops.yml for Azure Pipelines
[33m78133434b5[m Fix fp16 converter bugs[1/n] (#10882)
[33m5d4ff67c36[m Support fusion options for benchmark.py (#10900)
[33mb86d105153[m [python API] Change raise import error when `C:\Windows\System32\vcruntime140_1.dll` is not found to warning (#10927)
[33m740870a285[m [js] Create npm packaging pipeline (#10886)
[33m766e6ac4fd[m check TVM target for CPU (#10926)
[33ma46b00499a[m Revert "Upsample support NHWC (#10554)" (#10917)
[33m810c18e809[m fix complex multi-dim dft (#10896)
[33m07a71d5bf2[m Fix handling of nodes inserted by NHWC transformer. (#10904)
[33me03b799b95[m Make it clear in verbose log on why a kernel impl does not fit for a node (#10872)
[33m6c0eff1ae4[m optimize Transpose3DKernel (#10891)
[33m463fac67a3[m [FIX] symbolic shape infer error with onnx-1.11.0 (#10674)
[33md7d7665023[m restore random states after export_model (#10705)
[33m42d7112f03[m Add multithreading test and put a lock on nvinfer1::createInferRuntime() for TRT EP (#10714)
[33mce204d0744[m Update to flatbuffers v2.0.0 (#10866)
[33mbac9c0eb50[m skip optional related models from opset16 (#10840) (#10878)
[33m5763657715[m [UPDATE] Add prefix in front of the file (#10884)
[33m625a1f7673[m [TVM EP] code refactor (#10655)
[33mf468ea40e5[m Refactor Node::AddAttribute() (#10869)
[33m040c0645e2[m [ADD] Add micro-benchmark for Cast (#10870)
[33m860f28254e[m Update DFT definition to more closely align with PyTorch by enabling axis attribute, and arbitrary tensor rank. (#10842)
[33mde6d1fcb41[m Update C# runtest.sh
[33maebbb90b79[m Integrate C-API tests into Pipelines for release packages (#10794)
[33m2d961604b1[m Refactor Python API docs to better explain IO binding scenarios (#10651)
[33mf385c73058[m Fix a couple of issues with the python package tools (#10858)
[33m0d8d44d035[m Fix Reduced ops pipeline (#10861)
[33m7e9dfe627a[m Add additional NNAPI QDQ test cases for expected failure path (#10769)
[33me53422c6d0[m Update convert_onnx_models_to_ort.py to support runtime optimizations. (#10765)
[33m03181caeae[m Creating test case for printing ort tensor (#10850)
[33mce10d7d231[m Workaround https://github.com/microsoft/STL/issues/434#issuecomment-921321254
[33md1f059c856[m Remove kernel32 defaultlib
[33mddf1a312ab[m Remove cpuinfo from WCOS builds
[33mc4f73af234[m Fix wrong percentile values returned during calibration (#10847)
[33m6ac3b8d46a[m Add support for opset 16 to transpose optimizer. (#10841)
[33m2d2eebb844[m Correct a comment
[33m2e7592ddf8[m avoid using LocalFree on FormatMessageW buffer (#10796)
[33m64556888a1[m add python binding for RunOptions config entry (#10694)
[33md478a53d43[m don't clear grad_fns & add test (#10671)
[33m1a62306db7[m Use separate build directories for full and mobile iOS packages. (#10835)
[33m5202efd11e[m remove unused six in code and CIs (#10832)
[33mf87a06cd96[m Patch absl so that it doesn't disable important VC++ warnings (#10836)
[33m97ae44d060[m Mark end of version 11 C API. (#10803)
[33m3ae2bfaefe[m Abjindal/torch api change gelu (#10833)
[33m1d545dfe87[m Address performance issue with abseil flat_hash_table. (#10819)
[33me80ff63274[m Fix bug in MemcpyToHost (#10816)
[33m9853eaa14f[m Detect runtime CUDA JIT and warn the user (#10781)
[33mcc3a3476ed[m Uninstall onnxruntime-training before running local tests (#10827)
[33m9cbcc93e03[m Add micro-benchmarks for Attention and SkipLayerNormalization ops. (#10798)
[33m1c313f4476[m changing gelu backward op and adding required files (#10813)
[33m0293e525ea[m Make QDQSelectorActionTransformer() is_int8_allowed parameter required. (#10820)
[33mcc6bc34c8c[m Update protobuf submodule (#10801)
[33m58521fb822[m Make training CUDA kernels to adhere established code structure patterns (#10735)
[33m4ef81b142d[m Making the Java tests faster by optionally disabling ones which require running multiple JVMs. (#10811)
[33mae97ecf05b[m Fix CPU, CUDA Selu activation logic (#10771)
[33mc147c9dda6[m Remove ORT_ENABLE_RUNTIME_OPTIMIZATION_IN_MINIMAL_BUILD. (#10778)
[33m769aa8363d[m update onnx-tensorrt to bring in https://github.com/onnx/onnx-tensorrt/pull/812 (#10810)
[33mf4fd67cc2c[m Revert "add load from buffer (#10162)" (#10590)
[33m7e04dccca7[m Bump numpy in /tools/ci_build/github/linux/docker/scripts (#10385)
[33m68c8f5a1ef[m Change a pipeline vmImage from windows-latest to windows-2019 (#10804)
[33m33c6819196[m add qdq support of Sigmoid (#10800)
[33m6260733533[m Fix eager mode pipeline (#10802)
[33ma9d9c6b486[m Register CPU, CUDA and ROCM opset-16 kernels for some operators (#10643)
[33mce07dc30fd[m Change how we apply patches to absl (#10799)
[33m1e4a4bfe58[m update onnx-tensorrt reference. (#10795)
[33mda885a72e8[m update with onnx 1.11 release (#10441)
[33m80917342b7[m [js] upgrade mocha@8.2.1 to 9.2.1 (#10793)
[33m4d943c9bd3[m Bump numpy from 1.16.6 to 1.21.0 in /tools/ci_build/github/linux/docker/scripts/manylinux (#10387)
[33mc07a27a008[m [FIX] delete python3.6 from AMD python package docker image builder (#10790)
[33m4a38f9e31d[m enable strided tensor for training only (#10748)
[33mb7f00b9682[m Refactor the common code per operator into an abstract base class. (#10785)
[33ma08036da09[m correct symbolic name of GridSample operation (#10782)
[33m3e54f94bb0[m Bump karma from 6.3.14 to 6.3.16 in /js/web
[33m25fdcfbd14[m [js/web] allow multiple inference session creating concurrently (#10784)
[33ma4b5fa334a[m Add type and shape information to profiled numbers (#10773)
[33md8bf9a479b[m Remove python 3.6 from training pipelines (#10780)
[33m9d30262422[m Fix AMD training pipeline (#10788)
[33m50a6f095cd[m Symmetric QGEMM kernel for ARMv8 A55 chip (#10754)
[33m55af7a96a7[m update the amd ci pipeline (#10723)
[33m60acfd3dd8[m Support CUDA Graph in the CUDA EP (#9978)
[33m0e335aba37[m[33m ([m[1;31morigin/c-api-test-package[m[33m)[m Update BeamSearch operator spec to support t5 (#10777)
[33m6be5185088[m Update dnnl Add, Mul, Sub, Div ops to handle scalar values (#10756)
[33m259ade2557[m Add ability to modify num_hidden_layers from benchmark script (#10760)
[33mfde847473b[m Add min max moving average calibration method (#10753)
[33m43ff27c7c8[m ppc64le: optimizing the MlasQuantizeLinear() with VSX (#10644)
[33m379b3cdef6[m T5 to ONNX conversion script (#10766)
[33m12eb660415[m Compare TRT vs ORT-TRT Accurately (#10565)
[33me3c85d4262[m Bump numpy
[33mb780a3784e[m Bump numpy in /tools/ci_build/github/linux/docker/scripts/training
[33m0b0e8ccf92[m Bump numpy
[33m283d0c47b4[m Update our absl cmake files (#10762)
[33m4c88fa5971[m Add micro-benchmark for FastGelu (#10744)
[33m46d0b20ac2[m upstream TVM. small code cleaning (#10515)
[33m395a7242d6[m [iOS packaging] Minor updates. (#10755)
[33me337f5faf3[m Enable QDQ cleanup and NHWC optimizers in an extended minimal build. (#10729)
[33m7aa706854f[m Pipeline changes to build full ORT package for Android (#10654)
[33m6072c6b65e[m Simplify QLinearConv registration so type reduction works with it. (#10747)
[33mc2c85dd6b1[m Add an option to export ONNX graphs in ORTModule tests (#10579)
[33m745fa5885f[m optimize web assembly build flags for multi-thread (#10759)
[33mc8ec7782bd[m Fix unused variable warning, move variable definitions closer to usages. (#10757)
[33med87e1b721[m Change axis to 0D in cumsum tests. (#10715)
[33mb3e96d6195[m A new pipeline to replace the existing WindowsAI packaging pipeline (#10646)
[33mfe8d867efa[m Optimize BinaryElementWise and BiasGeluGrad kernels for AMD (#10594)
[33m4c20f6863d[m Fix build with gcc 7.5 (#10567)
[33m75160d6779[m Add the missing status return in beam search (#10738)
[33ma9dc50ba8b[m Add option to force QDQIsInt8Allowed to return true when exporting to ORT format (#10719)
[33m44d08d80a0[m Add restriction to first usage in allocation planner (#10724)
[33m47ab0c2006[m Auto mixed precision conversion of GPT-2 onnx model (#10711)
[33m7ebff2b273[m add missing link to openvino (#10737)
[33mf9b6eef05f[m orttraining packaging pipeline for rocm 5.0.1 (#10725)
[33m7ab0c607b4[m add qdq support of (un)squeeze and GlobalAveragePool (#10721)
[33m9ad95bf068[m Skip SetName test on inbox build (#10699)
[33m5d8c5409ab[m POWER10: QGEMM optimization (#10642)
[33me5c6dc1fc8[m Add ability to save calibration augmented models through external data format when model size exceeds 2Gb. (#10695)
[33m62cc981599[m [TVM EP] support of TVM Virtual Machine (#10341)
[33ma7f6442c45[m [js] release pipeline for web and react native (#10656)
[33m9e7d7a9e97[m Convert ConvActivationFusion transformer to a selector action transformer. (#10687)
[33mfa9090f259[m check gpt-2 graph in converting beam search (#10712)
[33md07a2377b1[m Fix race condition in CUDA, ROCm, and TensorRT EP GetKernelRegistry() implementations. (#10200)
[33m2fb2dae42f[m Print tensor snippet in dumping node Inputs/Outputs to StdOut (#10707)
[33ma7738b52c5[m Add microbench to benchmark single operators. (#10678)
[33m19464614e7[m [NNAPI QDQ] Add QDQ Concat  (#10666)
[33m6448ca64e6[m Fix reshape allowzero with unknowndim (#10665)
[33mf652f70d91[m set qdq as the default static quantization format (#10684)
[33mf1b6f0becd[m Update nuget icon (#10672)
[33mc1cf16ed5d[m Conv node bug, cached state was incoherent (#10041)
[33mf4b2d3af2b[m Upgrade emsdk to 3.1.3 (#10577)
[33mc51b500ca7[m replace std::numeric_limits<T> by cub::FpLimits<T> (#10703)
[33m9a22b5d253[m Strided Tensor Support for Eager Mode (#10578)
[33mf856608599[m [java] Changes OrtEnvironment so it can't be closed by users (#10670)
[33me23a224518[m Fix CUDA 10.2 compile error due to inlined_containers.h inclusion (#10702)
[33m3243c9579f[m Fix VLOG?_DEFAULT macros usability. (#10568)
[33md1b2fb15ad[m Avoid clang-tidy crashing due to readability-static-accessed-through-instance check bug (#10690)
[33md2d22f2195[m Add support of generating symmetric/asymmetric tensor's range for calibration (#10663)
[33mffde44cd09[m [iOS Packaging] Add full ORT build iOS package. (#10626)
[33m1f6d8248da[m Add optional optimizer to remove leftover Q->DQ pairs after all other QDQ processing has completed (#10659)
[33me788cc2a23[m Convert com.microsoft::ATen into org.pytorch.aten::ATen onnx op (#10060)
[33me47434ea12[m [java] Adding the graph description to the exposed model metadata. (#10318)
[33m037f08f1ff[m Fix unsqueeze for opset 13 for ReduceMean Grad (#10668)
[33meb116595d4[m Add ability to customize ORT_CXX_API_THROW (#10688)
[33m240f31ef6e[m fix softplus (#10576)
[33mf2ca43fe0d[m Enable CoreML in the macos package (#10675)
[33mb30e0e2283[m Remove inline_containers include from tensor_shape (#10682)
[33m81831201a8[m Change C# tests to use C# 5.0 (#10686)
[33m5fbfca3d58[m Add Experimental API for setting model name (#10518)
[33m36c3271546[m BeamSearch op cuda (#10556)
[33m957dccb379[m Fix compile (#10667)
[33m12c44bfc4e[m fix bug: getting current cpu core type (#10630)
[33m617474e298[m Stop gradient edges for aten::argmax (#10650)
[33m2679711bee[m Refactor transformers and other code to reduce memory allocation calls (#10523)
[33m0b19a03361[m Fix the debug dump of tensor values to output int8 and uint8 values correctly. Without the change they are treated as char/unsigned char by std::cout. (#10658)
[33mb993de9dd4[m add reshape handler (#10627)
[33m56be66a0ab[m Update c-api-cpu.yml: change nuget linux arm64 RID
[33m7660eeef3e[m fix ortmodule's output device info when it runs on ort device (#10616)
[33m446258fa28[m fix bug: quantize output of activation op(Relu, Clip) (#10649)
[33m7dc7529ec8[m [TVM EP] Integrate tests for TVM EP into public onnxruntime CI (#10505)
[33mecf064f135[m Exclude pdb from nuspec unless it's the winml package. (#10638)
[33me076f3a125[m Fix incorrect target name
[33m573e440d35[m Fix no ARM64 natives for Linux nuget
[33mbd08f11a58[m Upsample support NHWC (#10554)
[33me0d1d6906a[m Merge two helpers involving the kernel def hashes into one file (#10609)
[33mea7f773a6e[m Merge pull request #10619 from microsoft/user/dwayner/DmlDev20220221
[33m9ba2d9379f[m [ROCm] Code sync from CUDA (#10631)
[33m8cfa4b1c17[m Fix build errors due to changes in warnings that VS 2022 17.1 produces. (#10621)
[33m7de86d39d3[m Build error int to bool
[33md6a8cba273[m [NNAPI QDQ] Add nnapi qdq softmax op support (#10591)
[33m4d3cd2f685[m Add helper for optimizing a QDQ format model for usage with ORT. (#10595)
[33m4a79ed62b4[m Remove extra version of a function in dnnl (#10599)
[33m742694f679[m [python] [orttraining] Add utility to export a graph to compute gradients (#8125)
[33m6f0640a57f[m Optimize ReduceSum, ReduceMean, ReduceMin, ReduceMax (#10280)
[33mdf841ee87d[m Fix incorrect type constraint registration for operator kernels. (#10489)
[33m893ee65e54[m [js/web] fix lint error when run without ort-web TS types (#10429)
[33m6db6ee5710[m Merged PR 6973543: ORT DML EP Opset 13 more complete
[33m1af4c170ef[m [js/react_native] publish onnxruntime-common npm package as web and node do (#10566)
[33me056fbaa51[m Add restrictions for hybrid cpus for thread pool task distribution (#10393)
[33m2fa333443a[m Add telemetry for device kind (#10431)
[33m2ca9566994[m Add range of helpers for making usage of ORT Mobile easier. (#10458)
[33mfad590a059[m Enhance TRT EP unit tests (#10493)
[33medbc844032[m Fix misspelling in python documentation (#10588)
[33mfd16085cea[m Zhanyao/attention (#10545)
[33m8d06e5a9df[m Add openvino base image option (#10581)
[33mccd7a2d840[m Fix build failure when using clang compiler
[33m09ac7595fc[m update (#10573)
[33m4f76c38686[m Revert "Reduce max gradient (#9859)" (#10574)
[33me71d77e974[m [ROCm] Fixing build for CIs (#10558)
[33m3be3db5180[m Use IntPtr instead of int conversion for pointer in Memory.Pin() (#10485)
[33md198fbc4d5[m Add a script for randomizing onnx weights (#10551)
[33m7443edb0bf[m Reduce max gradient (#9859)
[33mf436d3437e[m Add layout transformer for NNAPI (#10371)
[33mceb1e2b1a6[m [ROCm] Bugfix of BFloat16-float conversion and Add FastGelu Kernel for AMD (#10557)
[33mf22cd3af5d[m Leqiao/add selectable pipeline (#10560)
[33m05d6805830[m clean up quantization of QAT model (#10549)
[33m8e47bb9a4a[m [NNAPI QDQ] Add QDQReshape op support (#10533)
[33m0c3e88944d[m Fix create ort value hardcoded memory info to CPU (#10510)
[33m1cdc23aba4[m [TVM EP] Rename Standalone TVM (STVM) Execution Provider to TVM EP (#10260)
[33md3f7459263[m fix CI build (#10553)
[33m58f80c16ff[m Create branch according to cpu core uarch (#10521)
[33m3199074ac7[m Update QDQ propagation transformer to insert QDQ nodes (#10487)
[33m7691e7ed12[m Introduce load balancing dataset samplers (#10163)
[33m270dec7327[m Return a Status instead of throw an exception in GetAttrs (#10534)
[33m3f37609994[m Remove unneeded code in UpsampleBilinear (#10544)
[33mbfb20b315d[m Bump karma from 6.3.2 to 6.3.14 in /js/web
[33m5cfde7af29[m [NNAPI QDQ] Add QDQTranspose op support (#10495)
[33m318d31ea12[m Fix C# pipeline build error (#10524)
[33m4e2a974090[m [ROCm] UTs and code clean up (#10511)
[33m2002a96594[m The transformer of memcpy is needed for ROCm EP and MIGraphX EP when fallbacking CPU happens (#10522)
[33mf92e47e95b[m Remove onnxruntime_util dependency on onnxruntime_framework (#10512)
[33ma27aabad34[m Fix fomatting. (#10520)
[33m3185680b6c[m Add NHWC CONV contrib op (#10506)
[33meba730500f[m Remove file-scope non-constant static variables to support multiple inference sessions  (#10481)
[33m4d6d4dfb9d[m Add TRT ep perf benchmark (#10470)
[33mdd33ce0fdc[m [js/react_native] Create ONNX Runtime React Native pipeline (#10474)
[33m6f3ade55ec[m Move QAttention/QEmbedLayerNormalization op defs to quantization_defs.cc (#10507)
[33mc9fbd0b15a[m Optimize cuComputePartGradGammaBeta kernel for MI100 (#10475)
[33m7a2bf3c24c[m Reorganize contrib op schemas (#10494)
[33m399ffc9700[m Fix Windows GPU CI (#10499)
[33me4dc4e4d3c[m [NNAPI QDQ] AddQDQAdd/Mul, update to NNAPI QDQ handling, update some test settings (#10483)
[33m655f490c95[m Remove BFloat16 Specialized Code for ReduceSum (#10476)
[33m4388eaed1b[m Merged PR 6937750: Restore history to dmldev. Merge without squash
[33mb14944f9f8[m Merge commit 'b02f4ece5e4f48f5d303d6be0170c03d60b24efb' into user/rylai/restore_history
[33m7e5d68eea6[m gradient and test (#10455)
[33m435e14d60a[m [ROCm] BFloat16 support (#10465)
[33mc696da36c7[m fix unit test of quant gemm (#10469)
[33m0f5d0a091a[m Make user capable of adding new field in OrtTensorRTProviderOptionsV2 as new provider option (#10450)
[33m927f1f18c9[m [NNAPI QDQ] Add QDQ AveragePool op support (#10464)
[33md0ab881d07[m Contrib ops for TRT plugins: EfficientNMS and Pyramid ROI Align (#9486)
[33m6fd7ba5b7e[m Merged PR 6917440: ONNX Runtime update from GitHub master
[33m0d09dd5d20[m Support fusion for TNLR based model (#10432)
[33m4f13c8ac39[m Update orttraining-linux-ci-pipeline.yml (#10462)
[33m6bbf016dc4[m cmake: disable 'attributes' error to fix the build with GCC < 9.x
[33mbb09acffed[m Transformer model CUDA EP align with CPU on corner case (#9889)
[33m63198a6566[m [ROCm] BFloat16 support  (#10447)
[33m239c6ad3f0[m Support specifying an execution provider in benchmark script (#10453)
[33ma405658370[m Fuse Clip->Q to Q (#10434)
[33m97b8f6f394[m Add logic to NNAPI EP to exclude pre-processing involving dynamic shapes when partitioning (#10452)
[33m6076a262dc[m upgrade react-native packages to latest (#10454)
[33mad9d2e2e89[m Prefix match in first iteration of beam search OP (#10231)
[33m1aa0789691[m add qdq support for QGemm (#10414)
[33m7318361645[m [NNAPI QDQ] Add QDQ Resize support (#10442)
[33m91b8ad5ee7[m Allow users to bind arbitrary memory using raw pointers (#10428)
[33m3c96760192[m support rocm/migraphx EP in perftest tool (#10449)
[33m062129a5c4[m Update rocm_ep and migraphx_ep to rocm4.5.2 and fix dockerfiles to build docker images correctly (#10445)
[33ma1d9a71b8b[m Improve Perf System (#10404)
[33ma7c67860a5[m Reduce test time for TensorRT EP CI (#10408)
[33mef7b4dc05c[m Add test quantization of ArgMax for TensorRT (#10325)
[33m68262cce86[m [NNAPI QDQ] Add QDQ Conv support (#10418)
[33mc43c1691ad[m Enable transpose optimizer in minimal extended build (#10349)
[33mbaa1767922[m Allow for an optional subgraph input to have no type info. (#10379)
[33m85cbe8367e[m [ROCm] BFloat16 support (#10416)
[33mb02f4ece5e[m Remove cbegin and cend calls which do not exist in std::span or gsl::span (#10426)
[33m5f0ba31890[m Remove coremltools submodule *security vulnerability*  and copy the coreml model schema  (#10424)
[33mc4f1dfcfaa[m Cfu s8s8 (#10413)
[33m1a2925acce[m Add sympy package as a dependency (#10406)
[33m2dd5e75ba8[m Incorrect output after GPU to GPU inference via VideoFrame and Gray8 models (#10425)
[33mfeae842a7c[m Update pytorch-lightning (#10421)
[33mb14da94fc1[m Exclude CETCOMPAT from Windows ARM build (#10417)
[33mce081fe655[m Fix TopK with NAN on Cuda (#10314)
[33mff2057a817[m Add sample qdq unit test case for nnapi ep qdq integration (#10358)
[33m0e951d7d6b[m Add some more documentation for the C/C++ API tensor creation functions. (#10394)
[33m481b96d32a[m STVM, NUPHAR, remove tvm from submodules list, checks pointers are not null. (#10211)
[33mec4362f8f3[m Enable more static analysis warnings and enable the analyzer for training cpu (#10176)
[33m66acf50488[m Document C/C++ API documentation version info conventions. (#10396)
[33m3367ddc5ba[m Add abseil cgmanifest declaration. Update coding standards. (#10374)
[33m4d305282da[m [ROCm] Enable BFloat16 for Gemm and MatMul Op (#10398)
[33m5f49f40fa5[m Bump log4js from 6.3.0 to 6.4.0 in /js/web
[33m27a4af6074[m Fix some BinSkim defects (#10400)
[33mc6ef465011[m minor fix in node unit change (#10405)
[33mea9c8a7cdc[m support MIGraphXEP to work with ROCMEP for inference on AMD GPU (#10368)
[33m389d2db1ce[m Make model tests name clear (#10220)
[33m847801f5be[m [wasm] update emscripten v2.0.34 (#10391)
[33mcf13b9dd5e[m Symbolic export for numpy_T  (#10390)
[33ma27503ebe4[m use strict mode (#10397)
[33m5576e3553d[m Remove python 3.6 from our python packaging pipeline (#10395)
[33m4af116649c[m  [QDQ] Hookup NNAPI GetCapability/Compile with shared QDQ selectors (#10347)
[33m9aa51379c9[m [eager mode]: add configuration for ort virtual device count (#10346)
[33m5eafbb50f9[m Fix possible null pointer dereference. (#10373)
[33me1012a8662[m Added OnRunEnd and Sync method in ExecutionProvider (#10362)
[33mdf16c605e8[m Add "available since" message for C API additions since v1.10.0. (#10348)
[33ma0fe4a7c1c[m [TVM EP] Improved usability of TVM EP (#10241)
[33m6e95c0316d[m Builds onnxruntime + eager mode with the same value for _GLIBCXX_USE_CXX11_ABI as pytorch  (#10114)
[33m790c3be7e9[m Fix Reshape issue when shape size is -1 (#10356)
[33m4b87d2c172[m Fix dockerfiles/Dockerfile.arm32v7 build. (#10360)
[33mdf0c819850[m fix compilation error due to symantic conflict with another PR (#10370)
[33m2afce4830c[m Symmetric QGEMM  (#10289)
[33m7e092a7e3f[m Reduce number of memory allocations based on a customer profiling case (#10193)
[33m5df15c5644[m additional options of NNAPI for ORT_PERF_TOOL (#10351)
[33m3dfadf9031[m [FIX] Add condition in amd ci pipeline yaml to stop test in time when onnxruntime build failed (#10335)
[33m42db893607[m Add ThresholdedRelu to ROCm EP. (#9480)
[33m6876641c1e[m Pin version of post to dashboard scripts' dependencies and update them to work with recent version. (#10353)
[33mbfabef081d[m Remove unused pipeline orttraining-linux-gpu-perf-test-ci-pipeline.yml and unused send_perf_metrics tool. (#10326)
[33m141606534c[m Add support for FusedAdam to be mathematically equivalent to pytorch/AdamW (#10106)
[33m13e277525c[m fix whitelist
[33meee627fde9[m Track Session Creation Time (#10281)
[33md2b1424968[m fix bugs in cpuid_info (#10334)
[33m2dcb69685e[m support type promotion in binary poerators in eager mode (#10285)
[33mc67594694c[m Add ability to set onnx opset version from json config (#10223)
[33m001cc53968[m Fix CUDA10.2 Build Break for BFloat16 Change (#10331)
[33m4aa7cee0d8[m Abjindal/clean eager backend (#10055)
[33m90e2a4b936[m Fix GH Issue 10305 by adding implicit inputs to consumer nodes map. (#10319)
[33ma656c55a75[m Add _force_exportable_set and pass debug_options (#10282)
[33m7b14c70cfe[m [ortmodule] Ensure contiguous tensor into forward pass (#10315)
[33mb038f4e56f[m Add a build option to create a WebAssembly static library (#10184)
[33m03aab98adc[m Merged PR 6857190: RI 1/19/2022
[33m810cd12753[m Merge commit 'c12cafa524f254dc2ed1c80b22fa1821239fa137' into HEAD
[33m62eab67f79[m Fuse DQ -> ArgMax into ArgMax (#10274)
[33me27f2dc932[m int8/uint8 support for Argmax for opset 1, 11, 12 (#10296)
[33m712f4e403d[m [js/common] upgrade marked@4.0.10 (Dependbot warning) (#10313)
[33mc1c9fa18bf[m C#: Avoid inefficient DenseTensor ctor in ToTensor extensions (#10240)
[33m6ae22d562b[m [QDQ] Move NNAPI EP to use NodeUnitIODef for non-QDQ ops (#10237)
[33m33dd2f8f5e[m fix mac compilation error (#10268)
[33mc12cafa524[m Optimize Transpose CUDA Kernel (#10230)
[33ma757bd7186[m Render summarized ort perf with tree map in browser (#10189)
[33mab5fd42ed4[m reset MIN for float/double (#10284)
[33me365ad7f3a[m fix deadlock in model.train mode forward run only (#9960)
[33m6a7d3deb22[m Update pytorch-lightning (#10276)
[33m13ff79d1e4[m Merged PR 6839685: Merge public onnxruntime
[33m44e2db9397[m CUDA BFloat16 Refactor (#10085)
[33me38e51ea8e[m Improve iobinding, faster name search (#10005)
[33m3ea7fb0f9f[m fix mem leak (#10272)
[33m2a55bc2c21[m Bump engine.io from 4.1.1 to 4.1.2 in /js/web
[33m2affd6e71e[m orttraining packaging and ci pipelines to use cuda 11.3 (#10252)
[33m6cb18fc686[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33m4b205eb2b3[m Bump follow-redirects from 1.13.3 to 1.14.7 in /js/web (#10266)
[33m943a1aa2d6[m Bump follow-redirects from 1.14.5 to 1.14.7 in /js/node (#10265)
[33md43ef67d2b[m Move binary size check to separate pipeline (#10254)
[33m3d9d8e20cc[m Bump numpy from 1.19.2 to 1.21.0 in /tools/ci_build
[33m8aad46c09b[m Merged PR 6836425: Merge RI without squash
[33ma44d24d8b5[m Merge remote-tracking branch 'origin/dmldev' into user/rylai/ri_01_12_22
[33mc07e251cec[m Merged PR 6835169: RI 12/9/21 - 01/12/22
[33m499f1d5fd7[m Quantization of Argmax (#10213)
[33m6f7389bc03[m Merge commit '4af232df0ce89f0f0227ca8bd10ed8808d4398e5' into HEAD
[33m98f85ae05b[m Bump winrt version (#10243)
[33maff96ce081[m remove hardcoded type (#10251)
[33m4af232df0c[m Fix props file overwriting AdditionalIncludeDirectories (#10124)
[33ma099bd454b[m [QDQ] Add shared qdq selectors (#10178)
[33m79d2a0d185[m Dynamic cost model to mitigate high E2E perf variance  (#9833)
[33mfb4dea39e2[m Tolerate cpuinfo init failure (#10199)
[33m4048ed326c[m Update EP Perf Pipeline (#10149)
[33mcb9b0275b6[m Set default quantization weight type to int8 (#10209)
[33mce103ace93[m Amdmigraphx fix build error (#9272)
[33mbe9cc40aa5[m Make some parameters configurable for calibration (#10204)
[33m32ee379f50[m GraphPartitioner.cpp: fixed Merge function to handle duplicated partitions. (#9929)
[33m5cd57bb726[m add load from buffer (#10162)
[33medd1a2cf61[m Add more Java test logging. (#10221)
[33m0f5e82c294[m DirectML EP remove stale code for int64 via int32 double strides (#9959)
[33m1f5b073508[m Minor DirectML EP provider factory comments (#9965)
[33m7d93498e0e[m [FIX] register softmaxgrad_13/logsoftmaxgrad_13 for rocm (#10177)
[33m6e88c11cae[m Refactor QDQ node group selection infrastructure (#10195)
[33md52d3c0052[m Update C/C++ API docs automation to create a PR (instead of push to publish branch) (#10093)
[33m5ebb857501[m Update onnxruntime_unittests.cmake (#10215)
[33mbacae967a2[m Update Cuda to 11.4.2, update architectures, support Ubuntu 20.04 (#10169)
[33m2bbf1ac1e0[m Using better words. (#10210)
[33me7efcc93fe[m [ROCm] update hipify-perl location (#10102)
[33m4ac3277743[m adding definition of concat operator for mapping it to onnx (#10062)
[33mcab4579b83[m remove six references (#9941)
[33m0552a47ec2[m Enable CUDA provider option configuration for C# (#10188)
[33m08f512b25e[m Fix a Win GPU reduced ops pipeline (#10202)
[33m4ab891999a[m fix hardcoded type (#10205)
[33m7b5464ed7b[m aten add_ op supports bf16 (#10084)
[33m34c025109c[m Exclude graph_runtime_optimization_test.cc from reduced ops build. (#10191)
[33m2803a9465d[m Add example of registering custom cuda op as shared lib (#10025)
[33m2078210a1c[m Improve logging for symbolic shape inference
[33m792db33f01[m Enable loading of ORT format model graph runtime optimizations (#9901)
[33m97659495d9[m fix aten view op (#10050)
[33m91f85dfdad[m update Dockerfile.manylinux2014_cuda11_4_tensorrt8_2 to TensorRT 8.2.2.1 (#10167)
[33mc29397ad4f[m Modify the code to get correct ragne for symmetric quantization (#10170)
[33m0c517112c4[m Automate Python API docs generation  (#10116)
[33m230f323600[m add qdq support for LeakyRelu (#10077)
[33m1d3b34cc92[m Add `.git` suffix to github URL. Although github works with both, this is more precise. Having an extension also makes it easy to match with regex, when we want to inject code to reroute traffic to our own git mirror.
[33m7208fcbe1c[m use wasmscalar as default kernel (#9988)
[33m28ce2a5a78[m Re-work hierarchy, fix virtual method overload/hiding (#10160)
[33md5742f3a43[m moving from torch nightly build to stable build (#10150)
[33m3bc91c2151[m Move reduced ops files into build directory (#10030)
[33ma367f0664d[m From Python 3.8 and on you need to explicitly add the current directory for libraries to be loaded from it. Update onnxruntime_test_python.py with that handling. (#10129)
[33m3d6786c92e[m update tensorrt multi gpu pipeline to tensorrt 8.2 (#10141)
[33mceb17f82ff[m Use FusedMatMul When Transpose is Between First Dim and Contiguous Batch Dims (#9734)
[33mf780f06240[m ConcatGrad for OpSet13 (#10109)
[33m05d20343ee[m Remove duplicated constant initializer copies for TensorRT nodes (#10105)
[33mce1a9ca618[m Fix Microsoft.AI.MachineLearning NuGet App failure with multiple binaries copied to same destination (#10076)
[33m7a1bdc2052[m Don't check cache shape when using dynamic axis (#10090)
[33m4e9e01cb3c[m Fix SDL warnings in CPU EP (#9975)
[33mbd4fb4c5da[m Coding style fix. (#10080)
[33mcdbd678192[m Check kMSDomain already exists before registering it (#10078)
[33m12ee2e942f[m add int8_t for Resize (#10067)
[33m4fd85cd97a[m Fix broken link to TRT doc in exception details (#9496)
[33md42feae042[m Add citation file (#10061)
[33mf3c72de718[m [QDQ] Add shared NodeUnit class (#10052)
[33mef36488df0[m Add BeamSearch operator for GPT-2 decoding (#9680)
[33mfab39b4704[m Update optimization level message in perf_test tool (#9972)
[33m102f9b05e1[m Support new symbolic function api from PyTorch with PythonOp (#9880)
[33m93636cbd20[m Reduce ops for DNNL ep (#10056)
[33m44c701192b[m Revert a bad change in bfc_arena.cc (#10057)
[33m6357c12977[m use inplace reshape (#9991)
[33m7922a8c22f[m Optimization Convolution op when using dnnl ep (#10051)
[33m3466ee45a3[m Add hash value typedef. (#9710)
[33m4e73cc83d6[m Fix building DNNL EP with clang (#10014)
[33mb327e89efa[m Standalone TVM Executor Provider (#10019)
[33m16274beb6f[m update TensorRT EP to use TensorRT 8.2 (#9981)
[33mee975de77b[m reorganize quantization files (#10023)
[33m6cdab06255[m Enable argument files in build.py. (#10040)
[33m20f8a06f1f[m Remove OpenMP code (#10032)
[33m8043a9facc[m Bump master version to 1.11 (#9957)
[33m91096781c3[m A small fix to allocators (#10042)
[33m9d9ebd3b85[m Fix some static analysis warnings in the core framework (#10033)
[33me0a0f385bb[m Fix some warnings in mlas (#10034)
[33maf71da0ac6[m Yield op supports bf16 (#10035)
[33m703becd796[m Fix a bug in fusion_embedlayer.py (#10022)
[33m5be0fa13c0[m [DML] Fixed huge bug in ORT_NO_EXCEPTIONS for DML back end, the check is reversed
[33m9e04b7e59b[m Remove memcpy in in-place ATen ops (#9913)
[33ma7c2d1cb09[m bf16 for dlpack (#10016)
[33mcd0af7ad44[m Symmetric quantized convolution kernel ARM64 (#9772)
[33m7e55a942cd[m Add torch 1.10 requirements for rocm (#10028)
[33m6de2a878cb[m [js/react_native] Fix a broken manual build (#10012)
[33m7b63d1102b[m Fix some warnings in orttraining code (#10009)
[33mc82160bbd0[m Add AtenOp at:bitwise_or (#9662)
[33mad99dff298[m[33m ([m[1;31morigin/wechi/prof[m[33m)[m POWER10: Update builtins for DGEMM
[33m5d821b5bd9[m Address null dereference warning in div_grad_impl.cu. (#10010)
[33m777a80fbc1[m Abjindal/eager onnx operators fix (#9968)
[33md0b08af37a[m Implementation of  QAttention for the DNNL execution provider (#10004)
[33m787755328b[m Add s8s8 for depthwise qconv 3x3 5x5  (#10008)
[33mb4434c7694[m Automate generation of C/C++ API docs (#9997)
[33mb000ec91cc[m Add quantization tool and its unittest with s8s8 support (#10007)
[33m7a70d22150[m Change some const to constexpr in unit tests code(#10002)
[33mffdafb2012[m add fallback of s8s8 support on x64 (#9995)
[33m3c79f3055f[m Weaken x86.get_pc_thunk for NDK <= r22 (#9994)
[33m343a76945b[m Fix some documentation errors plus ones generating doxygen warnings (#9993)
[33m4669048b47[m Handle compiler warnings for TRT EP (#9956)
[33me0960d7d79[m Change assert on a null value to an ort_enforce (#9982)
[33mb9909f985e[m [js/web] rename build-def.ts to build-def.d.ts (#9954)
[33mc7e8365e1f[m Resolve security issue reported by dependabot (#9983)
[33m2fdcaffbb7[m add missing test files (#9989)
[33m41fd745996[m Fix build error when using '--build_minimal extended' and '--build_wheel' build.py options. (#9979)
[33ma7abd541c7[m Correct message type (#9973)
[33m42c176b60c[m Update default opset to 14 in ORTModule (#9743)
[33mbc0f2d173a[m enable s8s8 QDQ fusion on ARM (#9961)
[33mcd552e1bda[m Add build.py option for disabling memleak checker
[33m051d005926[m Fix build warnings with VS 2022 (#9967)
[33m0c72f1cd5a[m add copyright (#9943) (#9970)
[33m35cf8b8725[m [js/react_native] npm audit fix (#9876)
[33m0adeb86bfd[m Fix ortmodule for the pytorch model with ort device (#9927)
[33mfb30e9fdae[m Remove /safeseh link option from non-msvc builds (#9744) (#9935)
[33m9e7d52a801[m Update parity_check_helper.py (#9884)
[33mf60a287a64[m Add __x86.get_pc_thunk.bx to avoid dependency (#9955)
[33ma7f649db7c[m Enable proper override using MIMalloc (#9944)
[33m94dc844039[m Merged PR 6743839: Merge latest ORT master
[33mb34b991aea[m Improve reduced ops and types build (#9908)
[33m28cc3b63a0[m Merge remote-tracking branch 'upstream/master' into user/justoeck/merge_ort_master
[33m840212e115[m Enable OneHot kernel for ROCm EP and add Dockerfile for ROCm 4.3.1 (#9656)
[33m63c8889944[m Restore arm64x onnxruntime binaries (#9950)
[33m5e4d58a50a[m[33m ([m[1;31morigin/bahuang/test_branch[m[33m)[m Openvino ep nuget (#9909)
[33ma23cd5b697[m Update Xamarin sample code (#9925)
[33m58728f95a2[m Fix conv quant reduce range option (#9922)
[33m5871ca1cd1[m Comment out unused parameter (#9914)
[33m67a30ef716[m Address some code scan issues (#9873)
[33me613019174[m add s8s8 support for quantized conv and gemm (#9902)
[33md8c71304c1[m Update Dev_Guide.md (#9921)
[33m02aa16e3ea[m QDQ tool modification part3 (#9904)
[33m4ff78aae45[m Merge pull request #9917 from microsoft/user/dwayner/FnsCandyTolerance30696168
[33m5edaa75ef6[m Fix LoadFromStream to not use wss::Buffer internally (#9918)
[33m8db49e3d0f[m add ortmodule and eager mode test (#9888)
[33m6e4c534ce2[m Relax tolerance slightly more for Intel after autopilot run
[33m1c38ceda49[m Add fusion support for Dnnl execution provider (#9897)
[33m06e63218be[m changing commit for windows build for eager mode (#9912)
[33m77e67a6de7[m Add one more example line
[33mef7671b938[m Comment out old lines
[33m912e50f61c[m Add CI minimal build with all options disabled. Fix python binding code if sparse tensors are disabled. (#9898)
[33m5190953f6b[m Merged PR 6728025: Merge latest ORT master branch
[33m2e9dc8a0e2[m Merge remote-tracking branch 'upstream/master' into tmp_merge
[33m5ba4079546[m Merge branch 'DmlDev' into user/dwayner/FnsCandyTolerance30696168
[33m7a3abd863f[m Update WinML model test tolerances for tiny_yolov2 and FNS_Candy
[33m3f5c1e1c58[m Update to include the Xamarin targets for internal ORT builds so the managed nuget package is consistent as both CPU and GPU builds produce a package called Microsoft.ML.OnnxRuntime.Managed. (#9906)
[33m8d88a6ac7f[m add --amdgpu-target=gfx90a (#9820)
[33m00c979db4d[m Update doc for operators/opsets supported by mobile package (#9899)
[33m078782ea3c[m exclude test case from reduced-op build (#9895)
[33m3f82b2d5b1[m Merged PR 6723735: Need to unsquash the last RI to maintain history
[33m73d106e33a[m Merge commit '9345894c823de67f913d907da91dbc07ac322041' into HEAD
[33m175acf08f4[m[33m ([m[1;31morigin/wangye/summarization[m[33m)[m ScatterND supports negative indices (#9739)
[33mc161813217[m Misc InstanceNorm CUDA kernel changes (#9879)
[33m6de79d82c8[m Fix Training Packaging pipeline (#9885)
[33md8a7e1d159[m Merged PR 6718335: RI 11/30 from github
[33m740679d329[m[33m ([m[1;31morigin/user/dwayner/FnsCandyBug30696168[m[33m)[m Abjindal/fix windows ci pipeline (#9883)
[33m9345894c82[m Add build option to enable cuda profiling (#9875)
[33m16bfd3c771[m Cancel transpose optimizer for resize (#9870)
[33m0baf687f2d[m QDQ tool modification part2 (#9720)
[33m57a6f7c205[m Various fixes to fix WindowsAI RI build. (#9877)
[33ma0afd7303d[m add int8_t support for pool operators (#9852)
[33mec9b0ed800[m [python manylinux package] emit warning if missing CUDA/TensorRT dependency causes ld_preload to fail and user tries to register either CUDA/TensorRT EP (#9872)
[33m27e337ed7a[m [js/node] npm audit fix (#9861)
[33mbf716e667c[m layernorm throw error if input has no data (#9837)
[33m9e75ebf0dc[m Remove redundant inline specifiers, sync server IsLittleEndianOrder with runtime core (#9856)
[33m37bf46eb19[m support print in ort eager mode (#9825)
[33m1e9e57df3e[m no fallback when enforcing explicit EP registration. (#9863)
[33ma3ebc5e082[m [js/web] do not use nodejs type 'Buffer' in web (#9839)
[33m6eb0c8d420[m fix build break in release pipeline for Node.js binding test (#9850)
[33m53c43e9949[m WinML RT API: Add PixelRange Metadata to Bind() call PropertySet (#9827)
[33m18fd2cf457[m Fix potential data race with OrtValue usage in Python (#9841)
[33m0ae0f29f14[m [OpenVINO-EP] V3.4 Release with OpenVINO 2021.4.2 LTS Release (#9848)
[33m926109bd63[m Added algorithm for std::clamp (#9797)
[33md012d9fb91[m Fix memset size (#9840)
[33m6749e9fd44[m Cuda instance_norm fix (#9826)
[33m24f3d72b77[m relax atol and rtol for einsum ut (#9842)
[33m8564fc1933[m POWER10: Add optimized dgemm kernel (#9652)
[33mbf5e9a5044[m bumping up ORT_API_VERSION to 10 (#9838)
[33mfb4a8e12fc[m Limit inclusion of Xamarin mobile target frameworks. (#9834)
[33m74ca417c0e[m [js/web] optimize bundle file size (#9817)
[33mbcc6ab29f6[m Trim DataTypeImpl binary size (#9813)
[33m567749b2dc[m Expose IOBinding SynchronizeInputs/Outputs via C/C++/C# And Python APIs (#9823)
[33m8dcd388ec5[m Bump ansi-regex from 5.0.0 to 5.0.1 in /js
[33mc779f2cad5[m Bump path-parse from 1.0.6 to 1.0.7 in /js
[33m88d8d2d02a[m Remove Copy NuGet Package to Azure Blob Store build step (#8991)
[33mefcdbac4e7[m Fix ONNX Runtime Mobile link in js/web/README.md (#9828)
[33m3a85ade511[m Avoid segmentation fault when creating session with TRT EP or OpenVINO EP using python (#9814)
[33m7396689c2b[m Merge pull request #9765 from microsoft/user/dwayner/DML1.8forORT1.10
[33m6856619b18[m Decoder Attention CUDA Op (#9792)
[33m16ddaf564c[m Fix uninitialized warning by some compiler. (#9822)
[33mf28d7eca67[m Disable DML dynamicquantizelinear in backend tests DML Bug 33073263
[33m1b953c6423[m Fix some code defects (#9810)
[33md1b772e09a[m Mark dynamicquantizelinear as broken in DML
[33mba339e667b[m Add training performance investigation script (ONNX graph analyzer) (#9791)
[33mf047be55d4[m Merge branch 'master' into user/dwayner/DML1.8forORT1.10
[33m7e026286ae[m Safe remove quantized inititalier which may still be used (#9788)
[33me520bb5145[m Improve print functions for NodeArg, Node, and Graph (#9801)
[33m9d3c63263b[m symbolic_shape_infer: Improve error message on mismatched types (#9809)
[33m289b1bdc86[m Merge remote-tracking branch 'ado_wai_ort/DmlDev' into user/dwayner/DML1.8forORT1.10
[33m32419974ad[m Merge remote-tracking branch 'origin/master' into user/dwayner/DML1.8forORT1.10
[33me0ffc30a0b[m[33m ([m[1;31morigin/user/dwayner/DML1.8forORT1.10_DML_only[m[33m)[m Update to 1.8.0
[33mafd60a274c[m Fix some places where there were unused parameters when sparse tensors were disabled. Doesn't break in an android/ios build. Does in a windows build. (#9807)
[33mb77a6cda50[m squeeze and unsqueeze operators for the dnnl execution provider (#9798)
[33mdf5eb98b6e[m Bump tmpl from 1.0.4 to 1.0.5 in /js/react_native
[33mfcc167dd47[m fix reshape implementation in eager mode (#9741)
[33m7ea19539f8[m Bump path-parse from 1.0.6 to 1.0.7 in /js/react_native
[33m0556b41127[m Bump react-native from 0.63.4 to 0.64.1 in /js/react_native
[33m6977804804[m Bump electron from 12.0.2 to 12.1.0 in /js/web
[33m3af14fc554[m Updated SoftmaxGrad and LogSoftmaxGrad to support version 13. (#9733)
[33mdc1724b0e2[m Reduce DataTypeImpl binary size (#9783)
[33mf390347c11[m Add CUDA Kernels of RandomNormal[Like], RandomUniform[Like] (#9761)
[33m6284cbe833[m Add TensorShape noexcept for move ops and fix some warnings (#9802)
[33ma2787ca67c[m Merged PR 6688023: ORT GitHub to DmlDev RI
[33m533b20c6ca[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33m8ef6aff734[m Zhalei/dwqconv3x3 5x5 arm64 (#9714)
[33m7242627fec[m Integrate TensorRT into GPU Python package (#9785)
[33m76715ad525[m Delete ioscross code (#9793)
[33m1aa21df149[m Fix issue with debug VS2022 build when python bindings are enabled  (#9794)
[33m191bc518a1[m Merged PR 6676705: Add opset 13 for ops which are unchanged
[33me23892ddbe[m Support disabling support for the optional type in ORT builds (#9745)
[33m9fb3fac5a0[m Enable LearningModel::LoadFromFilePath in UWP Apps (#9790)
[33m3654a5d60e[m Register Custom Symbolic of torch.einsum for ORTModule (#9590)
[33m6545e24b60[m Update mobile prebuilt package ops to add support for opset 14 and 15 (#9717)
[33m20ec48129b[m fix typo in LearningModelDevice.cpp (#9787)
[33m871d3fb839[m Fix a bug in ReluClip fusion (#9764)
[33mb409cbe62c[m Fix incorrect library reference in Python manylinux package for CUDA (#9769)
[33m421e4c03ce[m Update default cast propagation strategy from None to FloodFill (#9713)
[33m9acbfeba09[m Address some code scan issues. (#9752)
[33m99afb87a02[m Update DirectML 1.5.1 to 1.8.0 for ORT1.10
[33mac57afc3a6[m Update ONNX to 1.10 globally in CIs (#9751)
[33m1d03baa8cc[m Openvino ep 2021.4 v3.3 (#9588)
[33m4ca11b05a5[m Remove python 3.10 from rocm docker image (#9749)
[33m1c84621020[m Adding ARM64 depthwise convolution kernel for symmetric quantization (#9655)
[33m9f4e8cf6a0[m Update training pipelines to pytorch 1.10 (#9709)
[33m99257eb8e3[m support build option to include external graph transformers  (#9478)
[33m6e09fc5152[m Implement block wise softmax for reduction dimention > 1024 cases. (#9696)
[33m3d0bd2596f[m Enable creating OrtValues from ID3D12Resources from the onnxruntime C-API  (#9686)
[33m21eb747a0f[m Custom thread creation and join hooks (#9426)
[33m52203e06dd[m Merged PR 6668707: Fix Resize float16 ROI tensor (part 2)
[33m9f69d8bbae[m Disable partial runtime optimization implementation by default (#9748)
[33ma17bdaf725[m Enable JoinModels API in WinML+RT Experimental API (#9746)
[33m3e5d636f6c[m Merged PR 6668481: Fix Resize float16 ROI tensor
[33m5ad6dbb314[m Remove experimental from ORT format namespace (#9729)
[33mf6edf13513[m Implement a Gemm/Sum fusion pattern (#9699)
[33m997266a620[m Add build.py option to disable ORT format model runtime optimization (#9723)
[33m363cb2300b[m Merged PR 6664646: Merge ORT Github and address DMLXP build error from overridden GSL version
[33m2a9208188f[m ORT TensorShape changes to avoid build error in tools overriding GSL version
[33mb9c4b2e000[m Merge remote-tracking branch 'upstream/master' into user/jeffbloo/MergeOrtGithub20211101
[33m93e239747f[m Construct valid graphs for ONNX checker for IR version < 4. (#9665)
[33m32c896df6d[m Add DynamicQuantizeLinear to DNNL EP (#9620)
[33m559adbb534[m Replace deprecated PyEval_CallObject() call with PyObject_CallObject(). (#9737)
[33m724009289b[m Fix Issue #9671  (#9691)
[33m03f9d77e17[m Fix index out of bound bug of generated Gather (#9673)
[33me6f0fdd653[m Strip AMD libraries bundled with Python package due to libonnxruntime_providers_rocm.so change (#9679)
[33macb5459268[m Random CPU kernels should respect global seed (#9726)
[33m9d84811fb6[m fixing pypi pipeline for release (#9716)
[33m962feff7f1[m Update linux-ci-pipeline.yml to run debug unit tests. (#9722)
[33m31dc768e07[m update ONNX Runtime Web CI to use same script for package versioning (#9698)
[33m1541784f6c[m [python api] align api with other language bindings' treatment of explicit provider registrations. enforce use of providers param in python InferenceSession when execution providers other than default CPU are enabled. (#9712)
[33m517fff0a39[m Add opset 15 support for NNAPI/CoreML EPs (#9711)
[33madf98feb2c[m ATenOp Support for BCEWithLogitsLoss (#9670)
[33m1b70a14c51[m Remove usage of wstring_convert (#9251)
[33m3db2390dab[m QDQ tool modification (#9616)
[33me65f284476[m [js/web] Support WebGL for ort format models in benchmarks (#9661)
[33mde018f58e8[m Update manylinux build scripts (#9701)
[33mbdc279a7ed[m Use the same allocator following Pytorch (#9697)
[33m229c9a4e1c[m Added Trilu CUDA kernel. (#9633)
[33m6420530b3a[m fix the mkl dependency for eager mode (#9702)
[33ma70ae24475[m Add QDQ::Selector::Select to use const GraphViewer instead of mutable Graph (#9621)
[33m65590b049c[m Expose an API to query the CUDA compute stream to launch a custom kernel (#9141)
[33mc579ebfbc3[m change a for iteration (#9678)
[33m53afaefe3b[m Refactor Windows CI pipeline yaml files (#9672)
[33m24e35fba32[m Change TensorShape to typically not allocate heap memory (#9542)
[33m13e64f8ff7[m Remove all warnings C4800: Implicit conversion from 'int32_t/int64_t' to bool. Possible information loss (#9535)
[33md9c42acec1[m Merged PR 6646876: Merge ORT Github master to DmlDev
[33m7e207ba3be[m Use ORTMODULE_ONNX_OPSET_VERSION to modify the opset version in OrtModule (#9529)
[33m1151c661eb[m Add gi overload (#9690)
[33mf8ecf10cfb[m Merge remote-tracking branch 'upstream/master' into user/jeffbloo/MergeOrtGithubToDmlDev20211107
[33mc6fddb263f[m Add Node.js binding support to packaging pipeline (#9577)
[33m1cbbafdbe0[m Change the default value of onnxruntime_DISABLE_RTTI (#9674)
[33m3e5dbfd94f[m Increase binary size limit and publish binary size data even if limit is exceeded. (#9675)
[33mdfe4d0a330[m Abjindal/eager windows ci pipeline (#9587)
[33m74dc48f61c[m Remove python 3.6 from macos pipeline (#9602)
[33mee167bd078[m Optimize _TileKernel for non-memcpy case (#9648)
[33ma355bcbd73[m Clarify cgmanifest.json update process. (#9664)
[33m90de3c8e7c[m Update MLOperatorAuthorPrivate.h (#9575)
[33mbbeceb7541[m Support optional type in ORT (#8339)
[33m2fb03769bc[m Updated OperatorUtility to avoid C2672 and C2783 (#9651)
[33m1128bf282d[m Updated cpuid_info.cc to fix PVS-Studio error C1012 (#9581)
[33mddb4c05852[m Save graph runtime optimizations for minimal build (#9508)
[33m71a1a7b471[m Enable building winml with --build_nuget (#9632)
[33m9cedb12c89[m Add App Center e2e test to Android package (#9653)
[33mc8151b4037[m Add percentile method for PTQ (#9342)
[33m2406a425a7[m Move the common part of Windows CPU CI pipeline to a template file (#9650)
[33m15867dcc08[m enable prefast check with orttraining win pipeline (#9638)
[33m6ff02b04a8[m Add Java build/test dependancies JUnit and Google Protobuf Java to cgmanifest (#9641)
[33m230099e482[m Make ORTModule serializable (#9634)
[33m3a1b4045c9[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m51f84a0330[m support quantization of empty tensor (#9640)
[33m4644f8bc2c[m refactor profiling logics (#9567)
[33m19804876d9[m Updated data_types.cc to avoid warning C4946 (#9611)
[33me11fde0179[m libonnxruntime_providers_rocm.so and libonnxruntime_providers_shared.so are not included in python package. (#9618)
[33m020ec9c0f5[m [DmlEp] Added missing include to DmlOperator.cpp to its own header (#9576)
[33m88f61a1b2d[m [DmlEp] DmlEp acknowledges ORT_NO_EXCEPTIONS (#9622)
[33mf41396eff0[m Small addendum to #9624 (#9639)
[33m1240c595a9[m Fix a couple of bugs with how memory pattern planning is enabled/disabled  (#9624)
[33mc1112813e7[m Added missing _In_ to ort_apis.h to be consistent with its cc file (#9557)
[33m5247247b7f[m Add Resize Handler for Transpose Optimizer and revise Layout Transformation API (#9607)
[33md203cdf132[m  Check output edges in QDQ (#9600)
[33mccf1b8ad00[m [DmlEp] Avoid warning C4495 (#9533)
[33m034f297884[m [DmlEp] Avoided warning C4458: declaration of 'X' hides class member (#9583)
[33mc315d1b3cd[m Always enable ORT format model loading. (#9586)
[33m5c56fa0def[m Miopen conv grad (#9574)
[33ma07da457d1[m Merged PR 6622182: add back change history that I lost with a squash commit
[33m6a2d709db4[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33m6c236fd939[m Merged PR 6622174: merge latest onnxruntime into dmldev
[33m79436a2d5b[m Avoided warning C5038 (#9543)
[33ma3e4d77b35[m Replace wstring_convert with std::wstring (#9614)
[33mf7774a91d6[m Add api-ms-win-core-com-l1-1-0.dll, shlwapi.dll, oleaut32.dll to delay load (#9619)
[33mfa4658e8a9[m Move to XCode new build system if building on Mac using XCode (#9617)
[33m57491b6f93[m Add App Center test for iOS package (#9605)
[33mb5f7bb7d10[m Update ONNX (#9462)
[33m7744cc1013[m [DmlEp] Make DmlEp compatible with Clang for EPIC (#9585)
[33meb2612b588[m Remove netcoreapp2.1 target as it is EOL and out of support. Attempting to use it with VS now causes unit test run failures. (#9603)
[33m173e538b80[m Update mac-ios-packaging-pipeline.yml
[33mcc73bcc243[m Suppress component governance component warnings for ios
[33m1731f0080a[m Update attention_cpu_base.h to suppress static analysis warning
[33m9c15c68ed4[m Enable fallback when forward fails due to non contiguous tensor (#9369)
[33ma01a3f2552[m Add more statistics in transformer profiler (#9578)
[33m85874bb315[m embed layer fusion gpt2 (#9336)
[33ma555740708[m Attention fusion: update uint8 tensor parsing for ONNX upgrade (#9564)
[33m17cf39a964[m Clean up unnecessary codes in softmax and hardmax kernel (#9580)
[33me8268c9a18[m Add Transpose Optimizer and modify nhwc optimizer to use it. (#9284)
[33m87b1fddd97[m Add Linux/MacOS ARM64 support to nuget packaging pipeline (#9570)
[33m2d44bd525b[m DML functions always returning a value (#9485)
[33m8dd4d207e2[m Merged PR 6606929: RI 10/26 from github into fork #2
[33ma2b3e6bb23[m Remove pointless assert. (#9571)
[33m4e76360261[m Prevent PySparseTensor form being garbage collected if we have an outstanding OrtValue (#9540)
[33maa76520e60[m Update macOS build agents to macOS 11 (#9562)
[33m5d5c03bcdc[m Fix opset version change by not using copy of global constant (#9393)
[33mb5a652c578[m Add Xamarin support (#9436)
[33m12f216aab5[m Bug in DmlOperatorResize.cpp with m_inputDimensions (#9456)
[33m9639eded4b[m Missing `#pragma once` in dml_provider_factory.h (#9457)
[33m1efdbff1a3[m Fixed compiler error in Clang (for Win64) for ExecutionProvider (#9482)
[33m0301f401ee[m Cleanup unnecessary opset_version arguments (#9558)
[33mc79307e7b4[m [js/web] support opset-13 of softmax (#9493)
[33md079e0d48f[m Fixed Clang (on Windows) compiler error with `#pragma`'s (#9484)
[33mc54ad0dd0b[m POWER: Add Dgemm kernel for POWER processor (#9459)
[33m90555bf96d[m [node.js binding] enable CI for macOS arm64 (#9532)
[33mc1b0f924b7[m quantization tool better support operator when subgraph is enabled (#9463)
[33m33ef1d7700[m disable inner parallel for global avg pool as normally they are small (#9487)
[33mdf7a5342a5[m Upgrade com.diffplug.spotless to 5.17.0 (#9546)
[33mf39821adbc[m Fix a bug in CMakeLists.txt when handling NO RTTI (#9547)
[33mda15f5fc2f[m change cmake condition to prevent WCOS fom linking advapi32 (#9500)
[33m542f1a9737[m Cleanup some whitespace and capitalization for set (#9504)
[33m08dd8a0a02[m Merged PR 6604943: RI 10/26 from github into fork
[33ma036cc6d4b[m Fixing bugs in ORT_NO_EXCEPTIONS (#9479)
[33m1aabba7120[m Avoided warning C4458: declaration of 'X' hides class member. (#9541)
[33m7dad90b200[m Merge remote-tracking branch 'upstream/master' into HEAD
[33mf29057c7c0[m Added TanhGrad. (#9507)
[33mb125446f9c[m Optimize python overhead of APEX amp (#9447)
[33m27ad20df23[m Add QDQ support of Resize to able to fuse it into a quantized Resize (#9476)
[33m0270ff7951[m Minor import fix (#9538)
[33mf92b8e2ac8[m Clean up optional-lite references (#9534)
[33mbf4c3fa3d6[m [node.js binding] aggregate binaries for multiple platforms in single NPM package (#9501)
[33mfb4f7dbbb7[m[33m ([m[1;31morigin/bert_qdq_trt[m[33m)[m Call ATenOp for ReduceSum on ORTModule (#9471)
[33m651955d3c9[m CUDA: Enable parallel compilation (#8974)
[33m39d1b9e1c1[m Fix bug in Slice helper when dim value is zero (#9492)
[33mdbe1b57a71[m Update thread_utils.cc
[33ma79d375d24[m Added fixes for Clang on Win64
[33m9335cf102a[m Deleted duplicated "core/graph/function.h"
[33md608504438[m Don't use legacy mode for protobuf (#9498)
[33md83adaaf9f[m Remove optional-lite (#9424)
[33m3ed8ade675[m Use SafeInt for malloc related computation (#9503)
[33mbeddbdec5a[m[33m ([m[1;31morigin/user/sheilk/add-native-component[m[33m)[m Fix PythonOp exporter (#9318)
[33m5adf175847[m pad shape 0 is not allowed in edge mode to comply with latest numpy (#9488)
[33md2d480a0db[m Allow None As Autograd Context (#9315)
[33mb64b2d48f3[m Move iOS e2e test to XCUITest  (#9422)
[33m7f2f56633c[m Fixed implicit conversion warnings (#9481)
[33m49b66c7486[m NFC: Normalize whitespace around if statements in CMakeLists.txt (#9464)
[33mca7116ca3e[m CUDA EP's ResizeImpl now uses functors, hipify for ROCm EP (#9466)
[33m66ceb6926d[m rehipify ROCm EP files under orttraining (#9443)
[33mff23b9ff55[m Avoid cudaStreamSync at the end of Forward/Backward (#9470)
[33m5797bd6db3[m Remove one unnecessary deepcopy in unflatten_user_output (#9353)
[33m4028e51e7e[m Update the compatibility of ONNX Runtime Web (#9444)
[33m1249c7c29e[m Resolve issue when running Yolov4 on DNNL EP (#9355)
[33m9fc53df33a[m Only add aliasing to targets if the corresponding package was found (#9404)
[33mf1123c2fb3[m Fix whitespace and style in concat.cc (#9452)
[33m89a22fb641[m Add TopK to ROCm EP (#9391)
[33mf8acc6d0e8[m Add NonMaxSuppression and RoiAlign to ROCm EP (#9394)
[33mc33391329a[m Add QuantizeLinear and DequantizeLinear to ROCm EP (#9401)
[33m406f1629c1[m Remove Featurizers code (#9300)
[33me983f37121[m Bifurcation detector for aggressive decoding (#9432)
[33m20eaed43e5[m Ignore all string inputs to ORTModule AB#1310803 (#9344)
[33m4698b73725[m Fix output shape description of Attention op's schema (#9406)
[33m3873885316[m add missing atomic include (#9440)
[33m52c53e396d[m hipify tensor/gather_nd_impl.cu (#9392)
[33ma2ba923ac7[m hipify fast_divmod.h (#9400)
[33ma8e2e8d76a[m hipify tensor/transpose.cc and tensor/transpose.h (#9397)
[33m757bc66720[m Set cuda version to be None instead of an empty string (#9435)
[33me22920d954[m[33m ([m[1;31morigin/user/dwayner/MvnWarning[m[33m)[m Update ORTTraiing frontend codeowner (#9427)
[33mda3dd398c5[m Kernels for QLinearConv with symmetrically quantized filter (#9323)
[33m5da4e07daa[m Make FusedAdam mathematically equivalent to Transformers AdamW (#9343)
[33m5b65f1cb44[m fixes SDL Native Rules warning in Node.js binding CI (#9402)
[33mf60e603022[m Add support for DmlExecutionProvider for transformer profiler tool (#9380)
[33m0824207c0f[m Add Dev Guide to transformer optimizer (#9329)
[33m6ecb990fae[m Update win-ci-pipeline.yml
[33mb130a7b715[m fix MSVC micro benchmark build warnings (#9373)
[33m59dfab59dc[m Fix integer overflow for large step for Slice OP (#9376)
[33m901c7de918[m [js/web] remove webgl from default fallback list (#9374)
[33mf05c285a58[m Exception when duplicated autograd.Function name detected (#9351)
[33m74eaaad768[m [js/web] Support opset-13 for squeeze, unsqueeze, maxpool, pad, cast and clip (#9249)
[33mc8789d3047[m [ROCm] static re-hipify of CUDA EP to ROCm EP, now a shared provider (#8877)
[33m87e726d1a0[m Abjindal/merge eager with external custom ops (#8986)
[33m23700a15a0[m Abjindal/eager windows build (#9326)
[33m3e879aab6b[m work around ucx in rocm ci Dockerfile (#9360)
[33m11f0081c1e[m Remove tensorflow, tf2onnx from the list of dependencies for the documentation (#9221)
[33m22e3f8bf54[m Refactor TrainingManager.forward (#9354)
[33m851554536c[m [DML EP] ConstantsOfShape - Empty Output and EinSum - Optional Parameter (#9361)
[33m5ee47e3ffa[m legacy_megatron-lm/deepspeed_ZERO1&2 FP16_Optimizer wrapper (#9184)
[33m4771256be3[m fix to avoid quantizing attention with varied q,k,v sizes (#9357)
[33mba0cca96f0[m Hooked up eager logging to ORT default logger. (#9340)
[33m905fe36599[m Add Conv and ConvTrans to ROCm EP (#9338)
[33mbccd09c688[m Serizalize model only once to reduce backend preparation overhead (#8270)
[33me8ba5145ce[m Add  Transpose, Reshape, Pow and  LeakyRelu ops to DNNL  execution provider (#9180)
[33m1527af3e30[m [js/web] deduplicate test cases between opsets (#9327)
[33mfb31701f7e[m Fix bug in determining default slice axes (#9328)
[33m510b747821[m w (#9319)
[33mf0bc35c4ba[m fix a hardcode type (#9337)
[33md5c5c4fa50[m Handle implicit subgraph inputs required on different devices in Memcpy transformer (#9299)
[33m48737091c0[m resolve the provider options before create training session in orttrainer (#9199)
[33m52c021d1f3[m Fix export of aten op for Max and Avg Pool 2D (#9330)
[33mf9cf62912a[m Add same_shape case for BiasDropout (#9188)
[33m2f1204a5d5[m [js/web] Enable wasm profiling and preserve function names in profiling (#9314)
[33m787dcb7dbc[m Support extra addition before softmax in attention cuda kernel (#9205)
[33m03276527b3[m Fix typing error (#9316)
[33m79e736ed25[m Make onnxruntime::Status nodiscard (#9279)
[33mda56f01ac2[m Fix bug in ReduceSum with noop_with_empty_axes (#9301)
[33m7b61bca6df[m Fix inclusive sum overlfow when applied on int8_t buffer in Compress (#9295)
[33m29379db432[m Added SigmoidGrad schema and kernels. (#9244)
[33mcd65a8089e[m Optimize Variadic Elementwise Ops (#9186)
[33m5f5f28bf14[m Fix bug in allocation planner while planning location for initializers (#9306)
[33m68601fc296[m error handling ffor eager mode's data transfer (#9261)
[33m70cf61fa84[m disable bart-l for now (#9305)
[33m72c4cea9e6[m [OpenVINO-EP] V3.2 Release (#9232)
[33m7166586d7e[m Enable SkipCheck by default (#9215)
[33m88d5023885[m [js/web] always use new data dir for ort web E2E karma tests (#9303)
[33mc002dc86a3[m set mpi group  init flag after add group (#9293)
[33m4f4875b0e8[m Add   "workspace:   clean: all" to anybuild build yaml file
[33me2b1852eec[m Build: respect onnxruntime_PREFER_SYSTEM_LIB for more things (#9181)
[33m52d067402a[m Fix all-or-nothing fallback for bad ORTModule init (#9277)
[33m510b58c877[m Increase AMD CI pipeline timeout to 120 min (#9280)
[33m334980e016[m Delete nocontribops pipelines
[33mbcdb411c8d[m Implement FusedAdam for ORT adapted from DeepSpeed (#9266)
[33ma4d53c4ab5[m fix training distributed ci failure (#9273)
[33m35c2102cfa[m Fixes for GatherND, Multinomial (#9143)
[33m0b77c9ca7c[m Cleanup function definitions of contrib ops (#9265)
[33mccf8ef6760[m Merged PR 6531168: Unsquash merge on DmlDev
[33m21e29cf17b[m Merge remote-tracking branch 'origin/DmlDev' into user/ticastro/fix-ri
[33m6e2f66ee9c[m Allow custom exporter args + bug fix (#9242)
[33m67ff339df7[m fixed a profiler.py bug (#9231)
[33m113edbda64[m Add bf16 specialization for IsDataType (#9254)
[33m8f6fd014e4[m Force Windows AI NuGet pipeline to use Windows SDK 19041 (#9255)
[33m9fe09cb72a[m Update dockerfile readme (#9241)
[33m20b9390d1d[m Merged PR 6524907: Fix merge conflicts from public ORT to WindowsAI ORT
[33m335283d299[m Fix merge conflicts, merge from public onnxruntime
[33m11a391a88f[m Port ARM64x support (#9230)
[33m60bbdf1403[m[33m ([m[1;31morigin/sukha/onnx_ms_1_prophetnet[m[33m)[m Remove unused NodeArgs in Graph::Resolve (#9213)
[33m8adb9ab85a[m fix CodeQL warning for path-injection (#9243)
[33m45399d5ace[m Remove TORCH_WARN to avoid torch string related operations that take up time (#9238)
[33mbe4d887439[m Fix ONNX exporter call with latest API for ORTrainer (#9228)
[33m448325b254[m [js/web] name ort web for consistency (#9240)
[33mc23a216900[m MLAS: fix AVXVNNI+Linux qgemv kernel (#9234)
[33me2d779246a[m [wasm] remove deprecated prefix 'EXTRA_' in emcc flags (#9211)
[33mc6cb49c5a1[m DirectML.dll load fails when executable path contains Non-English characters (#9229)
[33m634bb5ede0[m fix CodeQL warning 'Remote property injection' (#9224)
[33m8c57d51928[m support WebAssembly SIMD for qgemm (#9191)
[33me79be39081[m LayerNormGrad function body and LayerNorm inference/body fix (#9160)
[33me1b84eefcc[m Revert "Revert "linux trt package pipeline (#7537)""
[33m5326397a6a[m [iOS] Facilitate usage of pods with custom builds (#9216)
[33mceb51dda4a[m Support external torch cpp extensions on ORTModule (#9223)
[33mffca0b777b[m Patching cuda profiler with enhancements (#9214)
[33mbeab1ef1bb[m Merged PR 6516718: [DML EP] Direct INT64 support for indices tensor for TopK/MaxPool/MaxUnpool
[33mdae5b1d4ac[m Merged PR 6515621: Autopilot build ORT clamp_cast on *64-bit release
[33m4a1b386f7c[m[33m ([m[1;31morigin/wangye/fluencyabart[m[33m)[m #9182 removed the `--is_store_build` option but one place where that was used was missed. (#9219)
[33m278928a102[m Added a test case for python gradient builder. (#9207)
[33m4f10024868[m Fix shape inference issue in Gather op (#9147)
[33m39c2d76c4e[m Merged PR 6512710: Code clean up in DmlOperatorPadding
[33m8bcd076f3d[m Merged PR 6511109: Register ONNX operators for int64 in DML EP
[33mb606005858[m Revert "linux trt package pipeline (#7537)"
[33m058108bef9[m Execution Provider Profiler (#8406)
[33m6f580f07de[m Switch AMD CI pipeline to use environment image from onnxruntimecibuildenvironment (#9206)
[33m1104e8d3e5[m Linux Anybuild build pipeline (#9091)
[33md3f859fe30[m Dropout Vectorized Kernel  (#9157)
[33m1b0816859f[m Only wrap sub-modules which can be wrapped as ORTModule (#9021)
[33m1a71687102[m Add QDQ for output of node (#9134)
[33mf16bb37fae[m make uwp store apps link to statically-linked crt desktop builds (#9182)
[33mc30cc9190a[m Change the agent pool for orttraining-distributed pipeline (#9179)
[33m9fda95fec9[m Change keepdims of ReduceMax/ReduceMin to always 1 when using quatization calibration MinMax approach (#9167)
[33mfd91bf91c9[m Print full stacktrace exception when exporter fails (#9169)
[33m39dc6ea8a3[m Fix to_dlpack Failure on PyTorch-1.10 (#9151)
[33m0888c6cc59[m fix bug introduced by PR9130 (#9166)
[33mddafe50199[m Fix Android build break after Virtual Environment update to 20210919  (#9163)
[33mbde16eea68[m Cleanup USE_TENSORRT macro (#8593)
[33m6e83392ff1[m Bump up TVM version to avoid conflict with existing one (#9159)
[33m4934455ab6[m Bumping up to 1.10 (#9006)
[33m4e5bc8365b[m Add Paddle2ONNX to Versioning.md (#9067)
[33m267fb898e3[m Added code to support Softmaxgrad for DNNL EP (#9022)
[33m675ea9b305[m Merged PR 6486412: Register ORT DML ONNX operators for int64
[33m1db21da5ae[m Replaced onnx build with pypi installation (#9139)
[33m153767bab4[m Add internal determinism flag configuration for ORTModule (#9074)
[33mb175f98dcc[m Do not generate nuget symbol packages on Linux (#9131)
[33m4df94a631d[m [NNAPI EP] Fix MaxPool error using uint8  (#9129)
[33mf7dedc9002[m Fix default initialization value in C API header (#9126)
[33m02b9213736[m Fix a bug for Openvino Python binding (#9130)
[33mdae37dc946[m Fix S360 issue by using "use strict" for javascript code. (#9128)
[33m49b329e266[m [js/api] add typedoc and revise comments (#9077)
[33m750e2e0481[m [js/web] check session ID in releaseSession() (#9105)
[33m5e197698b8[m Fuse attention for BERT without num_heads, hidden_size (#9108)
[33m47888392ab[m[33m ([m[1;31morigin/wangye/stream[m[33m)[m Fix nightly CI pipeline to generate ROCm 4.2 wheels and add ROCm 4.3.1 wheels (#9101)
[33m23e9c0a7f1[m move quantization examples to onnxruntime-inference-examples (#9107)
[33m6ae5f7a244[m C API Docs - Add build instructions (#9106)
[33mb876e5675b[m C API Enum Name Fixes (#9092)
[33m0183492931[m simplify Web CI pipeline (#9094)
[33m438175cb34[m Build shared host protoc in iOS CI pipelines (#9087)
[33m7fc28cd539[m [OpenVINO-EP] UEP v3.1 Release with OpenVINO 2021.4.1 (#9081)
[33m280e79463a[m FIll in more documentation (#9088)
[33m26509465f0[m Add default C++ initialization to OrtCUDAProviderOptions (#9064)
[33m12515552d1[m Remove cpuinfo from WCOS builds (#9076)
[33m498461485f[m optimize WebAssembly CI pipeline (#9058)
[33m4828d2ebb1[m MLAS: port aarch64 sgemv kernel to Windows ARM64 (#9071)
[33mbee5c26580[m Add CPU_ONLY runtime option to NNAPI EP (#9066)
[33me758870b18[m Upgrade ROCm CI pipeline for ROCm 4.3.1 and permit run inside container (#9070)
[33ma05e32803a[m Fixing MORE mlas unittest failures in POWER (#8673)
[33m273494ee9e[m Ensure ms-experimental domain Audio Ops build in mac pipeline  (#8857)
[33m98ac341c5b[m Filter nones from ctx saved tensors (#9063)
[33m4930320647[m Delete linux-pytorch-custom-ops-ci-pipeline.yml (#9023)
[33m0270ab17c5[m Set onnxruntime_DISABLE_RTTI to default OFF (#9049)
[33m32366fea02[m [Objective-C API] WIgnore clang documentation warnings from C/C++ header usage. (#9057)
[33m3ec3e9f705[m Add t-test to compare experiments in GPT-2 mixed precision conversion (#9042)
[33m7d28b596f4[m Add function-body to opschema of FastGeluGrad (#9028)
[33m4322f7e647[m Fix ROCm wheels CI pipeline break by installing latest protobuf from source (#9047)
[33mcf70635d2a[m Add Android executable drop in the Package pipeline (#9050)
[33mbe80698698[m [js/web] a bugfix and add tests for wasm proxy worker (#9048)
[33me574be4a53[m  [C API Docs] Add docs for run options tag/log level accessors/modifiers. (#9045)
[33m6036a6b915[m Add type int64 for Equal, float types for ReduceSum (ROCm) (#9010)
[33m9174cbe3d5[m Optimize CUDA Kernel for 3D and 4D Transpose (#8928)
[33m5969d576e5[m Revert "disable half2 kernel by dfault (#9034)" (#9044)
[33m34f37d2920[m Disable fallback for ortmodule api tests (#9018)
[33mc709380c52[m Add full iOS job in package pipeline (#9036)
[33m1422a9ba6b[m Remove previous temporary fixes and address TODOs (#9020)
[33m011cb8fd48[m Fix Where op type reduction processing (#9033)
[33ma1021a1cf4[m Add BatchNorm kernel for ROCm (#9014)
[33me83cc534d4[m Fix cmake POWER10 detection
[33mc674343d94[m Remove document text from error message in a couple of ops (#9003)
[33mc3321b1778[m Fix NVTX profiling so it can run in the shared CUDA provider (#9035)
[33m289999af35[m disable half2 kernel by dfault (#9034)
[33m8eb6546e8e[m enable eager mode with ortmodule (#8961)
[33m29d6573f3d[m Increase timeouts for Mac CI builds. (#9024)
[33mb3c2725862[m fix cpuinfo compilation flag usage (#9029)
[33mce7b12bf5d[m Added new fp16 allow/safe opcodes in PropagateCastOps (#8964)
[33m31af88c0bc[m Update cross_entropy_loss symbolic for new argument from upstream torch (#9007)
[33mff66cfdfa6[m Enable linking in exception throwing support library when build onnxruntime wasm. (#8973)
[33me5ee0b435d[m Attention Fusion for GPT-2 from Megatron (#8987)
[33m57b7ab56cd[m Adding async fetching for webgl backend (#8951)
[33m5145fa236f[m [js/web] fix ort web e2e test (#9025)
[33m2439ced3ec[m API Documentation (#8948)
[33m6412c6a362[m do not add pkg wheel entry to the index html file if it already exists (#9004)
[33me357022362[m Remove onnxruntime team from CODEOWNERS (#8954)
[33m00fbc3b0bc[m Instruct dockerfile users to do submodule updates
[33md78e90d1af[m Adding preprocessor checks for torch version during torch cpp extensions compilation (#8989)
[33m0367e1f1c2[m Update Nuget Packge Pipline to CUDA11.4 and TensorRT8 on Windows (#9000)
[33md209fe29b9[m custom autograd func memory refinement  (#8993)
[33md39959172f[m Fix fuzz testing build blocking release. (#9008)
[33m1533f574e4[m Add full Android job in package pipeline (#9009)
[33mc20cb766be[m Optimize sequence type usage on CUDA [3/n] (#9002)
[33m2e8792ca42[m [js/web] fix karma launch with chrome headless (#8998)
[33mec63d10303[m add model local function support (#8540)
[33mb7b42e0c5d[m fast reduction for reducemean (#8976)
[33m1c872f9d74[m Fix issues in TensorRT EP (#8996)
[33m6fbd0a8233[m Change cmake_cuda_architectures to double quotes (#8990)
[33m5ae4c54ab8[m Fix bug for validating GPU packages (#8997)
[33ma30d9f5317[m fix windows gpu pipelines that use cuda 10.2 (training, reduced_ops and 10.2 validation) (#8994)
[33m450524359e[m[33m ([m[1;31morigin/jingywa/nlrv5-finetune[m[33m)[m [js/web] WebAssembly profiling (#8932)
[33m0193490cbf[m ReduceMin - add int64 cuda kernel support for opset12/13 (#8966)
[33m91c15843cd[m[33m ([m[1;31morigin/edgchen1/binsize_base[m[33m)[m Fix a directml python packaging error (#8981)
[33me2194797a7[m bumping up to version 1.9 (#8982)
[33m00eca42413[m make_policy(SET CMP0104 OLD) (#8793)
[33mb7971575f8[m Fix python manylinux to not load cuda if it fails to load dependencies (#8882)
[33m0bb56a18cf[m Add TRT header file to ORT GPU nuget package (#8962)
[33m3be96f8a15[m fix: import error in TrtTable::Dict method (#8940)
[33m5d47b2e431[m Add Einsum and Reciprocal op support in symbolic shape inference (#8931)
[33m60c98a86b7[m CMake file changes for macOS universal2 support (#8953)
[33ma9776d1c70[m Add QDQ model support in TensorRT EP (#8969)
[33m53eb79f9f6[m Gemm/Transpose fusion - additional pattern coverage (#8941)
[33meebcc20f10[m Add netstandard2.0 framework to nuget managed package. (#8960)
[33ma0c9408f0d[m Make TRT Version Configurable  (#8864)
[33m1f576e1766[m Detect necessary files inside GPU packages (#8955)
[33ma7f5bd226b[m retarget torch181 to torch182 (#8947)
[33m0cc2909573[m Auto forward non method attribute lookups to the user's model and bind custom methods to ORTModule (#8798)
[33mc343f7cb43[m Add Algorithm Search for ConvGrad (#8613)
[33m91f05f387a[m Update embed layer norm fusion to work with transformers v4.9 (#8914)
[33me348929019[m Minor cleanup from #7592 (#8952)
[33m5f30be3e92[m Exclude training support from BatchNorm in minimal build (#8939)
[33m47435311f4[m Include pytorch_export_contrib_ops in inference builds (#8878)
[33m06bb2ec561[m ignore direnv configs (#8861)
[33mfe7f30aa14[m Enable all-or-nothing fallback by default (#8911)
[33m1a34775fe9[m Fix the benchmark code (#8926)
[33m6490191f58[m Fix non deterministic of --input_int32 of transformer optimizer (#8927)
[33m7647caa520[m update Tensorflow_Tf2onnx_Bert-Squad_OnnxRuntime_CPU.ipynb (#8898)
[33m4570d85f20[m Move setdlopenflags calls into _pybind_state.py (#8916)
[33mf711d8992a[m Not to calc memory for inference (#8935)
[33mfbb6f0f599[m Fix an error in Nuget pipeline caused by merge conflict
[33mb058dee648[m Fix a couple of issues mentioned in the PR comments. (#8936)
[33mddbc8bc5fc[m Fix CPU Xor implementation (#8934)
[33m1985616262[m Trim InferenceSession binary size. (#8917)
[33m332c2ba4f4[m [js/web] Integrate ONNX Runtime Web CI with BrowserStack (#8859)
[33m757e9e6df7[m do not post cuda version mismatch warning if cannot find local cudart version (#8924)
[33mf126a12699[m decouple pytorch from onnxruntime training build (#8815)
[33m9467f511ac[m Disable some ORT graph optimizers in offline transformers optimization tool (#8923)
[33m225439193e[m Optimize Concat and Split on CUDA to eliminate host-to-device copies when sizes are all the same (#8833)
[33m858989293d[m Reduce binary size of strided copy used by Concat (#8913)
[33m9e661b64ae[m Fix cast propagation to not change casts from bool type. (#8925)
[33m6299a60bf8[m Nuget: splitting PDB files to a separated package (#8903)
[33m00b0a9c127[m Add hugging-face models loss curve and performance guards to ROCm CI pipeline. (#8915)
[33m43d6951fa5[m Add warning message for combined trt +cuda python pkg (#8906)
[33macd9db7fad[m[33m ([m[1;31morigin/validate_gpu_nuget[m[33m)[m Fix location planning for initializers used only in nested subgraphs (#8642)
[33m4dc0ddf606[m support register external ep lib information (#8897)
[33m3eb08d4dc7[m custom autograd func memory (#8901)
[33mfeb747173e[m [js/web] Update browser support table (#8900)
[33m8404a2d011[m Add NNAPI E2E test for Android java package (#8912)
[33ma9a0d3f6fa[m Update min supported macOS version to 10.14
[33m70ca03d491[m Correctly set the skip check flags for ORTModule (#8891)
[33m69ab4670f7[m CUDA UpsampleNearest performance improvement (#7592)
[33m129722db37[m Add android binary size monitor back (#8904)
[33mcd4b9f7753[m Fix EP in transform (#8909)
[33mdc75a135c8[m Add elementwise operators to DNNL execution provider (#8899)
[33m2e37fe3f68[m Fuse HardSigmoid with conv. (#8674)
[33m206537936f[m [js/web] enable proxy worker for wasm backend (#8862)
[33m33c0b3e94b[m Perf test fixes (#8863)
[33mb7129305be[m [OpenVINO-EP] UEP v3.1 Release with OpenVINO 2021.4 (#8892)
[33m7659148d9f[m Avoid round-trip copies for "pass through" subgraph inputs (#8702)
[33m42ba0c5931[m output related packages (#8886)
[33mf6e7cd8050[m remove existed dir for output external data (#8887)
[33ma171d13b19[m Add a formula for layernorm parity test (#8888)
[33mc6d9426ef2[m Add binary size reporting back (#8883)
[33m868c8af9ac[m Abjindal/eager mode pipeline (#8870)
[33m6df4e293ff[m Remove unused code in tools/ci_build/github/azure-pipelines/nuget/templates/gpu.yml
[33m7cd46cb9c4[m Fix a problem in Zip-Nuget-Java Packaging Pipeline
[33mb75c1081ca[m [Objective-C] Enable static analysis, second try (#8875)
[33m84f9271a8d[m Enable registering external custom op schemas on Linux (#8889)
[33m03b680b940[m Delete template.targets
[33mfa27c19342[m Delete create_nuspect.py and template.nuspec
[33m1b5909dea8[m Delete download_cmake.py (#8885)
[33mc8dd0bf37e[m to publish stable wheel to ort channel (#8873)
[33m36fa0de8b7[m fix regression and enable custom autograd func tests in CIs (#8868)
[33m6e20eb7eb3[m Stop gradient for Multinomial, RandomNormalLike, RandomUniformLike and EyeLike (#8836)
[33mdf9438192a[m Re-introduce saving of optimized onnx model (#8860)
[33m31926176ac[m Support external custom operator schemas on Ubuntu (#8807)
[33m89e8bff121[m Enable selecting custom ops in onnxruntime-extensions. (#8826)
[33m6ea9324f82[m fix EmbedLayerNormalization shape inference (#8876)
[33mae7f2d824d[m Share the execution provider instance for training (#8719)
[33m6a1939252f[m Fix Android java API failure (#8865)
[33m615df42b46[m Add force_fp16_initializers in convert_float_to_float16 (#8871)
[33m0034ad72e6[m Minimize changes to fix missing symbols used from C# (#8867)
[33mf3083f4bf3[m Support of sparse initializers with smaller indices data type (#8834)
[33m775f862067[m Add new option to disable cpu sync for tensors  (#8490)
[33m6a477acecf[m Add tensorrt_provider_factory.h to artifact (#8869)
[33m7e53a1df6f[m Enable selector action transformer infrastructure in minimal build. (#8804)
[33m1886f1a737[m Make SparseTensor infrastructure optional (#8802)
[33mcb59f46e04[m Add gpt2 mixed precision conversion and parity tools (#8845)
[33me8564d6597[m [js/web] update emsdk to v2.0.26 (#8653)
[33ma16c681103[m [js/web] Prepare to integrate ONNX Runtime Web CI with BrowserStack (#8843)
[33meb8f84e2a2[m Fix issue of GPU tarball/zip/java package (#8850)
[33m0cfc4ec09d[m [Objective-C] Enable static analysis (#8842)
[33mc325207f7a[m Optimize MatmulGrad (#8846)
[33mced2d8e597[m Clean up TRT docker files (#8847)
[33m9cd7d836f7[m Delete Dockerfile.ubuntu_for_android (#8848)
[33mb21ea00020[m Cleanup C# bindings to add EP (#8810)
[33m613a600471[m relax android ci timeout to 180 minutes (#8844)
[33m32ecbf4691[m Create combined GPU tarball and zip file package (#8827)
[33mcee79526fd[m Add opset 15 kernels for Pow, BatchNorm, and Shape (#8442)
[33m33a97e995b[m POWER: Fix compilation issues with clang
[33m73fe7bfa0f[m Add ATenOp at::diagonal (#8838)
[33m237076a660[m Add option to disable FastGelu half2 cuda kernel (#8819)
[33m98ed235fc7[m Removed MSNPU code from eager. (#8832)
[33m4251e04eae[m Removed assert (#8779)
[33m56b37e55e5[m Add new transformers model type: Bart (#8698)
[33m3837027506[m Remove pyopenssl from installation (#8830)
[33mddd4586a2f[m [Symbolic Shape Infer] add more ops for auto merge (#8824)
[33m7f1e880649[m Reorder ORT eager headers (#8813)
[33m8992e31c85[m Move iOS package from framework to xcframework (#8805)
[33me25986781f[m Fallback to default quantization if quantization params is not found (#8788)
[33m17b0664e34[m Optimize sequence type usage on CUDA [2/n] (#8720)
[33m9053e1522d[m Check for Python_EXECUTABLE in pyxir.cmake to fix Vitis AI EP build (#8631)
[33m4bfff45859[m Downgrade Eigen (#8817)
[33m2693af9799[m Ported changes / bug fixes from torch/ort. (#8784)
[33mf51f2bad66[m Fix for doxygen doc errors. (#8814)
[33m62c0d24340[m Fix Windows Store build (#8753)
[33mea68955c71[m Add more info to kernel registry manager hash lookup error message. (#8801)
[33md4a88cfe3f[m Add Gemm op to DNNL Exectution provider (#8799)
[33m89656bb712[m [CoreML/NNAPI EPs] Move direct use of initializer data to unpacked tensor data (#8780)
[33m0c5a305742[m Bump up Nuphar cache version (#8806)
[33m9fa0d8392a[m Extend node debugging utilities to push tensors and node placement to SQL database (#8672)
[33m4666a49106[m Add Component Governance (#8794)
[33m19b82b438b[m GridSample OP implementation for CPU and CUDA (#8551)
[33m6f2f4721ec[m Update Python setuptools classfiers to remove windows and mac (#8776)
[33mc117ac57b7[m New S8S8 Neon kernel for arm64 only (#8783)
[33m94c3e2048b[m [convert_onnx_models_to_ort.py] Add option to specify NNAPI EP partitioning stop ops. (#8668)
[33m81889a1cf6[m Invertible ReluGrad (#8773)
[33m2beb873c6b[m[33m ([m[1;31morigin/wangye/profile[m[33m)[m move training CI agent pools to 1ES hosted (#8775)
[33m39059f2539[m enable torch interop build (#8493)
[33m51152e1aaa[m Integrate TensorRT EP libs into existing GPU Nuget Package (Approach#1) (#8727)
[33mfe5046f48e[m Add SparseToDenseMatMul to the list of required by test ops (#8774)
[33mfa9fcb5634[m fixed the link (#8757)
[33mb2813656f5[m eager: fix build against latest PyTorch master (#8745)
[33mcb67fca738[m [js/web] enable 'use_ort_model_bytes_directly' by default (#8734)
[33m401de5911b[m Remove CUDNN dir from setup_env_cuda.bat (#8762)
[33mb0c707caa8[m [Nuphar] Do not handle MatMulInteger with zero-points (#8760)
[33m00b345eb7b[m ARM Neon S8S8 kernel for QGemm (#8695)
[33m78759059f1[m [CoreML EP]Make coreml ep build on non-macOS platform (#8677)
[33m0983d61969[m refine glue code and tests (#8510)
[33m3406b7b528[m Simplify UnpackInitializerData API (#8736)
[33m60089f7093[m Cuda11.4 (#8709)
[33mcc275e7529[m Gradient Accumulation optimization verified for correctness (#8273)
[33m224380448d[m Expand Qgemm UDOT kernel to 8x8 block (#8562)
[33m871eeb4dbd[m Support dicts as inputs to ORTModule (#8718)
[33med254c283f[m Add support for experimental json config for fallback (#8759)
[33m6ecf626a9c[m [Nuphar] Parse node doc_string for quantize info (#8746)
[33m47b3ecb53b[m Packaging pipeline now builds with PythonOp (aka running autograd.Function) (#8652)
[33m2b1f0816f8[m to build cpu training packages for multiple multiple python versions (#8750)
[33m419834d285[m Add PyTorch fallback for ORTModule forward exceptions (#8346)
[33m11a618b2ec[m Add engine encryption in TensorRT EP  (#8732)
[33mf668a79532[m [js/web] fix perf mode in test (#8748)
[33m4ceedbe933[m [js/web] add SharedArrayBuffer check for wasm multi-thread (#8749)
[33mae6fdd3333[m Bring code coverage dashboard back (#8394)
[33m0fb82f0f8a[m Memory aware gradient builder.  (#8582)
[33maa12d68c37[m Update ORTModule API docstrings (#8309)
[33m8713d76dd1[m Introduce C and C++ APIs for Sparse Tensors (#8621)
[33m8335d3dc0b[m Fix Python Packaging Pipeline (Training Torch 1.9.0 Cuda 11.4) (#8738)
[33m9cefd1303b[m Integrate Anubis (#8603)
[33m93e1e1dfa1[m Drop quant_util.h and move helper function into quantization.h (#8747)
[33md0ff2621ee[m [Nuphar] Fix Windows build in VS 2019 (#8728)
[33m8f7422be69[m[33m ([m[1;31morigin/wangye/tfbert[m[33m)[m Limiting platforms where cpuinfo is included (#8716)
[33me695cd304a[m Dnnl refactor (#8627)
[33mf04a235c77[m Update manylinux build scripts (#8724)
[33m385b571824[m handle a corner case in removing useless reshape (#8669)
[33md7baef765a[m Fix 4byte to 8byte static warnings in attention_quant.cc (#8715)
[33m436ac6dd5f[m Rename ml_value.h to ort_value.h (#8726)
[33m606b6271fa[m fix build (#8725)
[33m59e59b9e0e[m Fix unknown warning "-Wformat-truncation" build failure for arm  (#8721)
[33m26a7886a5d[m Improve error reporting for posix system errors. (#8723)
[33m217b2c9f93[m Removing filelock import from ORTModule (#8722)
[33mf00933c41a[m Update TensorRT parser to the latest (#8712)
[33m76d21bbeb2[m Update Android API level to 30. (#8717)
[33md9d0228d0b[m [Symbolic shape infer] fix a bug in loop/scan (#8694)
[33m1a8adb96fe[m[33m ([m[1;31morigin/wangye/ump[m[33m)[m Reduce templatization of C API and refactor for InitOrtValue (#8700)
[33m89601ee6b3[m [EP Partitioning Utils] Add check for assigned node. (#8473)
[33m8d3c372dc9[m Fix typo
[33mce6675a74e[m Avoid setting compile options on system libs for protobuf on Windows
[33m5f74f198c1[m Merge CPU/GPU nuget pipeline (#8683)
[33m3e8cabbc3e[m [js/web] WebGL backend refactor (#8586)
[33m7ff6a5e503[m work around build warning on jetson (#8701)
[33m333ef3c089[m Bump path-parse from 1.0.6 to 1.0.7 in /js/common
[33m76dfe8108b[m Optimize quantized LSTM (#8634)
[33mcaacf249c5[m Disable candy_opset9 WinML model test on Qualcomm Adreno (#8647)
[33mbec24ca4c1[m create packaging pipeline to support cuda11.4 (#8663)
[33mc6ef6b5bc8[m Subgraph support for quantization tools (#8012)
[33mc5c5d3499b[m Rewrite dockerfiles/Dockerfile.arm32v7 (#8686)
[33mde2a53e46d[m [eager mode] fix build and support customize shared provider entry point (#8680)
[33mf661c18654[m Fix attention perf regression (#8682)
[33mc24335246b[m Support bool type for Pad Op and fix Unsqueeze in Tile grad for Opset 13 (#8602)
[33ma13daf550b[m iOS Coacopods spec fix (#8678)
[33m0725f80d2d[m Revert "Fix Windows Store build (#8481)" (#8679)
[33m53e7831b53[m Fix Windows Store build (#8481)
[33m064a385b59[m Support int8 for operator Split (#8615)
[33m3a742f2910[m Ensure that the BiasGelu op test runs on CPU. (#8671)
[33me74f86059c[m [js/web] enable SharedArrayBuffer feature for WebAssembly testing (#8651)
[33med17ca3595[m Remove onnxruntime/core/protobuf (#8617)
[33mf0073308d0[m Fix CONCURRENCY_VISUALIZER build break (#8664)
[33m1a2b41dbbc[m packaging pipeline produces -cpu- named packages due to a logical error (#8665)
[33mcadb43a715[m Fix 'SyntaxWarning: "is" with a literal' issues in Python transformers (#8658)
[33m20f006c580[m Remove flake8 check from CMake build. (#8662)
[33m52a212e4f1[m[33m ([m[1;31morigin/wangye/mst[m[33m)[m Bump ORT master version to 1.8.2 (#8646)
[33m3166a9b8e9[m refine API of transformer optimizer (#8633)
[33mbaf8c39a8d[m Add Python checks pipeline (#7032)
[33maaeb781132[m Revert "Add netstandard2.0 target to OnnxRuntime.Managed (#8600)" (#8648)
[33m6dd59a1117[m revert onnx version (#8643)
[33ma56e325eb8[m constrain inputs for min/max grad UT (#8632)
[33m1ce4328846[m [js/node] fix js node install (#8650)
[33mc86b813519[m [js] resolve CodeQL warnings for force strict mode (#8645)
[33m419fd5cc6e[m reformat build suffix so that the latest is always correct (#8267)
[33m44ff80e816[m re-enable gpt2 fusion tests (#8566)
[33m1b902d0227[m doc: add ort-web related instructions to update onnx doc (#8500)
[33m6d3c2c85ef[m[33m ([m[1;31morigin/wangye/debug[m[33m)[m Integrate eager mode source code into onnxruntime repo (#8584)
[33m484e9de55c[m Optimize sequence type usage on CUDA [1/n] (#8598)
[33me791faeca5[m Fix bug in CPU force fallback logic  (#8597)
[33mf3a1aebb33[m [js/web] support override wasm file path (#8610)
[33meab6c51413[m to create a training cpu package for torch-ort documentation (#7845)
[33m0458821944[m Delete linux-ort-srv-ci-pipeline.yml (#8628)
[33m24b14c650b[m Add parity test for LayerNormalization (#8622)
[33mdda9f53bed[m Build script logging updates (#8618)
[33m96eb9810ba[m Update onnx (#8458)
[33m9d88b1de78[m correct supported ONNX version (#8590)
[33me673d2e050[m Add netstandard2.0 target to OnnxRuntime.Managed (#8600)
[33mfa722d208b[m [js/web] adding webgl pointwise conv kernel (#8418)
[33m1041fa34f4[m Specify timeout for iOS packaging pipeline (#8616)
[33mf6da9ac6d6[m Add more detail to model IR version mismatch error message. (#8607)
[33m6c69baf78e[m Disable Training Windows GPU Debug build because it is failing (#8608)
[33m1003db0058[m Fixing mlas unittest failures in POWER (#8498)
[33m7b289a7927[m Add test to evaluate Gelu and Fastgelu precision (#8592)
[33m375e86f0a0[m Make DNNL EP not depending on onnx (#8588)
[33me09321f4db[m Update ORT format model conversion utility to optionally fail fast on model conversion failure. (#8589)
[33mdeab284e4c[m fix build failure with --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=1 (#8587)
[33md14b08d09c[m Update onnx-tensorrt parser and cgmanifest (#8585)
[33m9e07ad93ae[m [OpenVINO-EP 2021.4] Add/update Dockerfiles w.r.t OpenVINO 2021.4 Version (#8491)
[33m717627775a[m Increase build timeout (#8583)
[33mee99fb400c[m Upgrade TensorRT to v8.0.1 (#8512)
[33m87975bdeef[m Use CUDA_HOME and CUDNN_HOME from the environment if they are not specified on the command line. (#8575)
[33m49a6ff75e6[m Update py-packaging-stage.yml (#8569)
[33md8c145d218[m [Nuphar] don't transpose B if A is a 1D array (#8568)
[33m0510688411[m Update compliance tasks in python packaging pipeline and fix some compile warnings (#8471)
[33m330b8e74bd[m Fix attention parity for GPT-2 (#8549)
[33m816ad86d14[m Configuring ORTModule - Internal Options (#8537)
[33mc6f95841dc[m Add HardSigmoid to mobile packages. Used by PyTorch MobileNet v3 (#8552)
[33m464fd28ee9[m Update iOS packaging script to default build static framework, disable bitcode (#8533)
[33mad093b94b9[m Restore transformers tests and disable some tests (#8530)
[33mc80740b8fb[m Merged PR 6311990: RI 7/29 github master into dmldev
[33md78568a9ac[m Merge remote-tracking branch 'upstream/master' into HEAD
[33m0cf2ed029b[m Add python binding for CoreML EP (#8472)
[33md243b38929[m [Symbolic Shape Infer] Bump up required onnx ver
[33m94c54718fb[m fix build break (#8536)
[33m778680202b[m remove unused functions to avoid warnings
[33m5e2f4263db[m Enable cast propagation in the frontend. (#8517)
[33m00d8f8ce95[m enable shared lib based execution provider test on linux (#8480)
[33m2e28cbaa64[m Configuring ORTModule - End User Facing Options (#8470)
[33m6f5bf8b8f2[m Update Linux Training CPU CI pipeline (#8518)
[33m1370cbe256[m [ORTModule] Extract output schema in module's true train/eval mode (#8516)
[33ma71dab691d[m Implement BatchNormInternal for cuda (#8172)
[33m539d1d44c1[m Optimize ARM64EC build (#8515)
[33m1798698545[m avgpool2d atenop (#8507)
[33m73660d78df[m Fix WinML build warnings in HStringFromUTF8 (#8519)
[33mceeb1a65d6[m Add quantization support of GEMM directly with QGemm (#8447)
[33m0f46b08646[m improve the qlinear avg pool perf (#8514)
[33m56441dcd88[m Limit work items to available threads, upgrade checks from assert to ORT_ENFORCE (#8495)
[33m686f9b530b[m ORTModule set_seed in int (#8511)
[33m7d47175f76[m cleanup NCHWc transformer (#8479)
[33m3850755feb[m Fix: onnxruntime_eager library does not compile on Windows due to path string constant (#8487)
[33m6b05a62584[m Merge remote-tracking branch 'upstream/master' into HEAD
[33m1685ab8138[m Implement Concat with Strided copy  (#8336)
[33m4c939e1cb7[m Add an option to use the input model bytes (ORT format only) directly without copy at session creation (#8502)
[33m1ae32655b3[m fix t5 assert error (#8501)
[33mb4baac888c[m [NNAPI EP] Make partitioning stop ops configurable from Python API. (#8484)
[33m421c4059c0[m [iOS Packaging] Update build definition (#8503)
[33m0a70c2de00[m [Nuphar] Add support for opset 14 (#8483)
[33m91936864ce[m Expose additional shared_provider APIs (#8478)
[33m534c22d769[m use float for alpha in attention Gemm (#8477)
[33ma9fc3c448c[m Improves documentation, show InferenceSession contructor attributes (#8494)
[33m79097ef553[m remove useless reshape node (#8419)
[33m6dee9b9d2d[m attention fusion kernel refactoring (#8432)
[33ma396c9e572[m Add more safety checks to the C API (#8474)
[33m6a07172a93[m Restore cpu affinity after loading tensorflow model from transformers (#8448)
[33me66846da4a[m revise terms according to guideline
[33mab5289f109[m Performance: enable faster training with skip checks config (#8411)
[33mc8d210de29[m Decouple Forward and Backward of ATenOp (#8301)
[33m619a8782a5[m Improve AddValueInfo (#8451)
[33mb2b9de939f[m cleanup onnxruntime_mlas.cmake of old gcc workarounds (#8469)
[33m002e427c5b[m Add UINT8 datatype support to Java (#8401)
[33m950fe5e28b[m Implement SparseTensor and infrastructure suppport and advance ONNX commit (#8038)
[33mf641c0f4e8[m Update requirements.txt
[33m9073c094d4[m Update torch litghning and re-enable test
[33me8ee31bcc3[m Update onnx_model_bert_tf.py (#8457)
[33m9a6fa057c8[m [Java] Allow extraction of multidimensional String tensors (#8452)
[33m287a2a778f[m Update CODEOWNERS with mobile team ownership of expected kernel def hash data files. (#8454)
[33m3360024a0b[m Support plugging in custom user-defined allocators for sharing between sessions (#8059)
[33m989491c333[m [NNAPI EP] Make partitioning stop ops configurable. (#8444)
[33m892ac9f55a[m code structure update (rename only) (#8410)
[33m4275055868[m Add Gridsampler contrib op (#8372)
[33m53d5814d12[m Move the wrapped types out of provider_interfaces (#8455)
[33m14b045ad52[m Add link to sample repos (#8417)
[33m83bb771e0b[m Merged PR 6283367: RI Onnxruntime github to internal Fork 7/21
[33mb0c0b087a4[m FIx merge conflict
[33m695536a7ac[m Make some common macros safer to use. (#8445)
[33m972aee8308[m Fix GCC build error in quantization tests (#8449)
[33m7e2ecb2eeb[m Remove unnecessary line as no headers exist now (#8446)
[33m55b26b6951[m [Java] Adds support for DNNL, OpenVINO, TensorRT shared providers and refactors the CUDA shared provider loader (#8013)
[33m1cd9b47d8d[m Remove all C/C++ samples from our C# dir (#8441)
[33m894fc82858[m POWER10: Additional check in cmake
[33m28527b4867[m Handle duplicated names for output_grads (#8431)
[33mcc9f793b48[m Move one function from cuda_provider_factory.h (#8407)
[33m3e7fcd8c92[m Fix iOS packaging pipeline failure (#8433)
[33mbf54fe481e[m [CoreML EP] Support 1D Conv for coreml ep (#8398)
[33m862bc8c7a0[m shape infer for present output of Attention op (#8430)
[33m0f989c6162[m bumping onnxruntime version to 1.8.1 (#8429)
[33me04e1d5ce0[m Move shared providers CPU providers into separate file (#8293)
[33mdfe42e185c[m update bert notebook to use onnxruntime 1.8.1 (#8379)
[33mafce0e2543[m Attention kernel update to handle different Q,K,V hidden sizes (#8039)
[33mc3129306e5[m Enable string attributes for experimental model building (#8428)
[33m1686e8ff57[m [OpenVINO-EP] 2021.4 Release (#8369)
[33m8544c222ce[m Fix build error about `if` being constant in Eigen and Protobuf (#8291)
[33m4a614637a7[m [NNAPI EP] Update NnapiExecutionProvider::GetCapability() to use partitioning utils (#8387)
[33m2f408f757e[m Improve performance of Pad CUDA kernel (#8408)
[33m127b1f0d01[m SDL Native Warning errors in DML ep (#8396)
[33mbcd50afafb[m [CoreML EP] Fix failure for layer without name (#8399)
[33m963d883de8[m Create a common directory for quantization code and functionality. (#8320)
[33mef930b3ca9[m [Objective-C API] Fix ORTIsCoreMLExecutionProviderAvailable link error when used from Swift. (#8350)
[33mc5038063ed[m Add iOS/macOS static framework (#8357)
[33m41f1280fc9[m Fix transformer optimizer (#8392)
[33m88d1ffe9b8[m Fix invalid access in log call. (#8389)
[33m0a1c00e8db[m [js/node] remove unused dependency node-pre-gyp-github (#8388)
[33m5cd254aa79[m update gpt2 attention fusion for past pattern (#8375)
[33m4e1c5f6ef4[m Move the samples to a new repo (#8374)
[33m4931ef666d[m Update ORTModule frontend code owner file (#8335)
[33m68c5eb5414[m Fix reduced ops CI failure (#8377)
[33me340a59993[m Update machine info script for transformers notebooks (#8376)
[33m16f6904232[m [iOS] Packaging pipeline improvements. (#8324)
[33m0020703d00[m Fix cpuinfo initialization failure in mlas test (#8366)
[33m04297110c3[m Support int64 in ReduceMin cuda op for Opset 14 (#8307)
[33m8d8db7c9f0[m [ROCm] clear last status if hipErrorNotReady (#8358)
[33m178c139718[m cleanup formatting in skip_layer_norm.cc (#8371)
[33m31f291f0af[m Add TRT EP memory leak test into trt perf script (#8155)
[33meda1411e03[m Fix symbolic shape inference regression in RoBERTa training (#8364)
[33m7db4fc8c2a[m Fix segment fault for custom function (#8331)
[33m5bf862eef9[m Fix build break on windows arm64 (#8361)
[33m530d7bb46d[m Temporarily disable transformers tool test (#8360)
[33m0a5b75f5cd[m Update submodule onnxruntime-extensions. (#8282)
[33m29ca08a729[m Update Dockerfile.cuda: remove compute capability 30
[33mdf4cb6f301[m Adding pytorch cpuinfo as dependency (#8178)
[33meec8e1394a[m Memory map files on windows to speed up model load (#8349)
[33mf6956e0259[m Refactor qgemm file (#8322)
[33mb7c9696ac3[m Symbolic_shape_infer fixes (#8280)
[33m10142f9510[m Add metadata_props to ORT model (#8340)
[33m60641a19e4[m Add "/external:templates-" to VC++ flags (#8338)
[33me467d78a11[m fix a typo (#8334)
[33m598454bb5f[m Fix the mix precision handle for square case (#8333)
[33m187743726b[m [CoreML EP] Add Int32<->Int64 handling around coreml ep (#8183)
[33m5369821ad6[m Support SpaceDepth ops in the CUDA and ROCM EPs (#7960)
[33m1b2e1a7e0c[m Refactor QDQ optimizers to enable future usage in minimal build (#8191)
[33m46e5c8d4b9[m Cosmetic change in test infrastructure (#8292)
[33m5454af4b95[m decouple the shared python dependency  (#8294)
[33m067759b387[m Fix bad URL to huggingface onnx-export example notebook
[33m84bc20fe9d[m Enable cast propagation with level one by default. (#8286)
[33mf40df30219[m Replace functions with secured version for OSX compliance (#7586)
[33m6dbfb8db0e[m autograd function fallback perf (#8312)
[33mc254c3c355[m Fix issue with ONNX to ORT format model conversion script when given single model file as input. (#8323)
[33m6652d17dcd[m Support lists as inputs to ORTModule (#8311)
[33m9a855fe9e7[m Make Torch CPP extension build optional for packaging pipelines (#8305)
[33md7c3703371[m handle unsqueeze change in opset13 (#8308)
[33m2347a0aca8[m Autograd Function Fallback bug fix - moe support (#8105)
[33m40e5279f8f[m Drop unused functions from math.h (#8304)
[33m62d1458ea8[m Move kernel implementations outside of lookup table utility functions. (#8306)
[33m090bae21ab[m Pinning pillow version to 8.2.0 to circumvent regression introduced by 8.3.0 (#8303)
[33m008c5f7640[m Use single builder image across Python versions for ROCm wheels (#8302)
[33m56e4dd1d3e[m Fix optimizer crash (#8274)
[33me71846b029[m fix ld_preload for rocm (#8290)
[33m036eee5b66[m register softmaxinternal with rocm (#8289)
[33m969eb545d1[m Update issue template to ask users to check known issues to avoid repetition. (#8288)
[33m0fa9ac3648[m Remove path from telemetry strings (#8281)
[33m552806f3be[m Fix lamda function formatting in layer_norm.cc (#8276)
[33m2bda2a62fd[m Pin version of Pillow to 8.2.0 to circumvent noncompatibility with numpy (#8278)
[33m88ec95ea96[m Support OrtMemTypeCPUInput for ATenOp/ATenOpGrad (#8116)
[33mb42e7d2c78[m Add iOS packaging pipeline (#8264)
[33ma9a2394fa5[m disable computation reduction optimization for non-gpu build (#8251)
[33m9cfe642b34[m enable BN training in cpu inference build (#8269)
[33m996a98b3ac[m fix the shared provider test for training build; expose more symbols to non cuda build (#8249)
[33mb46310b349[m Integrate onnxruntime-extensions into onnxruntime. (#8143)
[33mf616cd07b4[m Provide torch module interface for ORTModule (#8148)
[33mce9d134952[m gather elements optimization (#8154)
[33mef8f50c4ab[m ScatterNDGrad (#8261)
[33m97f1eea2ea[m Propagate ROCM version to onnxruntime wheel package (#8247)
[33m665ecdf9ce[m [CoreML EP] Use partitioning utils in CoreMLExecutionProvider::GetCapability(). (#8179)
[33m4993680e56[m Graph::GetNodeProvidesGraphOutput -> NodeProducesGraphOutput (#8243)
[33mb3479367cf[m Add helper to check if node provides a graph output.  (#8186)
[33m17d4545ccb[m Improve readability of Graph::PerformTopologicalSortAndCheckIsAcyclic. (#8187)
[33m9b19241b27[m Disable update database for Android code coverage (#8182)
[33mfa8768723a[m Allow custom loaders for testing (#8150)
[33m507d97b200[m Add initializer for embed layer norm unit tests. (#8196)
[33m9ec0fd6a1c[m Revert the cuda algo finding change as this causes a significant memory bloat. (#8181)
[33m83be3759bc[m Add post-install command to build PyTorch CPP extensions from within onnxruntime package (#8027)
[33m25db5706bb[m Change "Export PyTorch CustomOp" build pipeline to use Ubuntu 20.04 (#8158)
[33m32ceaf4532[m POWER10: Optimized SGEMM in MLAS (#8121)
[33m9b75be3d3e[m Fix a warning in pool.cc (#8168)
[33m821492f6f5[m Drop std::count_if() in *EmbedLayerNorm Ops. (#8161)
[33m523db6ef44[m Check for null runoptions in Run (#8163)
[33m588511d6da[m Rename embedlayernorm_op_test.cc to embed_layer_norm_op_test.cc (#8160)
[33m800b62a139[m Create a quantized EmbedLayerNorm for ORT. (#8124)
[33m9366114028[m make pipelines to support torch1.8.1 and torch1.9.0 (#8084)
[33mc716b56f26[m Update C++ Standard from 14 to 17 (#8041)
[33m9618b6ba62[m Fix mac shared_provider warning (#8153)
[33ma41d0db43c[m[33m ([m[1;31morigin/wangye/lf_attn[m[33m)[m Enable C# GPU tests in Windows GPU CI pipeline (#8142)
[33m91075255a7[m Enable TRT provider option configuration for C# (updated version) (#7808)
[33m49938cce77[m Fix Python Cuda loading issues (#7939)
[33m378a98597e[m Use std::make_reverse_iterator directly
[33m00e44861c5[m Fetching frontier tensors to frontend for ORTModule (#8086)
[33meb36258df4[m Enable signed int8 data type for activations in static quantization (#7029)
[33me083d207cf[m Disable InitProvidersSharedLibrary when training is enabled. (#8132)
[33m7ed9f5fc90[m [Java] Fixing the creation of OnnxTensors from scalars, adding tests (#8023)
[33m80b7b134bf[m Adding optional ops in contrib ops (#7946)
[33m59e336040c[m Ortmodule override torch.manual_seed() (#8131)
[33mb478086bc1[m Fuse attention node even in case of different Q,K hidden dimensions (#8106)
[33m4fd7efcf0d[m Update logic in props.xml to account for shared provider library changes (#8138)
[33mf000dfddbe[m Update run_dockerbuild.sh: set default python version based on OS version (#8136)
[33m1fa6986656[m Chang how numpy version is handled. (#8130)
[33mdb88f3059c[m [js] fixing broadcast issues in pack mode (#8090)
[33mcbdd59dae9[m MLAS: enable SSE 4.1 path for x86 build (#8127)
[33m45ce239929[m User dynamic axes in one step beam search output (#8092)
[33mcccd61e3bc[m Add int64 as a required type to ConstantOfShape as it's used by the pytorch converter for Pad. (#8128)
[33mb1e21312b5[m [Mobile package] Update required operator config with additional ops for newer version of Wav2Vec 2. (#8123)
[33m664e548e31[m Col2im optimization by eliminating integer multiplications:
[33m6e2b064aec[m Delete some unused code in run_dockerbuild.sh and Enable Nuget CUDA tests (#8089)
[33mf6292d9b38[m [Android] Output error message to android log instead of stderr (#8114)
[33m9003df5d87[m Fix 32bit Android java API crash (#8122)
[33m4bb0e29d0e[m initialize generated_value_names with graph input (#8085)
[33m839f69d249[m Implement WINRT_IMPL_LoadLibraryW to avoid calling LoadLibraryW directly (#8065)
[33me7d7fa8fa2[m Update migraphx to rocm4.2 (#7994)
[33m5809890ba2[m Fix a compile error in InferenceTest.cs (#8119)
[33m8cacb26946[m remove debug.keystore from repository due to a credential issue report (#8113)
[33m27d1784d44[m Add TRT 7.1 Pipeline (#8073)
[33m3cd06cb38c[m Added support for ReduceMean on DNNL EP for CPU and GPU (#7902)
[33m352d560fd5[m Adding Conv+Clip fusion (#8102)
[33m10b7ed6430[m Added op_name to message when we are missing a kernel. (#8110)
[33mcba4bc11c7[m Split Linux CPU CI pipeline (#8097)
[33m51c12a715b[m Add NGramRepeatBlock contrib op (#8078)
[33m5ac06bad61[m Relax test tolerance to make CI more reliable (#8100)
[33m059d705988[m support pass in custom op registry for eager mode (#8087)
[33m9f5969693a[m clean up builds for interop_torch (#8017)
[33m5c2e1bbb0a[m Fix input schema extrator for ORTModule (#8098)
[33m7701c8703e[m Add module attribute to ORTModule to support HuggingFace Trainer save_model (#8088)
[33m08eeb8763d[m Loosen validation checks in Concat to unblock execution of model in #8020 (#8080)
[33mb2247ece25[m Make Perf Test Configurable (#7836)
[33maa68157c3d[m [Mobile package] Update required operator config with additional ops for wav2vec2. (#8079)
[33md83f7fd4aa[m [NNAPI EP] Enable Slice support (#8031)
[33m96989b83ee[m Create python packages for DML (#8061)
[33md924fd205b[m Create and move quantization tests to a shared Quantized utils file. (#8054)
[33m365070b744[m Merged PR 6158327: RI Onnxruntime github into DmlDev
[33m32ef39be58[m [Android] Move add header files into AAR to using Gradle (#8068)
[33m1d8edd0b5b[m Fix missing files on linux (#8066)
[33mc76172fab6[m Fix PythonOp with input which has no gradient (#8011)
[33mde8f2ecda9[m Reduce Kernel Optimization (#8067)
[33m0ebaa71f49[m Improve Windows Platform system error messages (#8063)
[33m32e118bef0[m Fix microbenchmark build failure (#8064)
[33me31784b6cf[m decouple the python module construction from pybind_state (#8060)
[33m96cf533c76[m Remove DML from Windows GPU CUDA 10.2 pipeline
[33m25c49a5fe0[m fix issue with cmake path (#8055)
[33m07b166bb1b[m fix PATH addition in windows
[33m887c3149e3[m [js/react_native] Use a mobile ORT instead of a full ORT (#8042)
[33m6a1b000125[m Fix unit test typo in test_op_embed_layernorm.py (#8056)
[33m07788e082e[m Enable python GPU tests (#7854)
[33mde1b1edcad[m Merge remote-tracking branch 'upstream/master' into HEAD
[33m8079c76383[m Create ORT opschema library (#7903)
[33mc72a8c7ff4[m Upgrade tf 2.4.1 to 2.4.2 for component governance (#8036)
[33m9acf93b90a[m Take graph topology into account when creating dnnl subgraphs (#7910)
[33m6d7461795f[m Update Version.md (#8021)
[33mad6a306a7f[m Add pragma once (#8040)
[33m96ead2be91[m Avoid hashing the operator type in the GraphViewer priority node check unless the string has a chance of matching. (#7972)
[33m6e134c2cc3[m [Objective-C API] Add support for documentation generation (#7999)
[33m1d7f44a832[m Add unit test for EmbedLayerNormalization quantization op. (#8033)
[33me6225c62a5[m transformers test CI pipeline fix (#8016)
[33m43c45ddd66[m Update DirectML EP changes from DmlDev as of 2021-06-07 (#7987)
[33m8b0c2e1f3d[m Merged PR 6101363: Int64 prototype work for ONNX runtime DML EP
[33m2f2aaf2cf6[m Fix Memory Leak from DlpackToOrtValue (#8029)
[33md02de9c1bc[m [ROCm] dockerfile updates (#7955)
[33m00d48d9c30[m Add enhanced partitioning utils for use by compiling EPs (#7991)
[33m35ca3c99d1[m Fix ROCm wheels pipeline after changes to manylinux scripts (#8026)
[33m20579595c8[m Make logic in InsertCastTransformer around forcing a node to fp32 more precise. (#8018)
[33m0237225117[m Add @file annotation to support doxygen generation of C API docs (#7458)
[33mb2ed4fb0a4[m Merge orttraining and ortmodule single gpu ci pipelines (#8022)
[33m4d1b48632c[m [CoreML EP] Add ArgMax op support and modify OpBuilder interface (#7924)
[33mb313c4581c[m Remove CC/CXX env settings from C API packaging pipeline (#8014)
[33m2a74f5e85b[m Save module output for backward if needed (#8010)
[33mc74265667e[m Remove CUDA architectures 35 and 86 from GPU packages (#8004)
[33mb03383f6d5[m Add cuda provides files (#8002)
[33mf013b0c0eb[m [NNAPI EP] Add support of Elu, merge in NNAPI updates for API level 30 (#8001)
[33maa45545af7[m Update orttraining-linux-gpu-perf-test-ci-pipeline.yml (#8005)
[33mcb5f411da3[m Fix Python Packaging Pipeline && Build Clean Up (#7993)
[33md433aa2459[m Add transformers tool test to pipeline (#7959)
[33mf0f3012666[m Add SoftmaxCrossEntropyLossInternal to Support Dynamic ignore_index Input (#7899)
[33mf38200e209[m Override ORTModule named_modules to support extra arg (#7954)
[33m1cc896c8ae[m optimize js package folder structure (#7989)
[33m47d8977741[m add missing provider_options.h in packages (#7995)
[33m275796a165[m Update googletest to latest commit to fix build issues with GCC11 (#7984)
[33m861cd0fb24[m Increase Python Mac Job Timeout (#7998)
[33m500f18badb[m fix bug that bias can not be shared across Convs (#7982)
[33mf5c6b9703a[m Merged PR 6129591: Merge github master into Dmldev
[33m66170bfcef[m Python with DmlExecutionProvider : choose device_id in SessionOptions (#7964)
[33m4ecbae43b2[m Use GCC 10 in Linux CPU CI pipeline (#7985)
[33ma776b57160[m Add shape inference to custom symbolic functions (#7937)
[33mdce76c15e7[m add dockfile for ROCm 4.2 (#7749)
[33mb50e9d9d74[m Adding webgl shape kernel (#7971)
[33m0f01de3b0b[m [js/web] Add wasm SIMD backend to onnxruntime-web (#7896)
[33m71c4f5ddb2[m ATenOp Enhancement (#7725)
[33m0696e2f0d4[m [Objective-C API] Add script to assemble pod package files. (#7958)
[33mfc331cbd5d[m Accept success codes other than S_OK in RoInitialize (#7979)
[33m8c951b94d1[m Merge remote-tracking branch 'upstream/master' into user/rylai/ri_6_4
[33meb354853d3[m Update CMakeLists.txt for openvino EP (#7980)
[33m1a5ee11dbd[m Implement Sequence Ops GPU (#7863)
[33m9e4dc08483[m training with custom autograd Functions (#7513)
[33m4cb3c5e3e2[m Update auto-generated csharp files (#7950)
[33me23529f313[m Update Python Wheel File Path to fix python packaging pipeline (#7978)
[33mbfa996b5fa[m add emsdk to component detection ignore dir (#7932)
[33m429df40f1d[m Suppress warnings in GTest (Fixes Gcc11 build errors)  (#7957)
[33m9b5f749176[m [wasm] emsdk: allow to install emscripten only (#7961)
[33mf352d54743[m Refactor Resize/Upsample implementation to reduce binary size.  (#7650)
[33mfd23b8caad[m Update mobilenetv2 quantization notebook (#7941)
[33m291453dac9[m [wasm] fix test report generation (#7953)
[33m09ab895563[m Fix a resolving issue on the quantization node transforming. (#7952)
[33m64f1a4ed22[m Merge remote-tracking branch 'upstream/master' into HEAD
[33mb856e7ae3c[m Update build.py: change default cmake generator for Windows to VS2019 (#7945)
[33m0975e7c9a7[m Add and correct multichannel test for qlinear pool test. (#7864)
[33m5a7f65b831[m Fix training e2e pipeline (#7942)
[33m2b3f953701[m Run PadGrad UT for CUDA Only (#7947)
[33m650314c926[m [wasm] bugfix for emscripten '--preload-file' under node.js (#7944)
[33m0723d16436[m [wasm] allows to specify MALLOC setting for wasm build (#7934)
[33m6a9023f47d[m [JS/Web]Adding support for WebGL v1 (#7906)
[33mab973dce33[m [Objective-C API] Enable CoreML EP (#7914)
[33med5fd919ef[m Update dockerfiles to use the latest cmake (#7933)
[33m8f8b9302a2[m Re-enable some of the recently disabled cuda tests (#7873)
[33ma118da160d[m pad gradient (#7926)
[33m3bb780dcd5[m Update Vitis AI EP to support multiple DPU targets through provider options (#6690)
[33m896f32ec09[m[33m ([m[1;31morigin/mem_leak_fix_for_example[m[33m)[m [js/web] support string tensor for wasm backend (#7891)
[33mb854f2399d[m Update manylinux build scripts and GPU CUDA version from 11.0 to 11.1 (#7632)
[33ma272a75cd1[m [js/web] allow pull wasm artifacts from CI (#7886)
[33m2fd703a97a[m Merged PR 6115647: RI github into dmldev. Need to merge this unsquashed
[33m5c8b07577d[m Merge commit '0fbec1b9c1d8f34a44ac5e7efc1fee0a0a08ac84' into user/rylai/Ri_unsquash
[33m14fe3e8404[m Merged PR 6115559: RI changes from Github into dmldev
[33m4f82ad1b58[m Topo sort the model before saving (#7913)
[33mc45ac166d3[m Add graphviz into Dockerfile images for Python API documentation (#7819)
[33mfaae347d9f[m [wasm] upgrade emsdk version to 2.0.23 (#7893)
[33m79a6727a02[m Add podspec template for ios package, update build settings (#7907)
[33m0e935b8718[m Fix typo (#7872)
[33m271a343024[m Cache initializers and avoid device check ot end of forward (#7905)
[33m9946e6f7df[m fix broken tests (#7909)
[33m0fbec1b9c1[m Update the operator documentation generation (#7787)
[33m3d734a1cdc[m Missing logic for cuda nuget package (#7911)
[33m38ca0f4839[m Change CMAKE_CUDA_STANDARD to C++17 for Windows GPU build (#7883)
[33ma9f7eef754[m Add API_IMPL_* blocks around shared provider methods as they are C APIs (#7908)
[33mf9587d6051[m [js/web] update README.md (#7894)
[33m6d9062641c[m Basic data parallel tests for ORTModule (#7812)
[33me7e200ee59[m Add test for iOS package (#7816)
[33m81ed6c55bf[m fix grouped pointwise convolution (#7885)
[33m3a72932c4a[m Don't hold onto unnecessary numpy references while binding numpy objectas as inputs (#7881)
[33md8bcb3d6a4[m Added virtual destructor to adasum_interface.h (#7882)
[33m451fcb7df1[m Add sequence support for identity on GPU (#7810)
[33mbccf29210c[m Merged PR 6103324: Remove usage of non-generic error code (FWP_E_NULL_POINTER)
[33m4dd724ef1a[m Enable WebAssembly SIMD build (#7839)
[33m5a63904aa9[m Remove some templated versions of functions that are no longer needed (#7868)
[33m3f43a84e10[m Merged PR 6093117: Fix test_DynamicQuantizedLinear_max_adjusted_expanded by allowing Identity operator to run on non-float inputs
[33me41e042de6[m [OpenVINO-EP] Adding OpenVINO-EP samples to Msft Repo (#7826)
[33mab4b5055c7[m [Objective-C API] Fixes from package testing and clean up (#7866)
[33m35b49b64c7[m Fix regex to detect Objective-C/C++ (.m/.mm) files. (#7870)
[33m0255c83dc4[m Clean up CPU kernel definition for opset 13 Pad (#7867)
[33m71b05f74a2[m fix duplicated node name (#7865)
[33m1f4421fe70[m Include ORT C/C++ API headers in the ORT Mobile AAR package (#7858)
[33m63df683040[m Fix path used in check for cudnn library (#7786)
[33mddf4aaaae1[m Resolve issue with wrapped ORTModule load_state_dict (#7847)
[33m8140e3fde5[m Make requantize a qgemm post processor (#7850)
[33mccdedf1b2e[m [js] update documents (#7852)
[33m7380219717[m Fix bug in Transpose CUDA kernel (#7329)
[33m883923a40a[m Support bool type for Pad CPU (#7856)
[33m13622bae91[m Add Apple log sink. (#7820)
[33m45a7352622[m Update Mac CI builds to use macOS-10.15 image, Xcode 12.4. (#7437)
[33m2a3851cd75[m fixed bugs in packed mode and enable pack mode tests in ci (#7848)
[33mbed6e87cbd[m add environment variable to control default training package's local version (#7849)
[33mfa093d8e45[m [Objective-C API] Add ORTSession methods to get input, overridable initializer, and output names. (#7837)
[33m94bb09bf47[m fix topo sort in quant tool (#7833)
[33mfc472a04be[m Relax tol for Conv1D fp16 test (#7844)
[33mc08bb4eee3[m Update docs/ONNX_Runtime_Server_Usage.md (#7818)
[33mafca89dce6[m fix boost download url (#7843)
[33m331f20428c[m [js/web] only apply max thread number when it's omitted (#7834)
[33mc5ea5907c0[m Fix permission error for ORTModule lock file (#7814)
[33ma85a9ddaf5[m Merged PR 6091402: Fix inbox ORT debug info
[33mc487824a31[m Fix bug in Einsum implementation (#7822)
[33md1f0251e39[m Python bindings fix ups in preparation to Sparse Tensor introduction (#7817)
[33m57782b3463[m Add supported operators/types documentation for the ORT Mobile package (#7807)
[33m4fe59c8b29[m delete model_copy to save memory allocated in forward call (#7832)
[33m1c6b6f696e[m fixes for cuda centos/manylinux (#7830)
[33mf78af4fc8c[m Use RTLD_GLOBAL for onnxrutime_providers_shared on unix (#7831)
[33mea1a4f8fb5[m [JS]support running super resolution model using ortweb (#7677)
[33m6ca1ee7733[m Fix rpath issue with pybind. (#7829)
[33m29c68888af[m Update BERT convergence baseline.
[33m3d12e957a7[m Workaround for miopenReduceTensor() behavior difference in ROCm 4.2
[33mf49a4b6329[m Decrease lock contention in qlstm by memory allocation. (#7815)
[33mc0a8905b90[m Merged PR 6087868: Update ORT to latest master
[33m3fb4a2dc99[m Merge remote-tracking branch 'upstream/master' into user/justoeck/ri_20210525
[33mff655175ff[m Eliminate no op node - add 0 (#7798)
[33m9241d76396[m Remove unnecessary cuda libraries refernced in cmake (#7824)
[33m93c8e29782[m Improve code coverage report (#7770)
[33mcdd2129fed[m Fix CUDA Pad kernel registrations (#7813)
[33ma41255c280[m Fix performance regression in Reduce operators introduced by PR #7206 (#7719)
[33mf487f6be25[m Add int8/int32 Relu for Opset 14 (#7536)
[33m98007f0be6[m Fix typo in the ios packaging script (#7802)
[33m02c78a8aa8[m test migration to rocm4.2 (#7800)
[33mda5ab325ee[m register batchnorm for opset14 cuda provider (#7806)
[33mbd5067a2ff[m Cannot upgrade SDK version because winml_lib_telemetry pulls in SDK cppwinrt version  (#7795)
[33m13a129054f[m Prevent unnecessary re-initialization of the graph when model has unused parameters (#7799)
[33mc4f515d380[m - Fix training cmake file so it builds if `--cmake_extra_defines onnxruntime_BUILD_UNIT_TESTS=OFF` is specified. (#7789)
[33mde4c221712[m set max profile before opt profile (#7801)
[33mae14cedd63[m Fix c_api warning (#7803)
[33m21ff8fabe9[m [js/web] fix webpack config for onnxruntime-web (#7785)
[33mee29330cab[m Delete unused file: Dockerfile.ubuntu_gpu (#7797)
[33mb5c5e8c1ca[m Update C++ API comment to resolve warning. (#7776)
[33m1fbc04d691[m Enable training ops in inference (#7783)
[33mb852b73e84[m [js][doc] update some part of documents. (#7768)
[33ma6ca9f0a40[m Use list comprehensions instead of list appends where possible (#7753)
[33mdb0d608ff0[m Fix build errors on Dev machines after PR #7626 merge (#7781)
[33m7c4a5faef5[m [wasm] enable DWARF format debug info for ORT WASM (#7777)
[33m2a02871157[m Disable reuse for YieldOp's inputs (FW partial graph's output) (#7767)
[33m62a1c39f75[m Merged PR 6070939: Merge ORT master
[33m3eace1ac48[m React native debug keystore. **BYPASS_SECRET_SCANNING**
[33m503bd59dcc[m Merge commit '31e6d3f85c21bb3fc0a9b194cf5a6e7380fd57d8' into user/justoeck/ri_20210520
[33mc2435d24ec[m Clean up ROCm4.1 Dockerfile build directory (#7732)
[33mc91602070d[m [js] update version of package "onnxruntime-web" and "onnxruntime-react-native" (#7769)
[33m6c252a0bea[m Fix builds that use gcc 5  (#7765)
[33mf6eb0f76ae[m to used cudnn7 to build onnxruntime-training wheel with Cuda 10.2 support (#7760)
[33mc99aa3a3f3[m Ryanunderhill/cuda shared (#7626)
[33m31e6d3f85c[m Revert CUPTI profiling feature (#7763)
[33me26c668a9b[m add google benchmark as direct dependency (#7762)
[33m38c1c6d2da[m using copy to when scale/zp are same in qlinear concat. (#7761)
[33m374acf1423[m Disable external initializers build option (#7635)
[33m6c868341e3[m Fix CUDA 10.2 pipelines (#7759)
[33mfbe6eccc65[m [JS/Web] Bug fix for Reshape Pack (#7754)
[33m203efef147[m Add a flag to allow for linking against shared system protobuf (#7577)
[33m3a68c389d9[m Add version lock to manylinux build scripts (#7755)
[33m126afbe450[m Fix shape inference warning issue in TensorRT (#7751)
[33m47b3cc4bde[m GatherGrad Bugfix (#7752)
[33m75dbc2a35e[m use stable onnx.ir_version in test (#7747)
[33m077e8c6b40[m allow update_version.py to update new npm packages (#7746)
[33m3f204d191b[m [CoreML EP] Add Squeeze Op support  (#7730)
[33md1c531058a[m Add elseif statement for arm64e
[33m1e6ad669cf[m Support arm64e for osx
[33me05b15175d[m Add cpp ext lock file check during ORTModule init (#7740)
[33m224a664811[m GPT-2 one step search tutorial (#7718)
[33m7834ca983c[m update optimizers for opset14 (#7722)
[33m26a472c948[m Increase test timeout from 1 hour to 2 hours (#7735)
[33me161213f8e[m Handle model with no parameters (#7736)
[33m96deec596f[m fix npm test for webgl without wasm artifacts (#7742)
[33me92b3c1394[m bumping up version number to 1.8 (#7733)
[33me4a985ff17[m [JS/Web] WebGL Profiling Tool (#7724)
[33m43e2ee37f2[m Some cosmetic changes (#7741)
[33ma6972c8782[m Fix issues in TensorRT provider options (#7738)
[33me9057d2e49[m ZCode FastFormers changes (#5827)
[33m38d90b0f15[m Cleanup install_deps.sh (#7734)
[33m9075488368[m Add per-column support for QLinearMatMul (#7729)
[33md3c4b70ede[m [Web/JS] Fixing two bugs in reshape_pack and im2col_pack (#7689)
[33m79854dda8f[m bumping up verson (#7731)
[33mf977644324[m ROCM support int reductions
[33mda5f24bd2d[m Support additional session options and run options in WebAssembly (#7712)
[33m6d9f541442[m [JS]moved logging level flag to global env (#7700)
[33m5e8086ad8e[m Support fusions inside subgraphs in optimizer tool (#7701)
[33mad95b19322[m Help build pass on ubuntu 16.04 with old g++. (#7706)
[33m0e48187b4e[m Add type checks for QDQ transformer (#7715)
[33mc873f5589d[m Fix bug where the output names were sorted lexicographically (#7709)
[33m6c41ed597b[m Add custom autograd function to prevent input passthrough on ORTModule (#7694)
[33m4fe2ffae16[m Fix ORTModule python doc generation (#7704)
[33mebee380911[m Partially revert PR #7348 (#7702)
[33m2b73163690[m Exclude training specific logic from BatchNormalization to reduce binary size. (#7703)
[33m557b94637d[m Add more TensorRT env variables to provider options (#7698)
[33m943ab9dcef[m undo clang-format corruption (#7720)
[33md604281a86[m Liqun/training pkg to run tests (#7662)
[33m3ead2f2f39[m update pt lightning version (#7711)
[33m017b94ab36[m Specify correct dependency for CI pipeline of nodejs binding (#7717)
[33m6b0a7905ed[m fix quant weight cleanup bug (#7707)
[33m9ba8da65d2[m Fix BiasDropoutFusion when there are multiple Dropout consumers. (#7708)
[33m53d1d55ea8[m Add ability for pre-packed weights of shared initializers to be shared across sessions (#7421)
[33mc78a40c0c7[m add opset14 registrations for cuda provider (#7699)
[33m97d9bcd644[m [js/web] fix bundle for multi-thread, add e2e test and support nodejs (#7688)
[33ma74e41e47d[m Add non-zero zp support for quant matmul and attention (#7570)
[33mc53b5be509[m force multi steps to use the same commit in CI (#7697)
[33m0f7721a019[m Fix bug for not checking original float value names when treat it as not existing. (#7695)
[33m1d403ba03b[m Fix a compile warning in EigenNonBlockingThreadPool.h (#7638)
[33m033f0b3b7c[m fix typo. (#7690)
[33ma9b47ca8e7[m update debug.keystore for a public usage (#7696)
[33m359fe1d197[m Liqun/ort training version (#7620)
[33mbfbcc89db1[m Add MLFloat16 support for SoftmaxCrossEntropyLoss for CUDA EP (#7679)
[33m39fac6d304[m Fix a buffer reuse bug in allocation_planner.cc (#7645)
[33m442c7300eb[m add opset14 rnn ops (#7687)
[33m3725d0211f[m support maxpool QDQ fusion from opset 12 (#7693)
[33m50c5edcf13[m Add nhwc support for QLinearAveragePool operator (#7656)
[33ma27ef39d8f[m Merged PR 6047693: DML EP fix GetSupportedDeviceDataTypeMask for int64 (and some float64 issues)
[33m37f69fcee5[m Regain performance by caching initializer names in ORTModule (#7685)
[33m19704aedbb[m Update Objective-C API (#7675)
[33m56e993a434[m Bump to rel-1.9.1 (#7684)
[33m32d8278c2f[m reshape fix (#7678)
[33m4b37901f10[m Aten support for rocm (#7680)
[33m4afdc19958[m ROCm optimized layernorm for MI100 (#7682)
[33md90a99aad5[m Fix the build on dev machines by replacing std::tuple with two arguments with std::pair (#7683)
[33m7bb3f243ff[m Revert (#7663)
[33m1ab8a95eb6[m Bind existing SessionOptions and RunOptions in Javascript API with WebAssembly (#7621)
[33m333318af04[m [CoreML EP] add clip support (#7666)
[33m46246f1bbd[m Add nhwc transformer support and unittest for qlinear concat. (#7587)
[33m3a407b40dd[m Add the missing source file to the target onnxruntime_test_debug_nodeâ€¦ (#7676)
[33m31ca21b782[m Replace Where Grad "Mul" with "Where" (#7672)
[33mb4e8e9b004[m Add  DnnlOpManager (#7521)
[33mdac24f7d63[m Add ATenOp and call aten::embedding and its Backward Op from ORT (#7590)
[33mc808621e9d[m Better detection of MPI using FindMPI (#7653)
[33ma47a234b7e[m Add minsdkver for AAR and AndroidTest (#7669)
[33m760828b2d4[m Add FromProviderOptions()/ToProviderOptions() for TensorRT EP (#7654)
[33m1c7e683a95[m Add Squeeze and Unsqueeze support for quantizaton tools. (#7673)
[33m31d4413919[m fix quantization tool bug when existing pass through only input (#7674)
[33m7cb9077043[m Fix readme page (#7659)
[33m9241f62e4c[m enable MatMulScale and cast propagation for ROCm EP. (#7657)
[33m5d9885f706[m Fix BadNames. (#7658)
[33m8deca24b1a[m Don't remove an unused initializer if it is overridable. (#7649)
[33mc5aeaa9419[m Support for unused model initializers (#7631)
[33m88d2fc8f1e[m ONNX Runtime React Native Library (#7564)
[33m29172d8f54[m Setup EP Dashboard (#7321)
[33mce8473a4ea[m Add script to build fat iOS framework (#7607)
[33md39db89fbb[m Add info on some additional pytorch models that were added to the test models. No new operators are required. (#7644)
[33m5276bab268[m Fail model loading if node input is a missing value (#7459)
[33m90c65ac171[m Fix a bug in inference_session.cc (#7639)
[33m69d1db83ac[m Enable bitcode for iOS by default (#7640)
[33m9f69b2f291[m Added InsertAndReduce strategy to PropagateCastOps transformation in addition to FloodFill strategy (#7454)
[33m08fbfe9607[m Resolve issue where a registered buffer was parsed incorrectly as a user input (#7617)
[33ma684e9aa52[m Add pre-training transform to convert BatchNorm to BatchNormInternal (#7539)
[33mde4089f8cb[m GCC11/Libstdc++11 Compilation fixes  (#7599)
[33m16297a8e61[m Implement NCHWc Upsample linear mode (#7623)
[33mec885040ef[m [js] specify correct config for terser (#7627)
[33mc5d28097e8[m [js/web] adding conv fuse logic (#7604)
[33m88c95ef06b[m Support for primitive types in ortmodule (#7588)
[33m4b691a5c0d[m Add ability for memory arenas to "shrink" periodically (#7284)
[33m803837df63[m Add 4dmask support for attention cuda kernel  (#7591)
[33m55c086b664[m symbolic shape inference improvements for contrib ops (#7606)
[33m5a5fec0452[m Fix logs getting skipped in single-line conditionals. (#7589)
[33me91bdbde20[m Add myself to CODEOWNERS for ORTModule python code (#7453)
[33m41e370c2b3[m Update protobuf to 3.16 (#7616)
[33m3c39fcc1fa[m [js/web] port fixes for packed concat over to ort repo (#7605)
[33mbdefc6c4d8[m [js/web] support multi-thread for wasm backend (#7601)
[33m8ab0deceed[m Add DLA support to TensorRT EP (#7532)
[33m9fc4116d51[m Use ASSERT_STATUS_OK so the error message is output if there's a failure. (#7515)
[33m0c91b643fe[m Bugfix for Scatter and GatherElementsGrad (#7593)
[33mcea0ea1591[m [OpenVINO-EP] Remove support for 2020.4 (#7580)
[33mbdb2ed7864[m Revert "Add log to allow serving platforms to quantify ORT usage. (#7476)" (#7598)
[33md88da44066[m Allow flexible order of Add inputs in Attention fusion (#7565)
[33m4896744638[m Improve CPU node placement logic to avoid Memcpys (#7427)
[33m097bab8d1e[m Cleanup a change to ExecutionFrame a little (#7576)
[33mbe2a3046fe[m Disable telemetry log for training builds (#7585)
[33m5413eaa5e4[m Additional cmake changes for OpenVINO build (#7579)
[33m830f0b45d0[m Update Objective-C API (#7567)
[33mf3a70f1aec[m Ignore invalid input argument to install_os_deps.sh (#7566)
[33m9465948715[m Quantization tools using one more extra_options on interface. (#7293)
[33ma284eede64[m Fix Linux CPU pipeline (#7584)
[33m8a9ddfe963[m Longformer Attention non-determinism issue fix (#7574)
[33m94c97ac8c2[m Fix compiler warnings treated as errors in GistEncodeDecode. (#7568)
[33m91985ab03d[m add use_dml (#7569)
[33m2f0479780e[m Improves NonMaxSuppression on CPU (#7557)
[33made6ed51eb[m Speed up Reduce operators for consecutive reduced axes (#7206)
[33m053bada30f[m Add support for setting shape inference function on fused nodes (#7007)
[33md8cf960412[m Add android test app to validate Java API for ORT-Mobile Android (#7477)
[33mf6cefc92e2[m Add quantized value map after quantize input node added. (#7558)
[33ma647da3e1a[m Fix 2 input Gemm grad (#7561)
[33md812354ebd[m Tile grad fix  (#7556)
[33me05528a365[m Update Android AAR packaging pipeline script (#7559)
[33m71ff6ff2ec[m Disable NNAPI support for dynamic input shape, add warning logs (#7439)
[33mc3c4db2c1b[m Upgrade GIST memory compression nodes, kernels, optimizer rule, and cli (#6262)
[33m9456bf420e[m Merged PR 6006709: Merge onnxruntime's master with DmlDev
[33mc1ed647170[m ORTModule enable run_symbolic_shape_infer by default (#7423)
[33ma94a893d5e[m Update SessionOptions.cs (#7540)
[33m7290270788[m Merge remote-tracking branch 'mainstream/master' into DmlDev
[33m594dde2647[m Validate that the conversion script from the python package can be used to convert models. (#7517)
[33m898fff702c[m compatibility was broken for myriad config parameter (#7349)
[33m3c9ece4a11[m [transformers optimizer] catch symbolic shape inference exception and clean up (#7560)
[33mfaea7a222d[m linux trt package pipeline (#7537)
[33m8eaa4c33e2[m [js] fix library bundling and some trivial improvement (#7550)
[33m731f9e5033[m Fix symbolic shape inference for Unsqueeze (#7555)
[33m418623355a[m disable logging for WASM in inference session ctor (#7545)
[33m8b6602ae68[m Refactor provider test utils to prepare for expansion. (#7538)
[33mcab84d902e[m Install and use conda on ortmodule CI pipelines (#7530)
[33mad15811ade[m Add QDQ support for MatMulIntegerToFloat, Gather and Transpose (#7500)
[33m830d9e54dd[m Add script to dump initializer, NodeArg, Node and subgraph info from an ORT format model (#7516)
[33m3600c3e66e[m [js/web] integrate latest changes from onnxjs (#7535)
[33m9c0e5954cb[m Output Tensor Shape Validation b/w ONNX inference and ORT  (#7252)
[33me344a583b0[m updated sampleTolerance of model fp16_inception_v1 for GPU execution provider (#7533)
[33mb0a3b501fe[m Add function body for Gelu and FastGelu (#7496)
[33m7079dfb93d[m [wasm] fix and unify webassembly target name (#7549)
[33m2e09d9921a[m "Sticky" allocation of worker threads (#7551)
[33m6714f2f85d[m Improve tol value logging in ORTModule test (#7544)
[33md1cb8c9dc9[m Support negative indices and fix bound checking in symbolic shape inference for Slice (#7401)
[33m8e3cdf0452[m Use unicode apis for loadlibrary (#7523)
[33madd4e4225b[m [js/web] fix pacakge metadata of onnxruntime-web (#7543)
[33m97de078c24[m [js/node] fix pacakge metadata of onnxruntime-node (#7542)
[33m79dc7d3e50[m [js/common] revise TSDoc of some interfaces (#7541)
[33m8ba6ed953f[m Fix batch norm training op on CPU (#6946)
[33m94c4c44bfc[m Enable Microsoft.Ai.MachineLearning package to work on .NET5 down to 17763 Windows SDK (#7522)
[33m9f1e61be92[m Check whether nvcc supports -Wstrict-aliasing before adding the flag. (#7509)
[33m00882ce495[m Set CMAKE_CUDA_STANDARD to 14 because we are using std::make_unique (#7534)
[33m93e93d0851[m Merge pull request #7519 from microsoft/user/dwayner/ort1.8dml1.5.1
[33m668a65f1a7[m Complete GetGlobalAveragePoolGradient  (#7514)
[33m9c1900866a[m Revert ""Sticky" allocation of worker threads (#7372)"
[33m9ba9da0c95[m Fix unused registered buffers issue on ORTModule (#7525)
[33m54db6648af[m kerne invoker api for eager mode (#7473)
[33mdfca1a09d5[m Add Thread Spinning Session Option in WinML (#7498)
[33me6f66f660c[m missed change for external allocator in ROCm EP. (#7505)
[33m10e67b7340[m Merged PR 5918130: Add activation fusions missing in newer opsets
[33m06a2b0401a[m Merged PR 5873494: Resize support nearest_mode floor in DML EP
[33me6f35cc132[m Merged PR 5866812: Decompose unsupported QLinearSigmoid operation in DML EP
[33mf87527c0df[m Merged PR 5861108: Allow nodes in DML graph partitions with empty shapes on constant CPU inputs
[33m915931384a[m Merged PR 5807585: Remove support for strided 64-bit emulation in DML's Cast kernel
[33m70e67ddd2b[m Update DirectML version to 1.5.1 and enable ARM/ARM64 builds with DML (#7511)
[33m00aaa6dabb[m update CI for onnxruntime-web (#7497)
[33m0d107bbb73[m Fix CUDA 10.2 pipeline (#7508)
[33md6df5764d7[m Android package infrastructure (#7430)
[33m3d92723d1c[m "Sticky" allocation of worker threads (#7372)
[33mec04b6203b[m Remove conditional compilation of std::is_trivially_copyable since we are no longer supporting GCC 4. (#7504)
[33m1012535dab[m Change onnxruntime::make_unique to std::make_unique (#7502)
[33md337fa90e7[m Propagate QDQ only when scale and zp are scalar (#7492)
[33me255506bcd[m Add another input validation to ReverseSequence (#7445)
[33m994c2ed420[m GPT2 one step beam search update with configuration support (#7425)
[33m6358e96b63[m Added OpenVINO 2021.4 support (#7470)
[33m7b003967b1[m Add static code analyzer to Windows CPU/GPU CI builds and fix the warnings (#7489)
[33m2b0bbfd1a8[m MLAS: add SSE 4.1 u8s8 kernel (#7490)
[33me73c3e0651[m rollback the GetRuntimePath impl for linux (#7488)
[33m0dbe51b002[m Enable TRT EP for C# (#7482)
[33m3c7c728989[m cmake: Add regex pattern for POWER architecture (#7494)
[33mf13b378995[m Re-disable tests (#7495)
[33me6a3308db7[m Optimize cuComputeGradInput performance. (#7479)
[33m6773b4f5dd[m Fix implicit-exception-spec-mismatch warning. (#7481) (#7483)
[33m3ee63beafa[m Fix user input order before ORTModule feed it to backend (#7456)
[33md68cedfa85[m Fix some C/C++ warnings in the jni part (#7385)
[33mab373d6f03[m Lifhuan/force trt sequential (#7440)
[33mc584d48283[m Add sequence identity for opset 14 & fix sequence insert (#7335)
[33m22d7cde725[m Fix a 'Squeeze' related issue in symbolic_shape_infer.py (#7380)
[33m674915208a[m Fixes RelWithDebInfo build issue on windows for OV-EP (#7471)
[33m044c78f089[m Add function body to LayerNorm (#7378)
[33mda5c9263e9[m Add log to allow serving platforms to quantify ORT usage. (#7476)
[33m8e21329206[m Update nuphar notebook model download url (#7475)
[33m196e6702ad[m to support multiple cuda versions in published onnxruntime-training package  (#7468)
[33me64e30ee0d[m Improve ConvTranspose by transposing const filter during prepacking. (#7388)
[33m9921f94ff6[m Merged PR 5982350: Latest Github master into Dmldev
[33m988ea0518e[m Merge remote-tracking branch 'upstream/master' into user/rylai/latest_ort
[33md21304ceb0[m Initial Objective-C API (#7366)
[33m78e583d08c[m Add CMAKE_CUDA_ARCHITECTURES=52 to TensorRT CI pipelines (#7455)
[33mc2418a1f42[m [wasm] fix memory info creation (#7461)
[33m4cbd2cce9b[m . (#7466)
[33m4ebc9c3b5e[m [JS] onnxruntime-web (#7394)
[33md13e5b2fd9[m NCHWc: ReorderInput improvements (#7442)
[33m82108b18e3[m Partial graph execution perf improvements. (#7438)
[33m0702a14ee7[m Add pytorch version check before loading Python ONNX Runtime training module (#7377)
[33m4804ede501[m Update build docker image cache cleanup build definition (#7452)
[33m40568d8821[m Wait for dispatch done in RunParallelSection to fix random TP UT crash (#7443)
[33mada0fbbd2d[m Implement qlinear concat and unit test. (#7341)
[33mb5592856a7[m Remove thread pool's cancel method and suppress some warnings (#7411)
[33m368e4a324f[m SqueezeGrad Bugfix (#7412)
[33mca9b3f18e9[m Explicitly pass cuda stream to thrust function rather than use cuda default stream implicitly (#7414)
[33mb9cbbc41ff[m dnnl matmul tensor dimension check (#7383)
[33mafe912d47c[m Reduce perf gap between thread pool and omp (#7333)
[33m410a81b21b[m Add support for ORTModule to execute the graph when ONNX drops unusedâ€¦ (#7424)
[33mf4f2cc1a00[m Add batch interface to floating point GEMM (#7323)
[33m7a3c1787af[m Add CI pipeline to publish Python training package targeting Rocm (#7417)
[33m34ebf7d3dd[m Partial graph execution made simple. (#7324)
[33m5208231126[m Fix some warnings in our CUDA code (#7436)
[33m8889e717eb[m add gather elements (#7435)
[33mef72764960[m Build would fail when nccl is not under standard path (--nccl_home) (#7402)
[33m9f683bae78[m Revert the TRT change and move the build to a new pool (#7434)
[33m979d63159b[m Add level two optimizations for constant propagation transformation. (#7410)
[33mf1c3f3fcc1[m TRT EP memory leak fix (#7415)
[33m043883b52d[m [CoreML EP] Add Gemm/MatMul support (#7403)
[33me7912736b9[m Add qdq propagation support (#7404)
[33m1fa6d8fe1c[m support loading external execution provider from python frontend (#7332)
[33m75e054cd33[m pick onnx release candidate (#7177)
[33md414039189[m Add ios coreml ci, and speedup ios ci run (#7420)
[33md67c86265b[m Enabled fp16-inception-v1 test (#7406)
[33mb56dd037d3[m increase timeout for nodejs binding test (#7422)
[33m4c8513a627[m SimplifiedLayerNormalization kernel for ROCM EP (#7409)
[33m6822ae95ec[m Reduce the number of TensorRT tests needed to run (#7419)
[33m771a6d235b[m Fix IsContiguousTensor check on backend (#7391)
[33mafa7b23609[m Update docs/ContribOperators.md and the script that generates it. (#7399)
[33m1bbe538379[m Update references
[33maa1ce726aa[m Remove unnecessary encoding step
[33m65b2b87f83[m Update CI build docker images (#7386)
[33m09313d9e1f[m Added GreaterOrEqual and LessOrEqual Ops to RocmEP (#7398)
[33mb4cfa88bf7[m Update protobuf to the latest version (#7396)
[33m243713c464[m Upload detailed code coverage result to azure blob storage (#7392)
[33m16ca7677e6[m Relax ConvGrad Test tol (#7393)
[33mb5493d724c[m Update rnn_helpers.cc: add #ifdef to DumpMatrixImpl  (#7389)
[33m7b11283af0[m Add ability to allocate initialized tensor memory from non-arena memory (#7267)
[33m8421124344[m Add support to **kwargs in ORTModule forward() method (#7360)
[33m76cc118dbe[m Gemm transpose fusion (#7306)
[33m913ea8264b[m GPT2 with one step beam search (#7163)
[33m1a3ddf0714[m Add gradient registration and tests for Min/Max (#7217)
[33mce7ff27bac[m Fix perf issue in  Conv CUDA kernel (#7348)
[33mac346a1b90[m Modify SimplifiedLayerNormFusion to allow fusion in the presence of Casts optionally (#7352)
[33m7abe1fd392[m Identity elimination with graph output (#7312)
[33m265db2ad96[m Fix Microsoft.AI.MachineLearning .NET5 publishing and C# Store Release build (#7373)
[33mbb1e417da0[m Add logging support to Cast Propagation transformation from python (#7353)
[33me9286aa9a9[m Merged PR 5950370: Unsquash merge from github Onnxruntime into dmldev
[33mfc88a7aad5[m Merge commit 'ef1aaa367aab7c0c384081678ae506e658be864f' into user/rylai/fix_unsquash_merge
[33m6dda1e0681[m Flag for tensor memory re-use in allocation planner. (#7359)
[33m96cdc65d57[m Fix android CI failure after gradle updated to 7.0 (#7364)
[33m009f342caf[m [JS] refactor Javascript/Typescript libraries in ONNX Runtime (#7308)
[33mded2b08380[m WebAssembly multi-threads support. (#7326)
[33m28e229ac4c[m Enable build dynamic framework for macOS/iOS (#7343)
[33me359220125[m Merged PR 5938615: RI onnxruntime into Dmldev
[33mef1aaa367a[m Adding interface for batched integer gemm (#7249)
[33mf1c1c38d44[m Delete an unused var in nuget pipelines(#7345)
[33maa9ab565f5[m FastGelu fusion for Megatron model (#7344)
[33m0da085ed48[m Propagate Cast operations to maximize lower precision (float16) computation (#7191)
[33mbe79575c6a[m Use built-in reduce_sum() for simple reduction cases, specifically reduce all to a scalar.
[33m3eb2d349a6[m fix typo in scenariotestscppwinrt.cpp (#7334)
[33m87bd836886[m Fixes in symbolic shape inference (#7258)
[33m75d8319286[m Liqun/ort package name2 (#7337)
[33mf62db1a09c[m quantization tools support qlinear average pool (#7309)
[33m4c862c73ed[m for training to use new python package naming convention to explicitlâ€¦ (#7204)
[33m6ceee5d131[m IsInf ReduceSum transform (#7188)
[33mf8a36dd6b3[m Add DropoutGrad function body (#7310)
[33ma5d3a52d1a[m Add Tile grad (#7289)
[33mce9cd6ad9a[m Update usage of generator expression $<COMPILE_LANGUAGE:L1,L2> which is not available in CMake 3.14. (#7318)
[33m2c96050336[m Fix SDL warning (#7331)
[33mf34468a309[m Fix TRT EP memory leak (#7195 revisited) (#7276)
[33mf616ea632e[m remove mlas unittest.cpp which is already refactored. (#7319)
[33mfce67e2b9b[m Create Android Package pipeline (#7295)
[33mb7c89ce78a[m User/sheilk/add api usage telemetry (#7320)
[33m8cafd2fb2c[m Merged PR 5918130: Add activation fusions missing in newer opsets
[33m4971310d6a[m Fix split op in the way it deals with the optional input (#7302)
[33m61ba9ac1bb[m matmul in dnnl (#7311)
[33m21c282ed54[m yolov3 accuracy (#7235)
[33m6334c29240[m[33m ([m[1;31morigin/stevenlix/trtplugin[m[33m)[m Zhalei/mlas test (#7213)
[33m75c0192e4f[m enable more unit tests for ROCM EP (#7307)
[33mf27f5afd8a[m NCHWc: Support "sizes" argument for Resize transform (#7290)
[33m2edf29552d[m Add Optype to type mismatch message (#7305)
[33mb221a4fd86[m Better error message when ORTModule used with torch.DataParallel (#7287)
[33mc22963c23d[m Polish Lamb Kernel (#7299)
[33m711cc99f4d[m Improve logged message for nodes that are forced to execute on CPU rather than some other EP (usually CUDA) (#7297)
[33m8ad5007f8f[m Polish Adam kernel (#7294)
[33m274e2fea0c[m[33m ([m[1;31morigin/c_charp_cuda[m[33m)[m change half gemm to use compute_32f as default (#7253)
[33ma4fdb4dbd9[m Support transpose by merge Reshape etc into direct xint8 operators. (#7265)
[33m42051c912a[m Narrow profiling scope (#7281)
[33m370f9b88c2[m Enable CoreML EP for minimal extended mode (#7266)
[33m7b4362c21a[m Add support to dynamic positional/keyword input for ORTModule (#7189)
[33m4969431eba[m Fix codeql java warning (#7280)
[33m0d49e53985[m [Symbolic shape infer] fix scalar shape in Expand (#7285)
[33mbc6ef809bb[m NCHWc: avoid buffer reordering around Add nodes (#7279)
[33me14b291ce7[m Enable symbolic shape inference in ORTModule (#7282)
[33md272c8434d[m Suppress tracer warnings from onnx export in ORTModule (#7221)
[33m27e778909d[m [OpenVINO-EP] Enabling save/Load blob feature (#7054)
[33mdef4cc09c7[m Add QGEMM benchmark (#7268)
[33maa2c465143[m Restrict ConvGrad to __CUDA_ARCH__>=700 (#7278)
[33mbeb299e17d[m ConvGrad CUDA Kernel Bugfix (#7273)
[33m844361bc67[m Support eval mode and torch.no_grad context in ORTModule and restructure ortmodule.py (#7162)
[33m025abf996d[m fix for using tensorrt:20.12 base image (#7264)
[33m4bc17ca04e[m CUDA ConvGrad Kernel (#7227)
[33m8219518aa8[m[33m ([m[1;31morigin/raviskolli/ortmodule-t5[m[33m)[m Fix initializer counts when used as graph output (#7260)
[33m2ec452cdad[m Remove ROCM workaround for half-to-double cast.
[33m25e261f196[m Avoid passing zero bias to Gemm in gradients (#7244)
[33m405ca49012[m build ONNXRuntime into WebAssembly (#6478)
[33m2aa89989c4[m Not-where fusion (#7182)
[33m790fc11e60[m QDQ: type conversion and more ops support (#7243)
[33m5d759e182b[m Allocate external Rocm allocator via PyBind (#7148)
[33m6308e709cc[m Update opset for other training graphs to 12. (#7259)
[33ma9ff4c29e5[m Add function body to GeluGrad schema (#7190)
[33mdbcfc4bee6[m Add mlas_bench tools. Starting with sconv bench and sgemm bench. (#7139)
[33m56b22c1c6b[m Fix assert that the tensor's device type is 'cpu' #7248
[33me9ffcfa247[m Add cuda kernels for GreaterOrEqual, LessOrEqual, Where; modify Clip to avoid memcpy (#7187)
[33mc85657cfd7[m Update test_training_model.onnx to opset 12. (#7251)
[33ma9dbb511fb[m MLAS: fix qgemm bus error with Android + ARM32 (#7250)
[33mfb40602ea2[m Mem trt (#6868)
[33m2fcd69d644[m Cleanup build.py (#7245)
[33m5bd192c439[m Update ContribOperators.md (#7246)
[33m3b16afc0db[m Make dW optional for convgrad (#7083)
[33mc5973fbbac[m Update the build script for Android AAR package (#7229)
[33m9f14af9809[m Add BERT-L perf regression test on MI100 and re-enable batch size test (#7240)
[33m10102c09b6[m Add better model test error messaging (#7239)
[33me7c5dcd572[m Fix Zip-Nuget-Java Packaging Pipeline (#7208)
[33m3ee9b0ec4d[m Add detailed assertion error message (#7232)
[33m008065aab1[m Update README.md (#7043)
[33m2b8513539e[m Div mul fusion (#7183)
[33m74ee24cf7f[m rename cuda_mem_limit and hip_mem_limit to gpu_mem_limit for both CUDA EP and ROCm EP (#7226)
[33m68b12a6179[m Support for saving and loading pytorch compatible state dictionaries (#7220)
[33m8d737f9770[m handle optional input in quant topo sort (#7223)
[33m59b57d8322[m HSA_NO_SCRATCH_RECLAIM and RCCL_ALLTOALL_KERNEL_DISABLE are not needed for ROCm 4.1 (#7224)
[33mba5f056b09[m move trt_profile to TensorrtFuncState and reuse it (#7195)
[33mef88dc912c[m enable more unit tests for ROCM EP (#7222)
[33mafbbeaa30a[m [NNAPI/CoreML EP] Add Onnx opset 14 support (#7211)
[33ma98c2ebb8c[m Enable saving optimized models in OrtModule (#7214)
[33mebde320950[m Add cupti path for python gpu packaging pipeline (#7200)
[33m2d352056cf[m Support SkipLayerNorm for ROCm EP (#7210)
[33ma3f17c8b0d[m update lamb and GatherGrad kernel for ROCm EP (#7184)
[33m17f91ff410[m remove un-needed header file. (#7193)
[33m5a6d477625[m Make IDataTransfer be directly shared with shared providers (#7215)
[33m0ebeaf529d[m Check kernel def hashes (#7120)
[33m48fcddd2c5[m Merged PR 5873494: Resize support nearest_mode floor in DML EP
[33m15c67ddbf0[m Make output 1 of ConcatTraining Optional and place on CPU (#7199)
[33m4543459984[m MIOpen supports MIOPEN_REDUCE_TENSOR_AVG now.
[33m34a8b22186[m disable prepacking in training (#7201)
[33m52bcef4d4f[m Openvino ep 2021.3 (#7180)
[33m249a2c14ef[m Pin version of pytorch to 1.8.1 for ORTModule CI pipeline (#7167)
[33mfc6ac5bfac[m dnnl fixes (#7202)
[33m329fd03bb4[m Add int32_t as required type to some operators  (#7192)
[33m9a8991e9b6[m Merged PR 5866671: Move onnxruntime arm64x forwarder
[33m04679e31ab[m Specify CUDA compute capability 7.5 in Linux GPU build (#7203)
[33m0e0dd50e39[m Support int32 type for TopK CPU op (#7089)
[33m057de97d92[m Merged PR 5866812: Decompose unsupported QLinearSigmoid operation in DML EP
[33m56d2c4baa2[m Merged PR 5861108: Allow nodes in DML graph partitions with empty shapes on constant CPU inputs
[33mb370ddbf5e[m Removes unnecessary transpose in operator Einsum (#7141)
[33md500c5952b[m Add Android AAR packaging script for ORT-Mobile (#7138)
[33m0fdef1bf47[m [Node.js binding] upgrade y18n to v4.0.1 (#7185)
[33m45cb0cae8c[m Adding TorchEmbedding contrib op (#7136)
[33me545604499[m . (#7165)
[33md880578537[m Exclude cpuid.h from Mac non x86 arch (#7166)
[33m0ccfe6c86a[m Enable type reduction for Scatter/ScatterElements CPU kernels (#7171)
[33m07201bac7a[m expose session option and provider options (#7112)
[33mc4ebc60870[m sort quantized nodes in topo logical order (#7172)
[33m4f30341253[m Check the count of DequantizeLinear for matmul (#7174)
[33ma01334ba56[m MLAS: activate udot kernel on Windows ARM64 (#7169)
[33mbbcf419ac6[m Move the Windows GPU machine pool of Onnxruntime packaging pipelines to a new one (#7161)
[33md1acdd4f4b[m Support building ARM64EC onnxruntime.dll (#6999)
[33m77c19436c0[m add a notebook for mobilenetv2 quantization (#7164)
[33maeca7c2940[m[33m ([m[1;31morigin/wangye/deviceprofiler[m[33m)[m Cuda Profiler  (#7110)
[33mb22e60bd44[m pull onnx latest commit (#7102)
[33m9297527b7a[m Enable NHWC transformer when generating ORT format model (#7126)
[33m90294b9c43[m Fix Transpose and MatMul fusion code to check the input datatypes as â€¦ (#7147)
[33m65ce5f07b3[m add Dockerfile.rocm4.1.pytorch (#7152)
[33mf27835c4de[m Disable batch size test for AMD CI pipeline after agent upgrade to Rocm 4.1 (#7153)
[33mf365f1d967[m Resize_impl.cu: Change _Round to roundf (#7140)
[33m63d9d5afd3[m Fix Pad and Gather incorrect usage of HasType helpers. (#7146)
[33mab86634c36[m Address comments from ORTModule master merge (#7101)
[33ma8f0ab9c5f[m Merged PR 5846998: Fix warnings level for DML EP
[33ma01f15198c[m Add support for large models (#7113)
[33m2b31b80b1f[m icnrease timeout (#7145)
[33m3771e0bf10[m update bert quantization notebook (#7137)
[33mc9b29fbd06[m Disable MatmulTransposeFusion for CPU EP (#7135)
[33m2bf54bcaa2[m Fix bugs in sparsify script (#7134)
[33mcc0e7bee76[m Add function-body to SoftmaxGrad (#6988)
[33m53c123dcee[m Add session option configuration to enable GeluApproximation (#7131)
[33m39bd192d33[m Merged PR 5837692: Merge latest from upstream
[33m8e54b76e2d[m QDQ implementation (#7033)
[33m865c67611c[m Exclude profiler from minimal build (#7115)
[33mfda0470683[m Add New AllocKind for YieldOp Outputs, Run YieldOp with InferenceSession in UT (#7125)
[33m1c8d874412[m Promote BiasDropout from orttraining to onnxruntime (#7116)
[33m293774fbeb[m Merge remote-tracking branch 'upstream/master' into p/adtsai/merge
[33mcd67f12add[m Move IOBinding and RunOptions to ctx (#7028)
[33m2e3bbad19f[m Move TensorRT Windows CI build to the machine pool (#7127)
[33m1c04eec2b1[m [NNAPI EP] Fix error for QLinearAdd with an initializer as input (#7093)
[33m540eac253e[m Deepspeed pipeline parallel and fairscale sharded optimizer test samples with ORTModule (#7078)
[33m6987106bf5[m Add missing Python dependencies for ORT training (#7104)
[33mfffe16cb43[m Fix a bug in quant GEMM and add an unit test (#7111)
[33mb07e168a2b[m Delete an unused file: download_test_data.py (#7109)
[33m5cb8934459[m update Dockerfile for workaround for issue in RCCL for rocm4.0 (#7108)
[33mc0994fdfbb[m Update ORTTrainer to permit Rocm and permit export of opset 13 (#7059)
[33m53392664d3[m Enable type reduction for Shrink, Sign, SplitToSequence CPU kernels (#7090)
[33mc3310efdcd[m Support for models having partially non trainable parameters (#7058)
[33ma7a2a16edd[m Pass arguments to azure_scale_set_vm_mount_test_data from perf test ci pipeline (#7094)
[33mc965878a69[m fix a bug in global average pool and add unit test (#6913)
[33m230c137460[m cmake: support install target with generated pkg-config file (#7076)
[33m309885b08d[m upload ort-gpu-training python nightly package to azure feed (#6998)
[33m416ee3c4d2[m MLAS: add 32-bit transpose support (#7092)
[33m5ec0e71542[m ORTModule support non-differentiable module output (#7048)
[33mbe45a59d99[m Make our CUDA code be compatible with the latest VS2019 update (#7062)
[33mdf6a68f59c[m Fix fallback providers for InferenceSession (#7091)
[33m529da3b003[m Thread pool profiler (#6748)
[33m867804bea1[m Add auto doc gen for ORTModule API during CI build (#7046)
[33m3b58fc7b97[m Add types support for Sparse Initializer in Onnxruntime (#7004)
[33m4a3d1176d7[m adding ngraph_DIR to fix build (#6975)
[33m4cbb8e166a[m Update kernel def hashing (#7019)
[33m06df28748f[m Change tabs to spaces in Windows.AI.MachineLearning.idl (#7088)
[33m79ba045d74[m Enabled rocm support for graph transformations (#7057)
[33mb2c6617b0f[m Use 'as_scalar' when checking the 'cond' value of 'If' (#7063)
[33mcec919bae9[m handle 8 bit uint dlpack tensor (#7069)
[33m8d5bfdeb47[m Increase timeout for Android CI pipeline by 30 minutes. (#7065)
[33m8c3b59a026[m Quantization calibration refactor (#6893)
[33m701e73b5b8[m Move Linux minimal build CI pipeline to the new Linux machine pool (#7050)
[33m8bc275e93f[m Enhance Transpose, Cast and MatMul fusion when Cast and/or Fusion feeds multiple nodes.  (#7021)
[33m1a1dd4843d[m Enable opset 13 for Rocm (#7047)
[33m7c7d6debe6[m [CoreML EP] Add Resize Support (#7015)
[33m3d37a3c1d3[m Merged PR 5807585: Remove support for strided 64-bit emulation in DML's Cast kernel
[33m897a0b9839[m Merged PR 5807395: Add DML kernels for QLinearAdd (com.microsoft namespace)  and DynamicQuantizeLinear
[33m514444d820[m Fix pipeline generating python documentation (#7027)
[33mc60ef62190[m Update ORTModule feature with remaining PRs from feature branch (#7040)
[33m4fd9fef9ee[m Support HuggingFace Models Converted From tf2onnx in Python Script  (#6985)
[33m934bb52cfb[m Merged PR 5805461: Add ARM64X forwarder libs
[33mbc3aea4be0[m Capitalize DLL name
[33m4f5d6a0e4d[m Add ARM64X forwarder libs
[33m335edaa2c4[m Merge pull request #6973 from microsoft/thiagofc/merge-ortmodule-into-master
[33m03885af5a0[m Adding prepacking to QLinearMatMul (#6980)
[33m90642e7eac[m MLAS: more code cleanup (#7036)
[33m8e0970a020[m dnnl format tag fix (#6943)
[33m0f9383e583[m [NNAPI EP] Add support of QlinearAveragePool (#6915)
[33ma0fdabd23f[m Rename all of the ONNX_NAMESPACE types for shared providers to be back in the ONNX_NAMESPACE with their original names. (#7034)
[33m73d085ccdd[m add slow test (#7035)
[33m3348b8485f[m Post merge update for ORTModule
[33med2d441a2e[m Update ORT server build pipeline (#7030)
[33m2e38bf5e23[m add TensorRT configuration to OrtProviderOptions (#6979)
[33m783acb144f[m Ignored return value SDL bug fix (#6451)
[33m2361cb99b6[m Remove CentOS CI pipeline (#6997)
[33m975e4efb8a[m Package ARM artifacts (#6805)
[33m3f0e50f14d[m Cleanup in RoiAlign (#7012)
[33m087d96200d[m HIP_CLANG_FLAGS replaces HIP_HCC_FLAGS for ROCm later than 4.0 (#6955)
[33m5480f8dd1d[m MLAS: misc cleanup (#7013)
[33m4e670f7ab1[m Support larger hidden size in Attention Cuda kernel (#7002)
[33m27ac88201a[m Support a CPU kernel for Celu (#6995)
[33md0cca35308[m Add README for docs (#6626)
[33me5e922ec1e[m Fix some warning option override warnings from dependencies. (#6983)
[33m4c9ccb0f1a[m [OpenVino] getcapability design (#6863)
[33m4161758058[m Remove openmp related packaging pipeline (#6991)
[33mc588d5d13a[m Add rocm execution provider to prover_list (#6306)
[33m031587814b[m Add support to save onnx graph with external initializers file. (#6911)
[33m12b5ab3bab[m Update CUDA custom op unit tests to account for recent ORT change (#6971)
[33m694389a85d[m Automate generation of python documentation (#6909)
[33mf7df2f805b[m Resolve HTTP Error 503: Service Unavailable for MNIST dataset
[33maa60a8368f[m Update type reduction operator type usage processors set. (#6976)
[33mb57a85d863[m Support symbolic shape infer in transformers tool (#6899)
[33mf4796e1953[m Enable type reduction for Range, ReverseSequence, ScatterND, Split, and Unique CPU kernels. (#6963)
[33m4a4488baae[m Release buffers for prepacked tensors (#6820)
[33m50973de1a2[m Merged PR 5691446: QLinear Graph Support
[33m2f307dd223[m Fix possible fd leak in NNAPI (#6966)
[33m89d450697b[m Introduce ORTModule training API to ONNX Runtime
[33m9f84819f32[m Update onnxruntime_perf_test.exe to accept free dimension overrides (#6962)
[33mf723ff2285[m fixed type to experimental session constructor (#6950)
[33m4884eee642[m Attention fusion detect num_heads and hidden_size automatically (#6920)
[33mce403eea98[m Add *args support for ORTModule inputs (#6883)
[33macfe7ac4ce[m Implement QLinearAveragePool with unit tests. (#6896)
[33m1e13e2666e[m Support ROCM EP for ORTModule (#6967)
[33ma8b897f710[m MLAS: quantized GEMM update (#6916)
[33mbc319bd7aa[m Fix warning from setting multiple MSVC warning level options. (#6917)
[33m8468099f93[m Use DLPack for Graph Inputs and External Outputs of YieldOp (#6968)
[33m3f579facbc[m Relax atol for some ORTModule UTs (#6969)
[33md5ed3e7fba[m Enable type reduction in EyeLike, Mod, random.cc CPU kernels. (#6960)
[33m89916fdb05[m fix stream sync issue (#6954)
[33mbdaea1d9ae[m Update baseline due to loss scale fix (#6948)
[33m743a93faf3[m Fix broken link in server usage and remove absolute path from dockerfiles readme (#6926)
[33m534adbb065[m Support ORTModule on ROCm EP (#6945)
[33m3b2847b2d8[m Add UT correctness and address comments for previous symbolic shape PR (#6930)
[33mba51774a1f[m Add GPU support for DNNL endpoint (#6741)
[33m5303b33f69[m Clean ORTModule dev branch (#6944)
[33m48eebed869[m Interchange Cast and Transpose operations to facilitate Transpose-MatMul fusion (#6924)
[33m91c6a330c0[m Add UseCount for External Outputs (#6894)
[33mc8e2e3191b[m Support parsing an array of values stored as an attribute in a custom op (#6878)
[33me64eff1f13[m Enable build with bitcode for iOS (#6905)
[33m73fe1f2deb[m Rename op kernel type control 'supported types' to 'default types'. (#6886)
[33mf1ade14e44[m Assert that the data is on the same device as ORTModule (#6942)
[33m67c67408c4[m Only set _native folder for Microsoft.AI.MachineLearning package (#6939)
[33mbc27652188[m MLAS: workaround LLVM x86 assembler (#6922)
[33mb89f52c277[m Add tests of Attention and QAttention for pruned model (#6914)
[33mf2f60eed59[m Fix broken Java API link (#6826)
[33m15d81fb63a[m Enable type reduction for Clip, MaxPool, and Pad CPU kernels. (#6918)
[33mb6c4a7ac54[m Support required types when excluding typed registrations (#6871)
[33mde6e66f3d4[m Fix loss scaling when running ORTTrainer with BERT under mixed-precision mode (#6932)
[33m56c5620fd2[m Disable Materializing Grads (#6822)
[33mdfc7c18e31[m Introducing TrainingAgent interface to performance training using YieldOp (#6898)
[33m601e04fb27[m[33m ([m[1;31morigin/stevenlix/mmcustomop[m[33m)[m update Readme (#6903)
[33m79f832c682[m Separate requirements.txt file for ORTModule pipelines (#6879)
[33mac4d615553[m Enable priority-based execution order as default to support inputs with symbolic/dynamic shape (#6892)
[33m9126faa35b[m Ability to fuse non-square (pruned) attention weights for BERT-like models (#6850)
[33mf986ffcb5f[m move pipeline file and change relative path (#6882)
[33m107c9672fd[m No such file or directory with  --use_external_data_form and int8 (#6867)
[33m679718b12f[m Configure session thread pool spinning preference (#6895)
[33m8f1786d5d2[m Save output tensors in bert_test_data tool (#6872)
[33mfa8d1b44b8[m Fix app packaging in UWP (#6804)
[33m7915b6709a[m Revert Gather Grad optimization in PR 6381 targeted for Rocm (#6880)
[33m54cdb6af71[m Add check that the first 2 Loop subgraph inputs have an shape (could be explicit or inferred) as we need to know the rank the subgraph expects. Other inputs to the subgraph are more opaque so we can just pass them through. (#6891)
[33mb429edcd45[m Merge pull request #6890 from microsoft/bmeswani/merge_master_onto_ortmodule
[33maa93f2e236[m move SetOutputMLValue from op_kernel.h to op_kernel_context.h
[33md5667554e6[m Merge branch 'master' of github.com:microsoft/onnxruntime into bmeswani/merge_master_onto_ortmodule
[33md01006fc22[m Move constants from heap to stack to avoid randomness on cudnn function (#6869)
[33m749e6a08a6[m Add more asserts for ORTModule forward's correctness  (#6887)
[33med1883a97c[m Workaround for HTTP Error 403: Forbidden for MNIST dataset (#6885)
[33mfedb68429c[m [NNAPI EP] Add per-tensor u8s8 support for Qlinear[Conv/MatMul] (#6818)
[33m3c5d811e77[m [CoreML EP] Add [Average/Max]Pool support (#6870)
[33m9a9e741a8c[m Support optional inputs/outputs in custom op development (#6727)
[33mf22f04a109[m Add comment (#6860)
[33m6285ee2398[m Reroute quantization tool readme to /docs page (#6854)
[33m9073f7a5c3[m support opset13 in embednorm (#6866)
[33m0d0eb2c85c[m Change OpKernel class to be shared with shared providers (#6837)
[33m38796ad451[m Refine force CPU fallback logic in the CUDA EP  (#6849)
[33m4238ce341a[m Add External Outputs Flag for YieldOp (#6789)
[33m66df167a73[m Add support for op kernel type control required types, require int64 for some ops (#6832)
[33m36a44d55ed[m Only report Android Baseline binary size for master branch (#6844)
[33m5cf6606964[m [CoreML EP] Add Concat support (#6834)
[33m12edf22f11[m Merge pull request #6838 from microsoft/mzs/ortmodule-api-sync-from-master-210226
[33m2d6e10ba00[m Update Attention and QAttention to support pruned model (#6819)
[33mf71d93ea2b[m Enable PyTorch Lightning basic test on CI (#6809)
[33mca48310d6d[m Merge branch 'master' of https://github.com/microsoft/onnxruntime into mzs/ortmodule-api-sync-from-master-210226
[33mcb8d8464bc[m Do not create compute stream when external CUDA allocator is used. (#6833)
[33mb4b87ac7a0[m update (#6827)
[33m059ed1c241[m Copy forward signature from PyTorch model. (#6777)
[33mc1b0cf6d0b[m Add pipeline to clear the cache for huggingface transormers models (#6813)
[33m355057cf9c[m Added RequiredGrad attribute to YieldOp (#6657)
[33md5175795d2[m Improvements to quantizer: Removed unused qType field, add reshape op (#6179)
[33m3426108739[m Fixed issue in python cmake to update wheel package (#6384)
[33m8a450d523f[m Check gradient correctness in the UTs (#6803)
[33mfa8a9015bd[m Mount hf model cache and use cache for loading hf models (#6810)
[33m99ffffbe6a[m Remove backward workaround from test. (#6811)
[33m46e026e900[m Merged PR 5727374: Github to DmlDev Update  2/25/2021
[33ma134b1f808[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33mb05403d877[m Clear iobinding outputs (#6774)
[33m9b3171e95c[m Make keepdims to its default value when adding ReduceMin/ReduceMax for quantization calibration (#6788)
[33mdb05d53b94[m Setup perf in docker and add features (#6582)
[33md5f292ab73[m fix issues caused by quantize/calibrate changes (#6802)
[33m7465673e33[m [OpenVINO-EP] Find package changes (#6801)
[33m8a148e44fb[m make ci pipeline also run batch and convergence test (#6798)
[33mab1713f5cc[m Fix regression in constant folding optimizer (#6795)
[33m8e200e13fe[m Rewrite ORTModule background task coordination  (#6700)
[33m7ce4075bbd[m Support nested sequence and mapping types in ORTModule (#6791)
[33m40fa40f3ce[m Enable more unit tests for ROCM EP (#6776)
[33maa5cd37ac8[m Refactor device handling and basic support for PyTorch Lightning (#6758)
[33mf4acdb2ecd[m Update transformers benchmark for transformers 4.3.* and ORT 1.7 (#6796)
[33m71a70ecf6e[m Allow 3D ConvTranspose in CUDA execution provider (#6794)
[33m5a473216b7[m [Java] Adds extra providers (#6770)
[33m47c8e9ad28[m Adding fp16 support for Einsum Cuda kernel (#6775)
[33mc02ec38f8a[m [Running CI now] Remove duplicate tests to speed up CI (#6768)
[33m7aa69a1f2a[m Support building python bindings when building unit tests is manually disabled. (#6771)
[33m65ba51d93e[m Re-enable test and increase timeout (#6785)
[33m563218dcda[m Update torchtext usage for pytorch transformer sample (#6767)
[33mb8b41e3775[m Update DirectML 1.4.1 to 1.4.2 for ORT 1.7 (#6780)
[33m09a5d6a9dc[m Update docs/ONNX_Runtime_for_Mobile_Platforms.md with info about op type reduction. (#6747)
[33m5db0c9c648[m Enable CI to cover globally allowed types (#6778)
[33m8703e2c778[m update benchmark_longformer for default test suite (#6772)
[33m8a6f6bc38b[m add --enable_cuda_line_info to build.py (#6773)
[33mf5313cc4ce[m [CoreML EP] Add options to enable CoreML EP only on hardware with Apple Neural Engine (#6765)
[33mee35be0129[m Support specifying globally allowed types from build script (#6677)
[33mc91f314217[m Add robust dependency check for Python package (#6436)
[33m9f7dffb109[m Make it easier to fold MakeString usages to reduce binary size. (#6754)
[33m3bda7f4d36[m Fix longformer parity and perf regression (#6760)
[33m58f3aca95d[m Support keyword arguments for ORTModule (#6539)
[33m47519623cd[m Fix iOS/macOS build warning for inconsistent symbol visibility settings (#6750)
[33mc170061998[m Removed BUILD.md from master as source now lives in gh-pages (#6709)
[33m20d6613efb[m Add direct link to build instructions on readme (#6729)
[33ma25c8e52a9[m fix link to samples in nodejs README (#6746)
[33m67e7a9c02d[m Merged PR 5703823: GitHub RI OnnxRuntime to DmlDev
[33m79b966b01a[m . (#6751)
[33m609d0ec953[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33m1a2f1bd23a[m Enable external CUDA allocator in ORTModule. (#6745)
[33m39d182f7fc[m ORTModule - FastGeluFusion/fp16 fix and minor LayerNormFusion cleanup (#6734)
[33mfb3f1f5cc1[m Enable custom ops on ORTModule (#6740)
[33m67c478ede4[m Entropy method for calibration-based quantization (#6619)
[33m3722dd2692[m Update docs MCR image publishing policy change (#6743)
[33m53eb948f4c[m Upgrade TensorRT to v7.2.2 (#6452)
[33mb7b5612159[m Merge pull request #6742 from microsoft/mzs/sync-from-master
[33mb1a12b49b7[m Avoid removing constant weight that is graph output (#6735)
[33mea3aee4d5f[m Bumping up version to 1.7 (#6736)
[33m40dda452cf[m Merge branch 'master' of https://github.com/microsoft/onnxruntime into mzs/sync-from-master
[33me44ac6524f[m Plug n Allocate with external CUDA allocator via PyBind. (#6679)
[33mdd8ef4409a[m Liqun/migrate perf test (#6733)
[33m2c5e603bad[m Liqun/nuphar nuget (#6656)
[33m21f9e32c60[m Merge pull request #6714 from microsoft/thiagofc/merge-from-master
[33ma5bef6886b[m Threading support for Hybrid core architecture (#6728)
[33m6810d98ea3[m Update links to gh-pages for ORT minimal documents (#6721)
[33maf4e5c0c6e[m Minor WinML model test skip name change
[33mb41e9b5d4c[m [OpenVINO-EP] Fixes OpenVINO-EP build on windows (#6726)
[33m9d4b730e46[m Fix merge leftover
[33m9853ef84f8[m Reduce binary size, limit  asynchronous/backgroud thread stuff to training only.
[33m5b7e7aaa45[m Move event_pool and message_queue to core.
[33meecce31a8b[m Fix build, cleanup.
[33m3184c47ad1[m Merge branch 'master' into thiagofc/merge-from-master
[33m14c9095d11[m Merged PR 5694922: Onnxruntime GitHub to DmlDev RI
[33mc31d278826[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33m9a9202a218[m [Node.js binding] update dependency typedoc (#6720)
[33m0be5475de6[m Update packaging pipelines(#6664)
[33m46c06f6ac7[m Change Windows GPU CI pipeline to CUDA11 (#6616)
[33meefeacd828[m Skip running gpt2 model in C# x86 (#6722)
[33mb8d5fa812c[m Fix typo in README.md (#6713)
[33m9e67b88c83[m Use local rank as GPU ID (#6719)
[33m9043df8b66[m Deprecate OMP from nuget pipeline (release:1.7) (#6671)
[33m105883f4b8[m remove longformer_global_impl.cu from hipify (#6716)
[33maa2622efb2[m Support multiple dynamic inputs in custom ops (#6666)
[33m01dfa8e125[m Support non tuple return values from torch.nn.module (#6660)
[33m02c7873b0e[m Update ORT model conversion script to support custom ops (#6701)
[33m7f33671ade[m Handle multiple devices scenarios (#6672)
[33m7ee5baa60d[m Remove monkey patch for PyTorch Nightly + ORTTrainer (#6659)
[33m9b446d5f7e[m Longformer Attention CUDA kernel memory Improvements (#6646)
[33mb09a370218[m Address warning in data_types_internal.h (#6704)
[33mc36ee4bd40[m Rename Python packaging pipelines (#6682)
[33m497eef8d3d[m remove omp (#6675)
[33md48a4c0a54[m Add CG step to nuget GPU pipeline (#6678)
[33m9a01174037[m Disable some unit tests for training (#6699)
[33m33279250b5[m Update a couple of usages of args.minimal_build to check for not specified vs empty list correctly. (#6688)
[33m37b83acd76[m[33m ([m[1;31morigin/ProifleTP5[m[33m)[m MLAS: add uint8_t NHWC max pooling (#6684)
[33ma35b30e237[m Change BuildKernelDefConstraintsFunctorFromTypeList struct to BuildKernelDefConstraintsFromTypeList function. (#6674)
[33mf649f917fe[m [OpenVINO-EP] Enabling OpenVINO Runtime options for Perftest application (#6654)
[33mdf3d6bad5f[m Deprecate OMP from Python package (#6610)
[33m72eb5de0e2[m Add Python 3.9 to pypi metadata
[33m25f7c93504[m Require explicit inclusion of custom op support in a minimal build (#6663)
[33mdd50c39ac6[m Change Linux python packaging pipeline compile flags (#6668)
[33m87cb6fd495[m Add LearningModelBuilder to WinML Experimental Namespace along with various Audio operators (#6623)
[33mff465483b1[m Add TNLRv3 fp16 pattern to Layer Norm fusion (#6661)
[33ma07a14dce5[m exclude non support types (#6653)
[33mb2cddc5337[m Consolidate MLTypeCallDispatcher classes (#6651)
[33me6de0eb813[m Add nightly pipeline for MI100 to run convergence and batch size test similar to V100. (#6611)
[33mf11b5d3072[m [CoreML EP] Enable coreml for onnx_test_runner and onnxruntime_perf_test (macOS only) (#6642)
[33m78e408dbe9[m Enable type reduction for ConstantOfShape CPU kernel. (#6594)
[33m950c941f11[m Remove year from license (#6658)
[33mce01c3760f[m Cleanup macros used to register activations. (#6628)
[33m1916e35bea[m Reduce tensorprotoutils binary size (#6634)
[33mfba46a76bc[m Update readme to reference docs webpage content (#6621)
[33m8378a45ae7[m Add python 3.8/3.9 support for Windows GPU and Linux ARM64 (#6615)
[33m1c3168c0f6[m Skip constant folding dequantizelinear for quant qdq format (#6643)
[33m0732d72706[m Add support for dynamic axes for outputs + check model output type before export (#6648)
[33mb4b829dfcf[m[33m ([m[1;31morigin/gh-paghe[m[33m)[m Update transformers tool based on latest transformers (#6641)
[33m9294dde143[m Rename ONNX graphs variables in ORTModule (#6645)
[33ma7b6fc08f2[m Support skiplayernorm fusion without beta in layernorm (#6617)
[33mfd83e38dcf[m [CoreML EP] Add support of BatchNormalization/Reshape/Global[Average/Max]Pool (#6625)
[33m64edcad2d8[m [NNAPI EP] Add EP option to disable CPU (#6593)
[33md2ce8a2c80[m Add hipFFT include directory (transitional step) before ROCm. (#5992)
[33ma9245f59d4[m Merged PR 5673432: Unsquash RI
[33m042964f633[m Change how ONNX get installed
[33m986c7a9bc0[m Merge remote-tracking branch 'upstream/master' into user/orilevari/unsquash_ri
[33me1b0cf9dee[m Revert "Merged PR 5672827: RI from github"
[33mc6c0278872[m Merged PR 5672827: RI from github
[33me59cb9455e[m Add CI build with type reduction enabled (#6622)
[33meec602e48a[m OrtModule v0.21 (#6395)
[33m352e8cb8a8[m Move ORT_ENFORCE()'s within MLTypeCallDispatcher to helper class functions to reduce the size used by function names in ORT_ENFORCE(). (#6624)
[33meef9a7a8a9[m Update DirectML 1.4.0 to 1.4.1 for ORT 1.7 (#6636)
[33m8502573125[m fix CheckLearningModelPixelRange (#6632)
[33m88d48063fa[m Log warning when GetGradientForOp() silently fails. (#6586)
[33mb09bfc8611[m Revert "Remove abs in LpPool (#6303)"
[33m8972621138[m Generate shape-independent graph if any input dimension < 2 (#6581)
[33m8f0b877a1d[m Enable running some ops on CUDA (#6572)
[33m505c1f30b5[m use == instead of is for python 3.8
[33me70344e648[m Fix training python packaging pipeline (#6613)
[33m1c72774232[m Update a few WinML model test filters for DML
[33m8f14b8bd9d[m Support disabling training kernels as part of a reduced build (#6557)
[33me9d03983fc[m Add engine decryption in TensorRT EP (#6612)
[33m0b89f931d0[m Update CUDA build configs (#6598)
[33md3a2c8c1c7[m Support double for operators ReduceMax, ReduceMin (#6265)
[33mff063309b0[m enable omp for debug build
[33m6c5f50d00e[m deprecate omp in ci
[33m56e4e47f66[m Quantize model with QDQ format (#6541)
[33mc02ae61cab[m Make kernel hash stable in type reduced build (#6603)
[33m16eed68a1e[m Fix layer_norm.cc on x86 (#6556)
[33m97c1693305[m Merged PR 5663009: Merge latest github onnxruntime into dmldev
[33m284f68638f[m Merge remote-tracking branch 'upstream/master' into HEAD
[33m13d7db9a98[m Don't update the excluded ops/types unless args.update is true. Updating the exclusion info triggers rebuilding of all kernels using type reduction. (#6604)
[33m0b1e21c638[m Fix bug with ORT format serialization of tensor attributes. (#6602)
[33m67ef6b1aa6[m [Mult-GPU inferencing] Add new API to get/set device id. Set correct device id in cuda allocator. (#6592)
[33m1dd920fa7c[m[33m ([m[1;31morigin/ptest[m[33m)[m Fix TensorRT unnecessary file cache operations (#6601)
[33m19c130f561[m Reduce CastMLFloat16ThroughFloat size (Scott's suggested changes), fix unused function warning. (#6597)
[33m190b90a682[m Fix some coding conventions issues (#6583)
[33mc86c21e002[m Generate error when an explicit stream argument is not provided in the <<<...>>> kernel launch syntax (#6599)
[33md18aa45b46[m Enable more ROCM ops that are sharing CUDA code.  Some are needed for Turing NLG models.
[33mdbe31361bc[m Fix build.gradle so it always targets Java 8 class files.
[33mb57a7f4de3[m Delay load dxcore in winml model tests
[33mb50b0a89aa[m Fix build failure when building with --build_wheel on Windows
[33maf9dfa7a4d[m Remove docs that have been migrated to https://onnxruntime.ai/docs (#6225)
[33mdda5a62072[m Fix updated Doxygen errors. (#6588)
[33m115e16b37b[m ort_test_utils: skip creating input if it is an initializer (#6544)
[33mccfd90291b[m Remove condition from ORT_RETURN_IF[_NOT] macro output. (#6563)
[33mb5bd14fc9f[m Update GPU packaging pipelines to cuda11 and fix the other build break issues (#6585)
[33m82229c8e61[m Support no bias in layernorm and skiplayernorm op (#6554)
[33m299ace0759[m Support to allow user to specify compute stream per session (#3723)
[33m973c3917a6[m OpenVino add build_shared_lib flag in the build command (#6560)
[33m68193e28de[m Let execution fall back to CPU EP if Compile of a partition on current EP fails (#6580)
[33mf2ce3aae13[m add set_model_dir and update ONNX (#6119)
[33m3b376da37c[m Enable type reduction for Gather CPU kernel. (#6579)
[33mc5d2538314[m Add more kernels that have typed registrations to the operators we track type usage for. (#6565)
[33mf14c621c10[m Tile perf enhancements - continued (#6561)
[33mc49d1dbc4b[m Add type reduction support to Slice and Transpose (#6547)
[33m89627a8178[m [Node.js binding] support NPM v7+ (#6559)
[33m615acf156c[m remove keras example from python documentation (#6574)
[33m4e61e254ec[m Update link in readme (#6537)
[33md914e29fe1[m Reuse reduction_functions.cu
[33m3c44184963[m Pick up changes from: https://github.com/microsoft/onnxruntime/pull/6490
[33ma9e4d70b50[m Fix merge conflict.
[33m76fcebd0a4[m Fix scratch buffer early free.
[33m86ac11af1a[m Delete ROCM-specific reduction code that is identical to CUDA reduction code.
[33m5d8792705b[m Code formatting.
[33m21a47ec8d9[m Disable a couple more unsupported tests.
[33m0b147702af[m Update remaining reduction ops to use MIOpen.  double datatype is not supported, so disable those typed kernels.
[33ma28ddb85b6[m Reduction ops.
[33m196132925e[m Reuse CUDA's reduction_functions.cc
[33m4c1db50df5[m miopen common
[33m554184bcc4[m Add reduce template parameters.
[33mc4b6559be9[m Update reduction_all.cu
[33m5fc377f21e[m Partial updating of ROCM reduction code.
[33m318b82ca7e[m Cast Op performance fix. (#6509)
[33m7427d6e10c[m Merged PR 5650614: Merge Github onnxruntime into dmldev
[33m355cc0e62e[m Merge remote-tracking branch 'upstream/master' into user/rylai/update_dmldev_feb
[33m2ef792ae6e[m Don't resolve symlink in resolve_executable_path(). (#6540)
[33maa31ba5774[m Merge CPU packaging pipelines (#6480)
[33mbc0d04bf07[m Revert "Add support for dynamic axes for outputs + check model output type before export (#6491)" (#6566)
[33m0d35f0e2c0[m [CoreML EP] Add support of Conv operator (#6510)
[33m6cf54ff296[m Switch Android CI java build to JDK 11  (#6552)
[33mc7feb48083[m Don't send out Runtime error telemetry when can't create LearningModelDevice on machine without hardware adapters (#6535)
[33m464dbef143[m [NNAPI EP] add uint8 support for Transpose/Concat/Maxpool, add support of QLinearSigmoid (#6534)
[33mc983b84316[m Add support for dynamic axes for outputs + check model output type before export (#6491)
[33m62ac164279[m Cache datasets on CI machines (#6525)
[33m6cb8f8c812[m Support disabling a typed kernel registration that uses the output type (#6530)
[33m8d53ef69e5[m Add type reduction support to Min, Max and Pow (#6519)
[33mfbb24b57d0[m Update code owners for pytorch frontend team (#6329)
[33m85434273ff[m Fix CUDA Reduction kernel for ArgMax/ArgMix for when reduction dim=1 (#6490)
[33m8a890ddfd7[m Sync ORTModule branch with master and fix tests (#6526)
[33m14f7d56c81[m Add optimized version of ConvGrad for pointwise convolutions. (#6531)
[33m6fc5237d9e[m Introduce --enable_training_ops build flag (#6523)
[33m9a6e71574a[m MLAS: improve quantized depthwise convolution (#6513)
[33m588ddeb82f[m Add level 1 optimized mnist model so that the required_ops.config includes the ops in that (which are used in mnist.level1_opt.ort). NNAPI unit tests need this. (#6514)
[33m7264a067a9[m Implement QuantizeLinear with avx512 (#6260)
[33m5b69cbe80e[m[33m ([m[1;31morigin/hari/x86Warnings-3[m[33m)[m Fix Windows CI builds by updating test scripts to work with numpy 1.20. (#6518)
[33me5cbcec17f[m Fix issues with ArmNN build setup (#6495)
[33mf2872ffd64[m Print a warning message for using newer c_api header on old binary (#6507)
[33m7c5bfbaaab[m Lochi/refactor yolov3 quantization (#6290)
[33ma36f627a4c[m Dnnl training (#6045)
[33m3a30ad7b57[m handle hr error conditions (#6449)
[33m531eb064ab[m fix sdl bugs for uninitialized variables and returns (#6450)
[33m76f5d9edc6[m add explicit barriers for buffer overread and overrwrite (#6484)
[33m7f5731741d[m Optimize GatherGrad for AMD GPU (#6381)
[33m76bc0e479c[m Enable dense sequence optimized version of Pytorch exported BERT-L on AMD GPU (#6504)
[33m8c6d76a4c0[m Update to match new test setup. (#6496)
[33m8306150e0e[m Refine transformers profiler output (#6502)
[33m06a6c63434[m [CoreML EP] Add support for some activations/Transpose, move some shared helpers from NNAPI to shared space (#6498)
[33ma19c48f5cb[m Fuse cuda conv with activation (#6351)
[33m71389ff9ab[m nuphar test to avoid test data download to improve passing rate (#6467)
[33md3203adc26[m Update document of transformer optimization (#6487)
[33m066520f6c1[m Improve work distribution for Expand operator, and sharded LoopCounter configuration (#6454)
[33m7abb5b667f[m Support pad operator in quantization and quantized nhwc transformer. Fix Pad operator bug. (#6325)
[33m1a5b75a554[m [OpenVINO-EP] Remove support for OpenVINO 2020.2 (#6493)
[33m3b1227c5ce[m SDL annotation fixes (#6448)
[33m21b4842c34[m SDL fixes: add proper casts/format specifiers (#6446)
[33md4e1f5ab78[m Fix of support api version bug for [de]quantize (#6492)
[33m785e51d22f[m Export the model with torch.no_grad() context (#6472)
[33mce46f37ff2[m expose learningmodelpixelrange property (#5877)
[33m93aa72e468[m Support inputs to ORTModule forward method that require gradient (#6420)
[33m3f60b27703[m Speed up the Mac CI runs (#6483)
[33mea2b560055[m Fix test breaks in Windows ingestion pipeline (#6476)
[33m00afd00059[m merge e2e with distributed pipeline (#6443)
[33mc84bb9df9f[m Add ability to track per operator types in reduced build config. (#6428)
[33m752627c5bb[m [CoreML EP] Add CI for CoreML EP (macOS) and add coreml_flags for EP options (#6481)
[33m2e228d74d0[m Increase the distributes tests pipeline timeout to 120 minutes (#6479)
[33m77d0eb3f56[m Fixing a leak in OnnxSequences with String keys or values. (#6473)
[33m237b275bd8[m Enable device change during training + minor forward() refactoring (#6417)
[33md850fa63bf[m Op kernel type reduction infrastructure. (#6466)
[33m91b19b8364[m Delete nuget extra configs (#6477)
[33m7a0ab9c450[m Update pypi package metadata (#6354)
[33mb6ac35fed3[m use tickcount64 (#6447)
[33med1ebd2e21[m fix SDL rule (#6464)
[33m1ce1a51d46[m fix SDL native rule warning #6246 (#6461)
[33m0100f336d7[m [java] Adds support for OrtEnvironment thread pools (#6406)
[33mf68eb35aed[m dequantize 1st input of lstm back if it is quantized (#6444)
[33md5f51c4033[m Bug 31463811: Servicing: Redist (Nuget) conflicts with Microsoft.AI.MachineLearning starting 21H1+ (#6460)
[33mc05adb1147[m Initial version of CoreML EP (#6392)
[33mfd43806252[m fix max norm clipping test in python packaging pipeline test (#6468)
[33mb5d1a49b30[m Share allocator between CUDA EP & TRT EP. (#6332)
[33m9835b46a1d[m Add an option to save the training graph after optimization (#6410)
[33m0d20104a72[m only build experimental api in redist (#6465)
[33mafd7b8b3f7[m add tool for generating test data for longformer (#6415)
[33m76dbd88526[m Expose graph ModelPath to TensorRT shared library (#6353)
[33m7e42840298[m fix null dereference warning (#6437)
[33mf3a0344f9a[m Farewell TrainableDropout (#5793)
[33m6ed12402a4[m Liqun/liqun/enable pipeline parallel test2 (#6399)
[33m24f1bd6156[m Minor cmake change (#6431)
[33mc20965f9b2[m enable pipeline to run quantization tests (#6416)
[33me1dc268e45[m Add support for custom ops to minimal build. (#6228)
[33m6507b4f818[m Reintroduce experimental api changes and fix remote build break (#6385)
[33m3c3d36334b[m Continue memory planning when unknown shape tensor is encountered. (#6413)
[33m61ecf52c24[m Fix generate_submodule_cgmanifest.py Windows issues. (#6404)
[33m60c772e2bc[m Megatron checkpointing (#6293)
[33m4442d94c6c[m OpenVino docker file changes to bypass privileged mode
[33mbba185a582[m Fix some compile warnings (#6316)
[33m98cc7b5a9e[m Load the model path correctly (#6369)
[33m99a38f4023[m fix build on cuda11 (#6394)
[33meb946c4177[m Unblock Android CI code coverage failure (#6393)
[33m8574854d23[m [Perf] Optimize Tile CPU and CUDA kernels for a corner case (#6376)
[33md9e4795385[m Fix Windows x86 compiler warnings in the optimizers project  (#6377)
[33m33f60a06d5[m Dont use default string marshalling in C# (#6219)
[33m69af0440b1[m Add the custom op project information (#6334)
[33m453431f7bb[m Add max_norm for gradient clipping. (#6289)
[33ma1b5bfc4f8[m Fix SDL warning (#6390)
[33md7bdd96425[m Refine auto_pad based pad computation in ConvTranspose (#6305)
[33mac36596fb8[m fix convert_common version retrival (#6382)
[33m910c5ab655[m Add ORTModule deepspeed zero stage 1 test to the distributed CI pipeline (#6342)
[33mbaac7c91e2[m Support MLFloat16 in CumSum Cuda op for Opset 14 (#6355)
[33m5b6753ce27[m Wezuo/memory analysis (#5658)
[33m4db4982a5e[m This added telemetry isn't needed (#6363)
[33meab164e1a5[m Add python example of TensorRT INT8 inference on ResNet model (#6255)
[33mf5a4f7fc2a[m fix -Wdangling-gsl (#6357)
[33mc8e37e3a36[m Fix one more SDL warning (#6359)
[33m961bb62ae4[m Add create session to WinML telemetry to track WinML Usage (#6356)
[33m8ce252caa9[m Pipeline Parallel Experimental Python API (#5815)
[33m6d0fb3ebb3[m Java: Set C language warnings to W4 and adjust JNI code (#6347)
[33me54e2f969d[m Use readelf for minimal build binary size checks. (#6338)
[33m5d9552cc8b[m fix longformer benchmark io_binding output_buffers (#6345)
[33mea6789b754[m Add PREfast to python packaging pipeline (#6343)
[33mfd21c84eb8[m Enable graph save for orttrainer (#6333)
[33mc24f2950bf[m update quantize to support basic optimization and e2e example for image classification (#6313)
[33m5b9d993a2e[m Fix DerefNullPtr issues raised by SDLNativeRules. (#6348)
[33m4df356d1c9[m Train BERT Using BFloat16 on A100 (#6090)
[33me35db194e3[m fix the pipeline failure (#6346)
[33m042053c55e[m Add support for running Android emulator from build.py on Windows. (#6317)
[33mb220feee2f[m [NNAPI] Add pow support (#6310)
[33mfcd9fc9b6d[m remove gemmlowp submodule (#6341)
[33mcfd6f10098[m Remove OpSchema dummy definition. Only needed for Function now, and we can just exclude the method in Function (#6321)
[33md367941cc4[m changed wording. (#6337)
[33mf7034b9bca[m add external data support to tensor proto utils (#6257)
[33m62e404591a[m Enable add + softmax fusion for Rocm platform (#6259)
[33m56ab2166e8[m Delete float16.py (#6336)
[33m0586c610b2[m Add ORTModule BERT classifier to CI the pipeline (#6330)
[33m9b7510d88c[m Add ORTModule distributed CI pipeline (#6278)
[33m87ec1f6208[m MLAS: add fallback implementation for quantized GEMM (#6335)
[33m5623cc6d17[m Use onnxruntime_USE_FULL_PROTOBUF=OFF for the cuda execution provider (#6340)
[33maeca96caba[m Liqun/enable pipeline parallel test (#6331)
[33mf77ff1bc3d[m Quantization support for split operator with its NHWC support (#6107)
[33m6b73bae035[m Java: add Semmle to Java publishing pipelines (#6326)
[33maacc8dbfa3[m Remove false positive prefast warning from threadpool (#6324)
[33m0ed56d491a[m fix opset imports for function body  (#6287)
[33mb491d7c179[m Avoid false sharing on thread pool data structures (#6298)
[33mec81e29c84[m Add longformer to  python package (#6314)
[33ma8257666bd[m Support 1D input for Conv + Mul/Add fusion optimizer with test (#6295)
[33m3b3e698674[m Remove abs in LpPool (#6303)
[33ma038924bee[m update transformers required package versions (#6315)
[33mc43ca45c4f[m Force reinstall onnx python package on Windows (#6309)
[33mac5b5e5d1e[m more dtype for Equal CUDA kernel (#6288)
[33m938e65d878[m add --sequence_lengths option (#6285)
[33mf3a479901b[m add poc test for ortmodule (using MNIST dataset) to the ci pipeline (#6308)
[33m84024bdfa9[m Enable ONNX backend test of SequenceProto input/output  (#6043)
[33m5084ce0969[m Update nuget build (#6297)
[33mfa851bff66[m Add workaround to remove ROCm-specific binary-elementwise files.
[33m1059bfaf75[m Workaround for static_cast<double>(half)
[33mf9cc6ee7c2[m Merged PR 5557454: Update to latest ORT master
[33me22ae49bcb[m Merge remote-tracking branch 'upstream/master' into user/pavignol/1234
[33mb4082e370b[m Merged PR 5557382: Revert "Merged PR 5551793: Merge with latest ORT master"
[33mda952a9a20[m A list of changes in transformers tool (#6224)
[33mac5ca2bbe0[m fix data_ptr assertion error for past_sequence_length=0 in GPT-2 (#6284)
[33m7fc827a8a1[m Fix Min/Max CPU kernels for float16 type (#6205)
[33ma72fcbd5fc[m Add helper to compare model with different precision (#6270)
[33m04287ec770[m Increase timeout for Linux GPU CUDA11 build. (#6280)
[33mc10948699b[m Rename MakeString and ParseString functions. (#6272)
[33m18ef0fafc4[m Merged PR 5551793: Merge with latest ORT master
[33mb80e8ce6a5[m rename past to past_key_values for GPT-2 (#6269)
[33m481a2cdf61[m Add script to preprocess python documentation before publishing (#6129)
[33md761571afc[m Deprecate Python global configuration functions [Part 2] (#6171)
[33ma92e762f22[m ci pipeline tests for ortmodule (#6268)
[33mbbc9ed908a[m Fix VS 2017 build break (#6276)
[33m127afe3b09[m Device handling fixes in ORTModule (#6187)
[33m431604ef89[m add bfloat16 to gathergrad type constrains (#6267)
[33m2347de4a9e[m Fix Linux/Mac error message on input type mismatch (#6256)
[33md42399e1b0[m Allow querying a GraphProto's doc_string as part of ModelMetadata (#6248)
[33meea3806db1[m model parallel refinement (#6244)
[33maddb4b8c2b[m Liqun/speech model loop to scan (#6070)
[33me0f2a12c2c[m ortmodule ci pipeline setup (#6251)
[33mce6161cf67[m Add MakeStringLite which uses current locale, update some MakeString call sites to use it instead. (#6252)
[33m493bf931c5[m Add the Concat Slice Elimination transform, fix constant_folding transform (#5457)
[33m6fd9d34bb0[m Remove a debug log in provider_test_utils.cc (#6200)
[33m93bf7c4d52[m Documentation for distributed CI tests pipeline (#6140)
[33mc8de3f355a[m Refactor EP Perf Tool  (#6202)
[33m46e0e4e69f[m Tune BiasGeluGradDx kernel in approximation mode to avoid tanh(...) on Rocm (#6239)
[33mffb4b62826[m Fix allocator issue for TensorRT IOBinding (#6240)
[33m1685167e46[m Update manylinux docker image to the latest (#6242)
[33md5cb17c679[m Update BUILD.md
[33mcd14c1af29[m Support double for operator ArgMin (#6222)
[33m84addcd2cf[m Support double for operator ReduceMean, ReduceLogSumExp (#6217)
[33m5968a91ea6[m Support double for operator Gemm + fix bug in gemm implementation for cuda, rocm when sizeof(type) != sizeof(float) (#6223)
[33m70e2f96ef4[m Support double for operator TopK + fix one bug in TopK implementation for GPU for double (#6220)
[33mecb2e119e4[m MLAS: handle MlasGemm(M/N/K==0) cases (#6238)
[33m4cc2ffef21[m Support MLFloat16 type in Pow opset-12 CUDA kernel (#6233)
[33m39a988ce1c[m Upgrade build.py to assert for python 3.6+
[33mc15a858745[m Update the readme file
[33m3911105f09[m Remove python 3.5
[33m1b23b28706[m Remove MKLML/openblas/jemalloc build config (#6212)
[33m5c584b2636[m Removed executor todo that looks dead. (#6234)
[33mbbb6b416f0[m Fix ImportError in build.py (#6231)
[33mdf7e2f3c1e[m Support double for operators Relu, Tanh, Sigmoid (#6221)
[33m111ac299cc[m Support double for operators Where, LpNormalisation (#6034)
[33m2d09db67b4[m Support double for operators Log, Reciprocal, Sum (CPU) (#6032)
[33m8a0f5c50ab[m Minor change to improve performance for operator Pad. (#5537)
[33m7ccdfed1a6[m Remove most ROCm-specific element-wise code and reuse CUDA element-wise code.
[33m52228a703c[m Use TArray in AMD element-wise kernels, rather than manually copying memory to device.
[33m1fc7f92f25[m Fix a memory leak in test_inference.cc (#6201)
[33m7347996942[m Openvino ep 2021.2 (#6196)
[33m0494a0f95f[m Add ability to skip GPU tests based on GPU adapter name (#6198)
[33mc562952750[m Dockerfile to build onnxruntime with ROCm 4.0
[33m21395f8e24[m Implement comparing outputs that are sequence of maps of strings to floats (#6180)
[33ma8b482681a[m Clean up checkpoint tests to use the new checkpoint functions (#6188)
[33m04b3e0ef5e[m Condition fix in Resize operator (#6193)
[33mfc27074bae[m Implement ScatterND for CUDA EP (#6184)
[33m945fae8f56[m Lochi/quantization tool for trt (#6103)
[33m234e94b4e1[m Add Status.csv to EP Perf Tool (#6167)
[33m67ac6ae4e0[m Tune fast Gelu to use exp(x) instead of tanh(x) on Rocm platform (#6174)
[33m53307a5f2e[m improve perf for softmax (#6128)
[33mea9cfa554a[m Add usage details of unified MCR container image (#6182)
[33m201d0dbb1a[m Android coverage dashboard (#6163)
[33mf874260b9e[m Backend APIs for checkpointing (#5803)
[33m2da8060f34[m Helper for compiling EP to generate deterministic unique ids for use in MetaDef names (#6156)
[33mcd3a5acca0[m Update get_docker_image.py to enable use without image cache container registry. (#6177)
[33m11b0a5401e[m Fix typo in BERT pretraining script (#6175)
[33mbbb52e9274[m [NNAPI EP] Enable per-channel quantization for QlinearConv  (#6155)
[33m39aedbc97f[m aggregate model states only for the case when mixed precision was true (#6176)
[33m86493e6d0c[m Update documentation for contributing a PR and add deprecation notices for PyOp and ORT server. (#6172)
[33m824ef9a1de[m Don't try to bind unused inputs in the Training frontend (#6166)
[33madc2071043[m save_checkpoint, load_checkpoint and aggregate_checkpoints (#6136)
[33mc339bb2da9[m Remove ignored build warnings for pybind on Mac (#6165)
[33m98d8a3e335[m Revert "Fuse MatMulIntegerToFloat only when scales are scalar (#6008)" (#6169)
[33m34725ae520[m Bugfix for topk cuda kernel (#6164)
[33mdec703b62d[m Update TensorRT-ExecutionProvider.md (#6161)
[33m32c67c2944[m Deprecating Horovod and refactored Adasum computations (#5468)
[33mefa1b0d864[m Minor fix to satisfy c++14 (#6162)
[33m36c03b32e9[m Using a map of of ops to stages as input of partition function. (#5940)
[33m503b61d897[m MLAS: add NEON version of int8 depthwise convolution (#6152)
[33m0fa04bdc50[m Fix clean_docker_image_cache.py detection of image pushes. (#6151)
[33m344a2a8ee5[m Revert "work around of the build break in mac (#6069)" (#6150)
[33m7250562271[m Fix edge case in BFCArena where allocation failures could lead to an infinite loop. (#6145)
[33m82690486c1[m Partition initial optimizer state for Zero-1 (#6093)
[33m8fd085801a[m Add gradient registration for Abs. (#6139)
[33maa49e476b0[m Fix TensorRT kernel conflict issue for subgraphs of control flow operators (#6115)
[33m0978d2bfbe[m Fix CUDA test hang: (#6138)
[33mb648bf641f[m nnapi add min max support (#6117)
[33mb8c8fe91f5[m ort's to_dlpack.
[33m939cc9b410[m Enable running the mnist_training sample without cuda (#6085)
[33mac62cf8058[m Unify IExecutionProvider and IExecutionProviderFactory interfaces (#6108)
[33m980a93c164[m Model Fusion For Bart (#6105)
[33m297c824807[m remove dnnl_dll_path from post build copy (#6142)
[33m64709b1335[m Deprecate Python global configuration functions [Part 1] (#5923)
[33mc4f827bee1[m remove initializers from original graph
[33mf7f435fc27[m Improve dynamic axes to work without data descriptors
[33m7729bb3c8d[m Add initial dynamic axes support
[33m004632ff8d[m TEMP: Add support to measure method execution time for perf improvement
[33me5fdb455ed[m Improve performance by running ApplyTransformers on gradient graph
[33me986ae5f86[m Remove dead code
[33m41b88ce91d[m Remove initializers from forward ONNX graph
[33m07f5ae95e5[m Refactor MNIST and BERT classifier to add time measures
[33m395e082bc3[m Remove (unnecessary) gradient graph from frontend
[33m4d9267e102[m Add IO binding support, which allows CUDA training
[33mf13c2a61d5[m Refactor IObinding
[33m39ac95b2fc[m add io binding
[33mff79e8743f[m Add support to BERT fine tuning (MVP 3)
[33m78831d009b[m Add list of initializer gradients to the backend training graph spliter
[33m60b6e2683f[m bugfix
[33mf6a8d2aa5f[m split graphs info
[33mcfd57c0136[m fix input order, and input grad.
[33me759da178d[m bugfix for graph inputs and outputs.
[33mb7564d0732[m Refactor after Vincent work on splitting on backend
[33m6d8fde8324[m sample code change.
[33m934feb0c99[m gradient graph split in backend.
[33mea5871ac15[m Change DropouGrad.input[1].input_type and del logits_grad from backward graph
[33mf1dc6e4007[m Refactor BERT classifier fine tune for better debugging
[33md4917f2d65[m Hard-code input types for DropoutGrad on BERT
[33m3b267d1d60[m Add BERT classifier example
[33m30042b6e0e[m Update InferenceSession usage to match master
[33m8b0ade0e83[m Integrate automatic graph split into ORTModule
[33mc36c8e14a7[m refactor
[33m26e6d6d004[m module transformer
[33m3524fb04e8[m Add working example for MNIST (MVP)
[33mf1b5c25b2d[m Improve example to display grads before and after optim step
[33mf06cafdebd[m Fix path on test script
[33m56ca4ab05b[m Add flag to allow pytorch-only or ORT flexible api runs
[33md4449d86b9[m Add script to run Flexible API MVP PoC
[33me71e08851a[m Basic plumbing for backward pass. Not fully working
[33m77cefcd6c2[m Perform forward pass using training graph with intermediate outputs
[33m11b69f141e[m Forward pass using InferenceSession on exported ONNX
[33ma8d549e181[m Minor changes to AMD element-wise kernels to converge with CUDA element-wise kernels.
[33ma9548283d0[m Don't mark issues that are marked as enhancement as stale (#6134)
[33m9810b9e02b[m Reduce amount of compiled CUDA device code (#6118)
[33ma6a23db130[m Enable C# .NET5 for WinML  (#6120)
[33meb5c1f0fcc[m Unify activation and initializer alignment value (#6109)
[33mcde723a136[m Liqun/move nightly pl to linux multi gpu v100 (#6024)
[33mdd2e5a1a05[m state_dict and load_state_dict for ORTTrainer (#6095)
[33md4dddd99d9[m Bump ini from 1.3.5 to 1.3.8 in /nodejs
[33mc755ca0b71[m Honor auto_pad attribute in ConvTranspose  (#4271)
[33m6cb5d3ac09[m Fix multi-tensor LAMB reduction to be deterministic (#6028)
[33mc8ac34d6a5[m[33m ([m[1;31morigin/wangye/prophet[m[33m)[m Fix DEBUG_NODE_INPUTS_OUTPUTS test by putting it in a separate process, clean up unused test_main.cc files. (#5949)
[33ma53f4dd379[m Introduce VariadicAlias, remove hardcoded alias limits (#6106)
[33m38c49c2483[m Make ROCM and CUDA reduction_all code more similar.
[33m1eb146f561[m Implement conversion from ORT String to WinML Tensor String (#6097)
[33m3b44eee241[m Merged PR 5490057: Preserve history of merge
[33ma12faed0a0[m Merge remote-tracking branch 'upstream/master' into 054fb4d3-revert-from-DmlDev
[33mc4429952aa[m Revert "Merged PR 5490021: Merge latest github master into dmldev branch
[33m054fb4d3f6[m Merged PR 5490021: Merge latest github master into dmldev branch
[33m8bcb5fd119[m Add skip test reason for onnx model zoo models and tier 2 models (#6081)
[33m753af576c4[m If building inbox, hook up winrt_activation_handler for WinML Tests (#6074)
[33me945b5fcf6[m adding fp16 support for topk cuda kernel (#6082)
[33m7ddeafdfcc[m Add ReduceL2Grad and ClipGrad (#5970)
[33m404982ded5[m Enable varied input type for custom op (#6066)
[33mcc47cfcb31[m Update AMD transpose to match CUDA transpose.
[33mabdbb5fc84[m Reduction kernel optimization (#6088)
[33m9e26e59a37[m Deprecate opsets <12 for training. (#6027)
[33md95fc5e849[m clean un-used code. (#6059)
[33m2705115732[m add dockerfile for ROCm3.10 and update BUILD.md for ROCm EP (#5821)
[33mb1a75d0e98[m Enable passing initial optimizer state while creating training session  (#5869)
[33m7a43fa0028[m Fix AllReduce kernel for contiguous buffer (#6064)
[33me357486707[m Fix build definition template typo, add logging (#6065)
[33m523d187193[m save data to and load data from an hdf5 file for checkpointing (#5975)
[33m3e81711a13[m Update version to 1.6.0 (#6041)
[33mf68a256140[m Android code coverage (#6061)
[33me35211c0ff[m Fix AMD GPU pipeline by adjusting reference /opt/rocm-3.9.0 => /opt/rocm (#6063)
[33m2c5ba9ab00[m Bump up API version for 1.6 release (#6076)
[33m3cae28699b[m work around of the build break in mac (#6069)
[33mfa06be2133[m Support export >2G model when using optimizer.py only (#6014)
[33mb348538c8a[m Update build docker image cache cleanup (#6048)
[33m51fbe87b9b[m Update profiler tool to support gpt2 and longformer models (#6011)
[33m925879a8b0[m Remove python 3.8 Windows GPU build from python packaging pipeline (#6054)
[33m020efc9002[m fix windows cuda support for python 3.8 +  (#6046)
[33m7cebf76a46[m Improve checkpointing for Zero stage 1 (#5478)
[33m0afbdfd81c[m Merge remote-tracking branch 'upstream/master' into HEAD
[33ma046ef133a[m Update api_summary.rst (#6038)
[33md5e8c48e54[m Bump highlight.js from 10.2.1 to 10.4.1 in /nodejs
[33md8139814fd[m Clean up builds (#6015)
[33m00f43a3a68[m add missing iclosable interface (#6036)
[33m14f6eb14b1[m Use __launch_bounds__ workaround, rather than limiting threads to 256 on AMD.
[33m98ea7372d3[m Re-enable Lamb unit tests for AMD
[33m245d43615d[m Fix AMD multi-tensor implementation.
[33m6572a4d306[m Disable Python 3.9 for training Python packaging build. (#6012)
[33mcdb91208a3[m longformer onnx conversion and benchmark tools (#6007)
[33m3b198c9614[m Support Fusion for 1 and 2 Inputs Bert Models Converted From tf (#5993)
[33mc86a1e5c13[m Fix Flaky orttraining tests (#5977)
[33m2878e8eb2e[m Fix nuget build error (#6009)
[33m2b35f7d4f6[m Fix build.py bug which prevents running some unit tests (#5990)
[33m0acc3837ee[m Make operator TreeEnsemble 5x faster for batches of size 100.000 (#5965)
[33m524b9fa899[m Initialize a structure in operator ReduceSum (#6005)
[33m648c9c7789[m Fix bugs for 1: Calibrator should check model inputs; 2: (#6017)
[33mbdd06f6310[m Fix PR #5550 reverted in #5911 (performance improvment for operator Transpose) (#5916)
[33mf2dcba7afe[m Fuse MatMulIntegerToFloat only when scales are scalar (#6008)
[33m4fdfbfd4b4[m Add int32_t support for DeQuantizeLinear (#5994)
[33mc727a28735[m include gemm_helper.h (#5988)
[33mb4e6cc59c7[m skip the check for A channel (#5989)
[33mcdacee6696[m [NNAPI] Support non-1d tensor for C of Gemm op (#5982)
[33m6846c665ff[m Use loose version in build.py (#5998)
[33m897310f6fb[m Add suspend handler with new telemetry event for UWP scenarios (#5907)
[33m934b7882f0[m Merge remote-tracking branch 'upstream/master' into dmldev_temp
[33m6d642a3dba[m Replace direct pulls from image cache container registry with get_docker_image.py, build definition clean up. (#5906)
[33mc63e8cf7d7[m Remove chronological starttime assertion in InferenceTest.cs because it is not determined (#5976)
[33m396074d2a8[m Fixing OrtEnvironment.getEnvironment() so it doesn't print a warning if the environment already exists with a non-default name. (#5973)
[33m30c7fffbab[m Expand the documentation on using compiling EPs with a minimal build (#5893)
[33m46277bfd09[m Remove survey link from README (#5979)
[33m5f516899bf[m optimize a bert model converted using tf2onnx (#5492)
[33m3323fb6082[m Update docker files to put 'unattended-upgrades' in a right place(#5983)
[33m2ec211ea7b[m Support the cross compiling for Apple Silicon (#5974)
[33mfb310fba0c[m Avoid adding non-existent inputs to new Event nodes (#5915)
[33m2d9dcc4576[m[33m ([m[1;31morigin/test-seq[m[33m)[m Add python 3.9 support (#5874)
[33m1852ade75d[m Enable the xcode build for Apple Silicon (arm64 MacOS) (#5924)
[33m45966d878a[m Code review feedback
[33m86e30a2db6[m Update CUDA IsAllFinite kernel
[33mbd96f60888[m Use CUDA's IsAllFinite kernel for ROCm
[33m06ad516a5d[m w (#5947)
[33m5f5d4a10bd[m [OpenVINO]Fix memory leak upon exception throwing (#5954)
[33m015fbb3dbb[m Add support for Python 3.8+ on Windows when CUDA is enabled (#5956)
[33me207589631[m [OpenVINO]Fix memory leak in `IsDebugEnabled()` under Windows (#5948)
[33m4afdced775[m [NNAPI EP] Update squeeze ops (#5946)
[33md52b9aca68[m Enable scalar input/output for NNAPI EP (#5922)
[33m5fdd9f0fd2[m Fix Python Linux GPU package name (#5943)
[33m27513d1fd7[m Update BUILD.md with shared provider information (#5944)
[33mc4b55d29fe[m Fix publishing pipelines. (#5942)
[33m1dbabb2362[m Update dockerfiles (#5929)
[33mc5b4d9091c[m Fix a tiny issue in onnxruntime_unittests.cmake (#5901)
[33m7546d251e0[m Expose parameters in clean build Docker image cache build. (#5941)
[33m31a6be3d67[m Add Longformer Attention Cuda Op(#5932)
[33me39e82b43a[m Bug fix for MaskRCNN and FasterRCNN (#5935)
[33m69b9368c93[m Add unit tests to identify configuration migration scenarios for checkpointing (#5678)
[33m8168c91978[m Sahar/fix documentation shared lib (#5926)
[33m87368655e2[m Make NNAPI EP reject nodes with no-shape inputs (#5927)
[33mfddbd8935c[m Adding Java support for getAvailableProviders and other small methods (#5366)
[33m40926867c3[m Add OpenVINO EP shared lib to Py Wheel (#5920)
[33m4d603e83d7[m Remove attention_past.cu and attention_transpose.cu from hipify to fix AMD build (#5921)
[33m8b83c51a35[m [Java] Initial Apple Silicon support (#5891)
[33mee908eb0aa[m Symbolic shape inference: fix rank for ConstantOfShape (#5912)
[33mc2d610066a[m C#: Add CreateFromMemory to FixedBufferOnnxValue to allow bind user buffers and pass custom binary compatible types (#5886)
[33m705d093167[m Update onnx (#5720)
[33m9b8189dd0a[m Rework AMD CI pipeline to use pool AMD-GPU and disable more tests in order to enable it. (#5885)
[33m846c5fb917[m Report arm64 minimal baseline binary size only for continuous integration (#5913)
[33mc49d5f1d98[m Reenable skip flatten/reshape if it's Gemm's input (#5904)
[33m782303324e[m Revert "Improves performance  of operator Transpose (#5550)" (#5911)
[33m9992f0f812[m Implement QLinear GlobalAveragePool with sse2/neon. (#5838)
[33md0a007e4f1[m Add info level logging for NNAPI EP partitions and number of supported nodes (#5903)
[33m4137c18d9b[m Add ORT minimal with NNAPI EP to Android CI (#5890)
[33m916410151c[m Fix for hetero multi python binding with new shared library (#5895)
[33m58ea7b3572[m temporarily disable test (#5868)
[33m5e8fcda24a[m Build docker image cache fixes. (#5902)
[33m3d5b48a894[m remove use_cdn when loading pretrained model (#5900)
[33m208f4c1d3c[m Azure ci pipeline for distributed environment tests (#5881)
[33m353e071b7e[m Fuzz testing misc (#5862)
[33mf473dd295d[m Add QLinearMatMul(u8s8) (#5899)
[33m57c92066c2[m Implement missing pieces for ARM QLinearConv support (#5894)
[33md46dbeafd3[m Expose knobs to create and share (CPU) allocators across sessions in C# and Python (#5634)
[33m26e6ced172[m[33m ([m[1;31morigin/stevenlix/int8cal[m[33m)[m Temporary fix for Android CI failure (#5889)
[33m910bbfe1ef[m Support 3D attention mask (#5887)
[33mcc6e8fb7cc[m Filter initializers for GraphViewer with IndexedSubGraph (#5884)
[33mba739a8000[m Convert OpenVINO into a shared provider (#5778)
[33m8c04ada0d0[m Bump training docker image version. (#5428)
[33m3738ca7e10[m Improve perf testing (#5760)
[33mf0142da59c[m Add NNAPI to providers that can be used via the python bindings. (#5867)
[33m3970eb2e5d[m Add documentation on enabling/using NNAPI in a minimal build (#5879)
[33mc0471240b4[m Remove redundant lines of code (#5883)
[33ma622533ecc[m Support profile_file_prefix in python binding (#5864)
[33m5a0fdd3537[m Update custom_ops.cc (#5507)
[33mceedf5630b[m Document all C# API pubic interfaces (#5853)
[33mab9d4b366b[m revert 262e9ef21dc319a8e7bece1f0d155364b17b019c (#5882)
[33mbef06dac93[m Automatically clean up build docker image cache. (#5843)
[33m6808bfefff[m Extend MatMulInteger fusion (#5871)
[33m44313970d3[m Enable scalar initializer support in NNAPI (#5875)
[33m00412a76e9[m Exclude some training specific code from the minimal build. Cleanup some related aspects of allocation planner. (#5861)
[33mb057b3d36e[m Enabled fp16 for input types (#5878)
[33m1068f3eb87[m Use flatbuffers for INT8 calibration table (de)serialization in TensorRT EP (#5873)
[33mfd6e7d9c5c[m Fix the arm64 build issue on some special OS for OpenVino (#5870)
[33m4b17fd560f[m Merged PR 5425356: DmlDev RI from GitHub master 2020-11-19
[33mdfea92925c[m Add calibration based INT8 quantization to TensorRT EP (#5842)
[33mff58f621fa[m Remove nGraph Execution Provider (#5858)
[33m8f0bfe870b[m Merge remote-tracking branch 'upstream/master' into user/dwayner/DmlDevRI20201119
[33m261462be0d[m Change NNAPI runtime options to use uint32_t (#5863)
[33m4bb41d610b[m Address scalar expand to scalar case (#5854)
[33me485805b8d[m [NNAPI EP] Add infrastructure for Op Reduction (#5841)
[33m62508ef0e4[m Revert "Remove MKLML build config (#5559)"  (#5855)
[33mcd07783dde[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m26db396b4b[m Reduce the number of CI build variants (#5856)
[33m62d4f75f18[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m47185b9513[m reducealll2 cpu kernel (#5833)
[33m7196d4206f[m Adding Transpose3d and Transpose4d special case kernels for Rocm (#5837)
[33mb495ae8103[m ORT fuzz testing (#5771)
[33m84c1340f9b[m Refactor implementation of Tensor<T> and underlying buffer stores to improve binary size and maintainability (#5836)
[33m63ee7b4771[m Merged PR 5420139: DmlDev RI from GitHub master 2020-11-18 #2
[33m85f945a875[m Regenerate CI build docker images (#5850)
[33m26882c2a6b[m Merge remote-tracking branch 'upstream/master' into user/dwayner/DmlDevRI20201118b
[33m395fac9a34[m Merged PR 5419219: DmlDev RI from GitHub master 2020-11-18
[33m6f86c4dbe3[m Quantize LSTM (#5595)
[33mc2a993e745[m Add documentation for OrtArenaCfg for CreateAndRegisterAllocator API. (#5831)
[33mb3a6ed14d4[m Prevent saving a model containing fused nodes as we don't have any way to save the compiled kernels so the saved model will be invalid. (#5840)
[33me8c0f5d0ff[m Update the quantization script to support GEMM (transB==1) (#5432)
[33mf964bb94ba[m Add QLinearConv NHWC transformer (#5824)
[33me814c9307a[m Boost Expand cpu operator by multi-threading (#5739)
[33m71e7c2b423[m Cache build docker images in container registry. (#5811)
[33m252dbf1182[m fix build break (#5835)
[33m3b5ba1cf7e[m Parallelizing Resize op (#5792)
[33mbd236ecc26[m Switch to unified DirectML 1.4.0 redistributable (#5794)
[33mc84bc25e28[m Add validation of op registrations (#5817)
[33m241b2226a7[m Update orttraining-linux-gpu-ci-pipeline.yml for Azure Pipelines (#5826)
[33m1a66dfc0f9[m Enable Squeeze Opset 13 for NNAPI (#5717)
[33m502f85c883[m Merged PR 5411855: Manual pull from onnxruntime upstream GitHub master into DmlDev
[33m7b76b57fc8[m Support EPs that compile nodes in a minimal build. (#5776)
[33m794e8479eb[m Revert #5805 (#5823)
[33ma3f3a63206[m Move OpenVINO specific validation function to somewhere more sensible, and rename to provide context on its usage. (#5822)
[33m732ffd12d2[m DirectML Execution Provider integration 2020-11-13 (#5809)
[33m339348bc46[m Fix bug in resize IsOpSupported, and add nearest neighbor resize support (#5810)
[33m833432d7d1[m Update mysql-connector-java (#5802)
[33m2a6c73cf8c[m Address publishing pipelines failures. (#5806)
[33m671fa60327[m Enable direct tensorization and detensorization to many buffers in WinML (#5791)
[33m20ae1ea21f[m Remerge custom gpu op (#5818)
[33me40df385ba[m Skipping even more x86 tests (#5799)
[33m89e5b3a24f[m resolve review comments
[33m89902c2519[m fix frontend bug.
[33mc4818d36ed[m [NNAPI EP] Make NNAPI EP build on non-Android Platform (#5779)
[33m5b7dc5aeee[m fix build failure for ROCm EP (#5816)
[33mced5b66306[m Re-enable multi-tensor-apply for LAMB optimizer
[33mfc614ad050[m revert the code change which was based on b4869926
[33mc23fbba463[m Fix reduce pipeline by replacing model (#5813)
[33m3269e59b2c[m Add opset 13 registration for Identity. (#5800)
[33m157d1844fb[m Named Dimension Override internals test and experimental API (#5805)
[33m262e9ef21d[m Support input dimension swap in Attention op (#5774)
[33mdfbf6d78be[m OpenVino: fix allocation failure on Window for RelWithDebInfo build (#5713)
[33m0c8902cbbe[m Update Gradient Builder of Some Ops for OpSet13 (#5748)
[33m1f722863b2[m Scale Bias post processor for ARM (#5795)
[33m435b904f0e[m add dnnl gpu engine (#5788)
[33m0ea998134a[m Skip new x86 tests in ort model tests (#5789)
[33m2f35e65135[m Add Float16 and BFloat16 support to C# API (#5775)
[33m4d517c68a3[m Fix reference to old download_e2e_test_data.py script. It was renamed to download_azure_blob.py. (#5790)
[33m88c3704257[m Add shape inference for additional ops
[33m4e29f48010[m skip gpt2 test on x86 (#5787)
[33m49288de17c[m Fix memory planning issues (#5752)
[33m44d3c31200[m Winml_principles_change (#5727)
[33mdc0f7b8f82[m Remove onnxruntime_session_options_config_keys.h from c_api (#5772)
[33m54de618c2e[m Improve TensorRT engine caching (#5737)
[33m2a87108431[m SoftmaxCrossEntropyLoss OpSet13. (#5777)
[33mb92fc66ea1[m Support opset-13 specs of controlflow ops (Loop, If) (#5665)
[33m07dc25e939[m Compute global gradient norm according to 'enable_grad_norm_clip' (#5728)
[33m1ae58c960c[m Allow turning off printing of shape when compiled with onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS. (#5768)
[33m5aec34500d[m Add megatron transforms for BART (#5521)
[33ma14cd6267b[m Support opset-13 specs of softmax family ops (Softmax, LogSoftmax, Hardmax)  (#5707)
[33me5c8040c52[m Improves performance  of operator Transpose (#5550)
[33ma84a058f9e[m [OpenVINO-EP] Enabling Multi Device support (#5740)
[33m4207e99be3[m [NNAPI EP] Move GetCapability independent of ModelBuilder (#5767)
[33md8ace07ad7[m Add CPU send/recv for pipeline (#5315)
[33m496fa18c96[m fix graph partitioning for nested functions (#5755)
[33mbc1768c7f1[m Stop gradient flowing to the `k` input of TopK (#5762)
[33m871af477d7[m Fix outputs of Sequences and Maps exposure. (#5743)
[33m1416d12f0b[m Liqun/merge e2e pipelines (#5702)
[33m2ba637c558[m Implement Scale function for quant gemm (#5632)
[33mcca8cd849a[m update native build instructions for ACL on Jetson. (#5764)
[33m79350a642a[m Update install_deps.sh: remove the unnecessary data generating step (#5758)
[33m0767c4fdfb[m Fix x86 build break (#5759)
[33m042365029f[m [NNAPI] Split OPBuilder IsOpSupported into a separated class (#5746)
[33m6803e4ab44[m Fix BatchNormalization registrations. (#5750)
[33m7d98596bfa[m Merged PR 5390213: Tile allow 0 in repeats
[33mc75b7c5c47[m [CMake] Enable NCCL only when enabling CUDA or ROCm support (#5516)
[33m48b14b52b8[m Remove Env::Task wrapper around std::function (#5753)
[33m2b1ebbc286[m update MCR images table (#5509)
[33m4c6118eb49[m Update get_applicable_matrix_reduction() to combine dimensions of 1 with the given reduction axes. (#5734)
[33m63b85fc696[m Fix VS 2017 build break (#5745)
[33md59f057db3[m enable string for operator Shape (#5742)
[33m8c74df2068[m Add support for string with operator Expand (#5751)
[33m4094a09a56[m Merge pull request #5731 from microsoft/snnn/rtti
[33m00b18d9dc5[m Update InferenceTest.cs to exclude one more model in x86 mode
[33m5e44d25c5a[m Support multi-loop parallel sections, use multi-loop sections in GRU (#5602)
[33m919c270f3c[m[33m ([m[1;31morigin/wangye/transformerXL[m[33m)[m Increase build timeouts.
[33mde85638543[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m838bc77f3b[m Merged PR 5386132: Update 8D BatchNorm
[33m2acdc3cd82[m Move GetUseDeterministicCompute() to OpKernelContext to avoid need to downcast to OpKernelContextInternal. (#5729)
[33m12d39ef4ed[m Remove onnx backend test filters for updated ops (#5718)
[33mbb1af718b5[m fix build failures due to recent change(858040fa) in CUDA EP (#5736)
[33mc0c9ab4d81[m Fix kernel registrations for Equal, Greater and Less (#5730)
[33m81b2cb9714[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m1e13ecabf7[m Merged PR 5380534: BatchNormalization failure in autopilot - fix output size
[33m2bf5046d4e[m Add tag types for Ort::Float16_t and Ort:Bfloat16_t structs (#5716)
[33mfff85a6a35[m Add GPU kernels for ROCm EP (#5655)
[33m697e8faa9e[m[33m ([m[1;31morigin/wechi/pp1[m[33m)[m Skip failing x86 winml tests and update testData environment variable path mechanism (#5719)
[33m9ec6da1e27[m added missing flag ORT_TENSORRT_DUMP_SUBGRAPHS (#5724)
[33m6f6dd0b869[m added missing flag ORT_TENSORRT_DUMP_SUBGRAPHS (#5724)
[33m92292de135[m Tensorrt perf tool (#5436)
[33m95e6da7957[m Revert saving optimized model as external data (#5690)
[33m71f90e08f1[m Nuget packaging no omp (#5666)
[33m77b1eea9cf[m Add option to allow quantize_input() use input_qtype for initializers. (#5721)
[33mf666c3d7d7[m update jetson build instructions (#5725)
[33m24016a517b[m Prepacking in Gemm with merged logic for Matmul and Gemm on PackingB. (#5693)
[33m479ed740ef[m Add link to survey to README (#5685)
[33md6f9cc181d[m Modify logic to determine OV Version (#5701)
[33md1d82065b9[m [Java] Fixes an error allocating large direct byte buffers during OnnxTensor creation (#5619)
[33m28197b1460[m Register opset13 flatten, LRN for cuda. (#5694)
[33m11fe683471[m Partition full graph one execution provider at a time (#5635)
[33m858040faaa[m Implement reduce_matrix_columns() to optimize ReduceSum (#5639)
[33mc46515cd56[m [TensorRT EP] Remove cudaDeviceSynchronize and use cudaAllocator for scratch buffers (#5714)
[33mfd9d0c4ee0[m Remove redundant const_cast (#5705)
[33m9e68e98423[m Add static CRT DLLs to Nuget package (#5661)
[33mff23083de2[m Unbreak microbenchmark build (#5710)
[33m5c4543e194[m Calibrate float tensor only (#5704)
[33m2127a229d7[m The IndexedSubGraph is used to create the Function body, but after that is invalid as the nodes it referred to have been removed from the main Graph. As such there's no need to store it in the FunctionImpl instance. (#5669)
[33m941e3a69f9[m Test a build break fix (#5706)
[33m6d8e81cb08[m Update Squeeze, Unsqueeze, Split and ReduceSum kernel for Opset13 (#5691)
[33m830f567be8[m Add C API Guidelines document (#5686)
[33m8bae883d3e[m User/alexzak/win ml principles (#5453)
[33m62a99824cb[m Wezuo/priority in nodedef (#5692)
[33me49f7a8b71[m Fix build error due to unused variable (#5698)
[33m0b9f7bb1b0[m Update InferenceTest.cs
[33m0445473dc1[m Add ssd to x86_disabled_tests
[33ma2b551ff08[m Add runtime options for NNAPI EP (#5576)
[33m2ad7bcb766[m NNAPI add opset version check (#5687)
[33m07bd4ef470[m Upgrade optional implementation to https://github.com/martinmoene/optional-lite. (#5563)
[33m67d7e3967d[m Disable some model tests
[33mb6eeadf420[m Enable OpenVino build on Arm64 platform (#5682)
[33mc9f44276da[m Add ability to filter GraphViewer using IndexedSubGraph.  (#5614)
[33m357a51c75c[m Update python packaging pipeline's docker image (#5680)
[33mdb9c1308a5[m Fix Resize kernel registration (#5677)
[33m28f1e32898[m Loosen tolerance of CudaKernelTest.ReduceSum_MidTensor, allow test random seed to be regenerated within a test run. (#5675)
[33ma028ca41ec[m Optimize flaubert (#5651)
[33m9b010963b7[m Turn off peak memory logging and fix memory pattern generation bug. (#5676)
[33m5d66cf017c[m Register Clip for OpSet13 (#5671)
[33m8856c2595b[m Sync the two IDs in OrtMemoryInfo when calling ctor (#5663)
[33m4936e10e22[m Disable some model tests (#5664)
[33m182d9c48e4[m Merge u8u8/u8s8 QLinearConv implementations (#5662)
[33mc875fe0919[m Add option to dump activations on all ranks (#5455)
[33m87e1063e19[m Revert "Update Squeeze, Unsqueeze, Split and ReduceSum kernel for Opset13 (#5488)" (#5668)
[33m2c02530603[m Bert Model Profiling Tool (#5654)
[33m1495f737ca[m Use cudaMemsetAsync and add checks on CUDA calls.
[33mdb63c5d10f[m Update Squeeze, Unsqueeze, Split and ReduceSum kernel for Opset13 (#5488)
[33m5b44982971[m Change the OrtCustomOp invocation as a constant. (#5506)
[33mff538b8d3a[m Minor fixes in BERT Inference notebook (#5637)
[33m1cca903680[m update onnx commit id (#5594)
[33mf2168cef29[m Misc. cleanup. (#5659)
[33m9af0d48524[m Memory planner and pattern generation enhancements. (#4443)
[33md98062da0c[m[33m ([m[1;31morigin/kaarthik/dev2[m[33m)[m [OpenVINO-EP] Hetero support (#5627)
[33md9293f38e6[m Revert "Custom Op on GPU (#5620)"
[33m7948a4b0bc[m Revert "add header (#5648)"
[33m32bf6390ad[m Some fixes to symbolic shape inference (#5642)
[33m7a80a4b526[m Support more C# APIs  (#5608)
[33m17bce6f07e[m[33m ([m[1;31morigin/kaarthik/dev1[m[33m)[m Implement Im2colNd NHWC and related qlinearconv logic for u8s8. (#5612)
[33md7f3baed18[m add header (#5648)
[33m3e71e8bd7e[m Revert "[CUDA EP] remove per-thread allocator (#5415)" (#5647)
[33m2c63196600[m Custom Op on GPU (#5620)
[33maa38893afb[m [OpenVINO-EP] Add Dockerfile with C# API bindings (#5633)
[33maec4cb489e[m[33m ([m[1;31morigin/wezhan/rocm[m[33m)[m ROCm EP for AMD GPU (#5480)
[33m742ffb860c[m Allow Kernels refer to some attribute data directly in the protobuf (#5624)
[33m1fa1c51544[m bug fix for name of gradient constant (#5626)
[33mb4869926d3[m [CUDA EP] remove per-thread allocator (#5415)
[33m2e1fa3ccb7[m Fix GeluRecompute for 2 inputs case. (#5573)
[33mb85e7a19ea[m isalnum is not defined - include cctype (#5623)
[33me6956be40c[m Publish no-openmp python packages to test pypi (#5610)
[33mb68e98e0b0[m optimize QLinearConv depthwise convolutions (#5605)
[33m1d87831c6e[m Merged PR 5344477: Disable GPU timeouts in DML EP command queue creation
[33m5129b4d5bc[m batch size tests (#5508)
[33m50582abe93[m Fix IS_ANDROID Issue  (#5599)
[33mbbfd914d72[m Skip new model test additions (#5611)
[33m27c6d1eeb2[m move variable declaration to avoid unused variable error (#5603)
[33m0dbf3e8893[m enable arena for arm64 (#5613)
[33m5e8952ef89[m ThreadPool clean up : mm_pause in loops, correctly spin-then-wait, and adopt static methods consistently in the API (#5590)
[33m92662659ba[m Liqun/remove number matching (#5606)
[33me90b6f06d1[m Factor out IAllocator so that it can be shared with shared providers (#5567)
[33me5b0d192f4[m pin transformers dependence to sentencepiece==0.1.92 due to ci fail (#5607)
[33mddf83d1ace[m Maajid/multi threading 2 (#5568)
[33mb851973f22[m pipeline_worker_pool_.JoinAll() should be called in pipeline code path (#5604)
[33m6f824c25e5[m Dropout op elimination - enable for ORT training (#5588)
[33m3433576fd3[m Support for Sparse Initializers (#5540)
[33m30cdc74bc0[m Enable prepacking in subgraph (#5433)
[33m564da960ce[m Fix nuphar docker file build break
[33m6c310858e3[m Support opset-13 Resize kernels (#5575)
[33m5bcb5f5a3d[m MLAS: Add support for AVXVNNI (#5592)
[33me380fd3c6b[m Merged PR 5334334: Fix asserts and failure in GraphKernelHelper.cpp
[33m694a4d6413[m Add more loggings for GradientBuilder (#5556)
[33m68fe722691[m GatherGrad optimization (#5524)
[33m8224718f8f[m Enable CommonSubexpressionElimination in training. (#5504)
[33m44773c60e3[m Add  a CUDA based IOBinding test (#5572)
[33mf4cee22b9b[m Handle -inf in ReduceSumLogExp, fix regression introduced in PR #5370 (#5583)
[33m502f67ba58[m MLAS: implement u8x8 GEMM for aarch32 (#5580)
[33mb2da700e4d[m Allow Upper case letters in RHS of einsum equations. (#5569)
[33m51af108af5[m Support older version of slice in reshape fusion (#5574)
[33m860cb22260[m Bug fix for C API (#5520)
[33m3f3b202e36[m Optimize GatherElements further, add threshold for parallelizing Scaler. (#5579)
[33m49ec73e939[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m3f06286154[m Add Flatten support for NNAPI (#5545)
[33m7da5949279[m NVTX label change (#5562)
[33m20bc83400b[m ACL/ArmNN update (#5515)
[33m00d749b3c9[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m98538580c8[m give more tolerance to DirectML runs (#5564)
[33m1f304fbee7[m Attention with past and no unidirectional mask (#5557)
[33m0a9b83a313[m Add zero test (#5476)
[33m6d35be215f[m Add `--skip_tests` to example command line as the included ops are being reduced. (#5554)
[33md220c9f950[m Resolve crash in MatMul optimization (#5551)
[33m5802fe1699[m Remove MKLML build config (#5559)
[33m82c7a9756e[m Fix shared provider unload crash (#5553)
[33m4291c57322[m [C# and Python APIs] Expose knobs to enable/disable platform telemetry collection (#5481)
[33mdf22611026[m Update ONNX commit (#5487)
[33mb48f596a91[m[33m ([m[1;31morigin/raviskolli/zcode[m[33m)[m GatherElementsGrad CPU Kernel and TopKGrad CPU/CUDA Kernel (#5511)
[33m6c2162e97a[m Fix quantization of Conv1D with bias (#5491)
[33m1038f9cc8b[m Optimize GatherElements and Scaler. (#5543)
[33m2f4fc83231[m Add NVTX profiling range around kernel computation. (#5542)
[33m45483dcf1f[m Add QLinearConv for activations=u8, weights=s8 (#5510)
[33m280cdf31f5[m Revert "Fix shared provider unload crash (#5523)" (#5547)
[33m21e02effc0[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m66c8a441e0[m Improves ReduceSum performance by removing transposition. (#5370)
[33m682898ae2b[m Add #include for std::tolower. Fixes VS2017 build error. (#5544)
[33m67968441e0[m GatherND - add Cuda support for int64 on opset 12 (#5531)
[33m610676293e[m Fix shared provider unload crash (#5523)
[33m4b29423656[m Re-enable custom op shared library test for debug builds (#5475)
[33m0298b9734e[m Save in EndTraining only if in last rank  (#5500)
[33ma3d2bc36be[m Fix script name in doco (#5530)
[33m6ad70d7371[m [Doc] ONNX_Runtime_Server_Usage fix proto uri (#5345)
[33m1e4b259d28[m Updating EP docs with Onnxruntime API calls (#5503)
[33m0b59004666[m Add fallback function implementation for DivGrad (#5518)
[33ma355281b99[m Add alternate IsSupportedOptypeVersionAndString signature (#5529)
[33mbc84aeb5a8[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33me1a54c4090[m Symbolic shape inference: fix a bug in shape merge (#5519)
[33meda9fd566e[m Update tar-stream and prebuild-install versions (#5479)
[33mec0dd8edbf[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mad94a1dd6d[m Add opset 13 registrations for Identity, IsNaN, NonZero, GatherND and Pad (#5513)
[33mf207f0bf5e[m Add WinML Model testing (#5417)
[33mb991ee4c69[m Cleanup NNAPI code (#5505)
[33m6f65e2ad2c[m Mark the dX and dB outputs of ConvGrad as OpSchema::Optional. (#5462)
[33m64f6d856e4[m Add FlattenGrad and test. (#5461)
[33m88f6523baf[m Add type inference for BroadcastGradientArgs (#5501)
[33m7da7e07909[m Cleanup some test infrastructure (#5484)
[33m645d978589[m Sunghcho/denormals (#5391)
[33mc1602ff028[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m915d475353[m Android CI update (#5474)
[33m6d2a30eae3[m [OPENVINO-EP] 2021.1 Release  (#5431)
[33m88ebad4cfe[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m2b6b3a2ee6[m Add GetProfilingStartTimeNs() to Python/C# APIs (#5280)
[33m1514509fd7[m Update protobuf submodule url (#5477)
[33m44248d9646[m opset13 kernel registration (Transpose, Tile, ScatterND, ScatterElements, Gather, GatherElements, Slice, DepthToSpace, SpaceToDepth) (#5454)
[33mfabe02ddc2[m Don't change global FPU state during round-half-to-even (#5376)
[33m67315d8ae0[m Optimize openai-gpt/albert model and add fusion test (#5466)
[33m5544391e79[m Fix linking of MLAS unit test lib on platforms where libatomic is required. (#5469)
[33m8e9afe1944[m Add long type support for SplitToSequence operator (#5367)
[33me01d152464[m Add OpSet kernel registrations as part of opset 13 support (#5465)
[33m6e6147fb75[m Use correct protoc tool file name for C# builds (#5429)
[33mb12824fa7a[m add telemetry event for nodejs binding (#5463)
[33mce5465d5f3[m [NNAPI EP] Add Resize and Clip support (#5427)
[33mc444b9d76a[m Add CUDA option to run copy in default stream (#5445)
[33m80d36eab86[m enable the onnxruntime shared library test on iOS (#5443)
[33m913116e64e[m bump ops version to opset13 (#5456)
[33m05b1c02d32[m Fix commands in README.md. (#5459)
[33m60dbd8a1e5[m Update maximum batch size for UT; Include recompute modes  (#5444)
[33mdbc626dcbe[m Add ExpGrad registration and test. (#5438)
[33m2a018cc235[m revert contrib op version bump and deprecation of TransposeMatMul (#5424)
[33m20c47ce91c[m Simplified layer norm changes (#5028)
[33med60e0fe39[m Fix BUILD.md environment variable name typo. (#5402)
[33m5e48c0fd6c[m Register opset13 ops: Dropout, Flatten, LRN, MeanVarianceNormalization, ArgMax, ArgMin, Reshape, Shape, Concat. (#5451)
[33m17544fc972[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m186f0668b0[m update onnx-tensorrt submodule (#5442)
[33mb9f90e297e[m Support sharing of initializers between session via the Python API (#5407)
[33m6132e1f6ae[m Shared providers - fix logging plus cleanup (#5406)
[33m6cba42e942[m Avoid inserting other CUDA calls in-between NCCL Send's and Recv's (#5430)
[33mdbe7e6623b[m only use/import pytest if needed (by enable_training) (#5437)
[33m9642f1448e[m Add OpSet 13 Registrations (#5426)
[33m3a9a1a4ef1[m Fix registration for GatherGrad (#5382)
[33m1cceefc7d4[m use run_orttraining_test_orttrainer_frontend_separately to work arounâ€¦ (#5408)
[33ma92ccbe1bc[m Various armv7 related fixes (#5394)
[33m8aa61aaa47[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mb99eaa99cd[m Prepacking MatMulInteger (#5403)
[33m621fdb44e5[m Fixes #4688, remove CPUAllocator in TreeEnsemble (#5375)
[33md4507e9331[m Use relative path for HEADER_SEARCH_PATHS (#5412)
[33m90f976d060[m Some improvements on transformers tool (#5383)
[33mfab7f799a7[m MLAS: fix ARM64 + VS2017 build break (#5423)
[33m8a632a903f[m Remove unused imports from Python tests. (#5405)
[33m15696b8fce[m bump version to 1.5.2 (#5420)
[33m498f94668d[m Keep all_finite tensor on CPU when using PyTorch Frontend (#5371)
[33mc2c78399ee[m Include config keys header file in the release packages for Linux and Mac. (#5388)
[33m09aef240d6[m Skip running onnx tests in python mac os pipeline (#5416)
[33m83ead3e2eb[m Fix com ptr refcount (#5404)
[33mb04cf2d229[m Update ORT to 1.5.1 in Bert Quantization Notebook (#5396)
[33m132ab2230d[m Updated with image for creating the onnxruntime pkg (#5400)
[33m9684e1b5a8[m Add doco for pre-requisites to be able to cross compile for Android on Windows with Java bindings enabled. (#5395)
[33m8133223871[m clear cudaDelayLoadedLibs since delayload is disabled (#5386)
[33m8ee2b08325[m Allow benchmark different threads (#5390)
[33m094384781e[m Add --use_external_data_format in convert_to_onnx.py (#5393)
[33m5947445457[m Add flatbuffers verifier for ORT format buffer (#5378)
[33mdeb708d3b1[m Move flatbuffers to 1.12 release (#5392)
[33m6f54113a1b[m Support OrtValue binding in Python to enable interesting IOBinding scenarios in Python (#5248)
[33m0122e890d9[m MLAS: implement u8x8 GEMM for ARM64 (#5380)
[33mb4934b0016[m Mitigate pybind11 build break using Xcode 12 on macOS (#5381)
[33m10f1902d90[m Update code snippet in README.md
[33m773992c7d4[m Liqun/bert pretrain tb (#5377)
[33mb5caa7cb12[m Updated docs: Execution Provider overview (#5328)
[33m1a3bfd7f06[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m323c4dfe02[m Adding an option for cudnn conv algorithms. (#5159)
[33ma0b8218f9a[m Amdmigraphx update to rocm3.7 (#5362)
[33m24f99b3be8[m Support OuterStride for QGemm when MLAS_SUPPORTS_GEMM_U8X8 undefined (#5374)
[33m668ab04917[m rename all TransposeMatMul nodes to FusedMatMul (#5373)
[33m891175d5d6[m Merged PR 5253310: Fix 0-sized dimension broadcasting
[33m4e3a420aa7[m Use single thread when pipeline is not enabled in TrainingRunner (#4265)
[33m3165d8045b[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mc20fcf26eb[m Onnx GPU runtime fails to fallback to CPU when GPU is not available/busy (#5304)
[33m4721729fdc[m Enable iOS CI pipeline (#5360)
[33m9df0790856[m Update linux minimal CI to report Android mininal baseline binary size (#5361)
[33m5bd7241839[m Raise output mismatch error in ort_test_dir_utils.py (#5364)
[33mf5e4c0ea04[m Fix benchmark_gpt2 model verification (#5343)
[33m6e4949e235[m javadoc warning fix (#5332)
[33m06cd81d791[m Support trilinear sampling in Resize CPU and CUDA kernels (#5300)
[33me71668f92c[m Expose recompute configs to the frontend (#5318)
[33me33de20861[m Update gpt2 notebook for int8 quantization (#5346)
[33mce49cfa67c[m add support for configurable build dir when building nuget packages (#5352)
[33mbb3c8f970b[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mf265834c2c[m Exclude GPT2_LM_HEAD from OpenVino's model test list (#5356)
[33m1612934f72[m Allow protobuf format of input data for performance test (#5323)
[33me8b9aa1f29[m fix quantization of EmbeddingLayerNorm (#5321)
[33m7495dc167a[m Symbolic shape inference: fix a bug in auto_merge when broadcasting (#5349)
[33mcaed6c264c[m Add tf2pytorch wrapper in transformers tool (#5316)
[33md62873a331[m Docker image release build updates (#5326)
[33mfe50213491[m Liqun/bert pretrain2 (#5327)
[33m1cad3e322e[m typo in contributing.md (#5340)
[33m2098d621a6[m Make some string optional for save to/load from flatbuffers (#5331)
[33ma343b21a09[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m383b1e207c[m Fix bug in the Resize operator kernels (#5303)
[33m3f00b8db8f[m move all experimental ops to version 1 of ms domain (#5287)
[33m2c32309e2c[m Update dockerfiles/README.md onnxruntime-training image tags. (#5333)
[33m37445d1198[m Update Bert Perf Script (#5339)
[33m8d4740b39c[m Add some log for the GetFileLength function (#5330)
[33mcb57c100e6[m Doc updates for 1.5 (#5302)
[33me237b9d7ed[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m69dbaaa015[m Add additional test cases to check for leaks in thread pool creation / destruction (#5311)
[33m1a12f510fc[m Support T5 benchmarking in transformers tool (#5133)
[33mc443330e98[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m9ec1ed42a8[m Enable BiasDropoutFusion for CUDA EP only (#5324)
[33med102e9d88[m Add iOS test pipeline and a sample app. (#5298)
[33mf07059ccc0[m Add weight prepacking to LSTM kernel (#5305)
[33m5af3630a29[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m11c194ce29[m Minor fix for ComputeBroadcastBackwardAxesDynamic; Fix for GradientGraphBuilder logging (#5313)
[33m24d8b1bf42[m to skip an unstable test to unblock release (#5314)
[33mcb83097632[m Cosmetic change in non tensor tests (#5317)
[33m1ff3b2d5b8[m Add ability to generate multiple test dirs so that different input mixes can be tested. (#5310)
[33meae2473dc1[m Scale Op for ReduceMeanGrad. (#5191)
[33m506060dc37[m Remove Useless Cast from Contiguous Cast Nodes (#5204)
[33md45d68fdd4[m Fix a memory leak in our testing code (#5312)
[33m3693f91218[m Update doc to be explicit about backwards compatibility. (#5309)
[33mb18a8bc74f[m Transpose kernel fix for illegal memory access error (#5294)
[33m1a04b8f8b7[m Add valgrind support to our cmake files (#5296)
[33mfec890a09a[m fix build break (#5306)
[33m507f5bf5f6[m Update test calibrate script (#5185)
[33md9ecc0cebf[m add bert loss legacy back (#5224)
[33m16d35266ab[m[33m ([m[1;31morigin/tensorrt[m[33m)[m add install targets for ep shared libs (#5286)
[33m3a3f26f38e[m Move ort flatbuffers helper functions and value info r/w functions into separated lib (#5276)
[33m098f6b9069[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m17f1178c2e[m Downgrade GCC (#5269)
[33mb03fb82ab7[m Transformer layer-wise Recompute (#4526)
[33mc2c30285cd[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mb6e71200eb[m Add additional tutorial links (#5272)
[33m89742411ec[m Insert telemetry template into GPU build, add telemry build switches. (#5278)
[33mebeeff22dd[m Update PyTorch TransformerModel sample (#5275)
[33m71b52ad5de[m Fix inbox telemetry  (#5265)
[33mb49ff6151e[m Workaround issue with VS2017 compiler. (#5279)
[33m5a71819be6[m Symbolic shape inference: fix a case for concat (#5277)
[33m4ed31ca214[m Combine custom logger global threadpools (#4857)
[33m6ad39819c2[m Update DirectML Nuget to 1.3.0 (#5274)
[33ma4cb00b91e[m Merge pull request #5273 from microsoft/user/dwayner/CmakeLinkerOptFlags
[33m6d5b93b805[m Synchronize training dependency versions between Docker image and Python wheel. (#5261)
[33m56862f4022[m Add way to disable additional linker opt flags
[33m16220f3848[m Add FusedMatMul contrib op (#5213)
[33mfe7e7bfe60[m Update build.md for building using Xcode 12 on Mac (#5256)
[33m61ba5b501a[m Fix bug in the back to back quantization of matmul and conv (#5264)
[33mb5a6a8e847[m remove implicit linking of tensorrt and dnnl ep shared libs (#5262)
[33m6ea66b43db[m ORT DirectML EP for Iron release, ONNX 1.5 (part 2) (#5263)
[33m75d994f194[m Handle zero norm values in LpNormalization CPU kernel (#5251)
[33md26c71f55c[m [java] Fixing the buffer semantics. (#5223)
[33mc52561d044[m Rework broadcasting setup to decrease binary size. (#5227)
[33m43faf9e388[m Disable a few tests that run too long(1 hour) in debug mode (#5257)
[33m3bbce69185[m bump version to 1.5.1 (#5258)
[33m59e69bf35b[m Handle missing initializers in allocation planner to fix crashes with DML provider (#5244)
[33m682ac275fb[m Merged PR 5201369: Remove copy of initializers added in DMLXP refactor
[33m9d57bb4ba7[m Add way to disable additional linker opt flags
[33med5665758c[m Merged PR 5195856: Fix broken cases of zero size tensors in Cast/Reduce
[33m898531f502[m Fix reshape fusion crash (#5252)
[33me30530d9ea[m Add java API for AddSessionConfigEntry (#5241)
[33m8dceebda0e[m [Training/Python] Add option to enable symbolic shape inference (#5107)
[33m14f250a4d0[m Update BUILD.md training dependency info. (#5240)
[33md957dbebea[m Fix possible ios build break after update to Xcode 12 (#5246)
[33m417929b049[m jobs timeout ..
[33ma6eb90472c[m try fix error on code coverage ci build
[33m1478643215[m Place Shape's output in CPU memory (#5245)
[33m038192bdb2[m  Place shape related compute nodes in CPU  (#4940)
[33m0cb09374c6[m Update BUILD.md for CUDA versions (#5239)
[33m3147bc00c3[m update TensorRT docs (#5238)
[33m55e4b5d302[m add pipeline distributed training test (#5222)
[33m84c222126c[m Deprecate testMNISTTrainingAndTestingOpset10 (#4927)
[33m974b9bfc09[m Allow sharing of initializers between sessions. (#5092)
[33me0719a1073[m Revert to using release SafeInt repo now that it supports a build with exceptions disabled. (#5233)
[33me9671e93f0[m Fix TransposeScaleMatMul and MatMulScaleFusion issues (#5230)
[33m65740deb10[m Fix a bug in EmbedLayerNorm fusion (#5150)
[33maefb2cc49b[m Create profile for all dynamic shape input tensors (#5229)
[33mcd663d58f5[m Fix WinML warnings (#5228)
[33m78a29aebbc[m [ORT Mobile] ORT Minimal E2E CI (#5200)
[33m8ee4e8226e[m Preserve relative order of the results and the tests. (#5225)
[33mb49f6a5e2c[m using GPU_WARP_SIZE to make kernel portable between AMD and Nvidia GPU (#5173)
[33m84589c7e05[m Fuse softmax(a + b) in case of simple broadcast (#4937)
[33me0b49844e9[m Provide option to let layernorm stash mean/var as fp32 or bfloat16 (#5215)
[33ma90ab12589[m Refactor onnx_test_runner (#5169)
[33m13318ab0d4[m Remove invalid install line (#5219)
[33ma632dd2d3b[m Amdmigraphx improvements (#5158)
[33mf91248e0cc[m remove curand_generator_ related code since it is not used. (#5220)
[33mce3b67e0cd[m [Python] Move symbolic_shape_infer from nuphar to tools (#5162)
[33mf7c1e51810[m Remove shape inference and fix save large model(>2g) issue (#5210)
[33mc46a480306[m Update conversion script and process to simplify creating ORT format models and a minimal build (#5217)
[33m1b61dfaf69[m fix _WIN32 (#5218)
[33mf5df96256c[m Fix order of returned values in quantize_weight_per_channel (#5205)
[33mf37e1292a1[m --shm-size=1024m to fix nccl shared memory issue (#5214)
[33m8156e0dd10[m [ORT Mobile] Some updates to iOS/Android build settings (#5184)
[33m8698157112[m NCHWc optimizer fixes for quantized models (#5203)
[33md535894297[m Add API to allow configuration of the global thread pools. (#5199)
[33me01e0b2e40[m Fix softmax_warp_backward math when is_log_softmax = True and register LogSoftmax CUDA kernel (#5160)
[33m584638e5d3[m Corrects doc typos and formatting (#5201)
[33mcd0386b649[m MaxPool versioning in quantization tools. (#5194)
[33mb11c106346[m Remove almost all of the reinterpret_casts from the provider shared API (#5190)
[33mc37472a1aa[m[33m ([m[1;31morigin/lay_norm_stash[m[33m)[m Mixed Precision Transformer and Gradient Builder Refactor (#4892)
[33mf3f119a945[m Use onecore umbrella lib in onecore builds (#5182)
[33m1a2e289d2d[m Fix nuget build (#5163)
[33me6f85f338e[m Refactor TensorAt, prepare for release (#5180)
[33ma20f8037f6[m Install ssh in builder image, fix segfault in TrainingRunnerTest.Basic. (#5186)
[33m400ac85565[m Improve error message for FE model export checking (#5156)
[33m965e2b095d[m Update MCR CUDA docker image to 10.2 (#5181)
[33m79e27d937a[m MLAS: add sgemm weight prepacking (#5183)
[33m3afc2bfa73[m Remove mutable arguments from symbolic_shape_infer (#5166)
[33m7f3aa3a163[m Add GetStartTime() for profiler to get private profiling_start_time_ (#4994)
[33ma0a435abc6[m Add sympy==1.1.1 to Linux docker image (#5177)
[33m0752fd7425[m change version number from 1.4.0 to 1.5.0 (#5178)
[33m9f526f45ac[m TensorRT Perf Tool (#4900)
[33mef496d36ea[m Build: Add missing EXCLUDE_FROM_ALL to ONNX submodule (#5161)
[33mde6e3fb61d[m Reduce IOS shared library size by symbol file. (#5171)
[33m8fa427b264[m Ryanunderhill/backout 5014 (#5167)
[33m089789c135[m Revert change to disable support for loading ORT format models in the packaging pipelines. (#5168)
[33mc0d7c8bc44[m Add docs indicating that the onnxruntime engine from other distributions can be compatible with the WinRT NuGet (#5009)
[33m1dde215d96[m promote cuda version on packacking pipelines (#5154)
[33m3068a835f1[m Fix quantization of 1-D conv with bias (#5157)
[33m82b25e1731[m Fix datasize call in calibrate (#5110)
[33mf7edf0aa57[m [OpenVINO-EP] Enable EP config options for VPU hardware (#5119)
[33md45e49dd2b[m Add LeakyRelu and Sigmoid QLinear Quantization support (#5116)
[33m8946d212bf[m Remove the dependency on CUDA SDk's version.txt (#5155)
[33m20b2f45b24[m Support per-channel quantization of weight tensor (#5057)
[33m2a456d16c0[m Enable onnxruntime iOS shared library build. (#5148)
[33mcc3212f9d5[m Add fp16 pow kernel (#5016)
[33m1d6a21fd08[m [TensorRT] Add slightly faster hash computation for `vector<int>` (#5142)
[33m0c7e9fb52a[m changes to ensure compilation issues in windows is fixed by disabling the level 3 warning 4267 (#5147)
[33m9392aa2f64[m Promote Cuda version to 10.2 for windows pipelines (#5138)
[33m6fcd99f6ed[m Some minor updates for ORT mobile (#5146)
[33me5892dd6f3[m Change the version check of ort format save/load (#5140)
[33m323a1ba8a4[m Add option to exclude support for loading ORT format models in full build. (#5129)
[33m5302fe4079[m A fix in load_pretrained_model() (#5137)
[33m849bb8653f[m Exclude a few python tests for the DML EP (#5135)
[33m698eccf15e[m Add iOS build instruction (#5125)
[33m7511021e0e[m Save Gpt2 test data (#5132)
[33m120e3cda74[m fix path (#5131)
[33m92a8c650ad[m [Debuggability] Add feature to ORTTrainer Frontend (#5124)
[33m89509f256a[m Not fuse SkipLayerNorm when add has initializer input (#5123)
[33mcd56ab197c[m csharp build documentation (#5121)
[33m15d431f39b[m Bump node-fetch from 2.6.0 to 2.6.1 in /nodejs
[33mccfbc56388[m Handle dummy mask in Attention operators (#5108)
[33mc794c88ae0[m Solve name conflict in TensorRT engine caching (#5128)
[33m51f3d3af72[m Enable onnxruntime_perf_test for ORT minimal build (#5126)
[33m59ee8ffb17[m Remove SparseTensor support from minimal build. (#5114)
[33m879751f3b7[m Support Tensorflow benchmarking and onnx export in transformers tool (#5068)
[33mc5efb0085d[m Update Linux GPU build pipelines to CUDA 10.2 (#5120)
[33ma8557b3f0f[m skip tests when model opset > released opset (#5096)
[33m782ccff207[m Add dll probe path so that the right DirectML.dll is loaded while running C# tests (#5104)
[33m5618b9dddc[m Use CMake built-in function to compare NCCL version (#5118)
[33mc5d4ae0401[m Add transformers tools to python package (#5090)
[33m61051396e8[m [TensorRT] Align naming convention and remove redundant code (#5094)
[33mfae5915d76[m CMake fixes/tweaks for minimal builds and MinSizeRel builds (#5112)
[33ma5530358c9[m Fix a path problem in Dockerfile.manylinux2014_cuda10_2 (#5106)
[33m47554a0422[m Disable some tests (#5103)
[33m3207de276c[m Remove IDeviceAllocator class as it doesn't extend IAllocator in any way. (#5067)
[33m5b6643cefb[m Move ort flatbuffers header to use enum class instead of enum (#5105)
[33m433061531e[m Enable onnx_test_runner for ort format (#5100)
[33m62848c4de5[m Add store builds to nuget packaging (#5040)
[33m9ba56dcfed[m Support Send and Recv for old NCCL versions (#5097)
[33m09a6ce6bc0[m Add re2 to memory leak checker whitelist (#5101)
[33m934f30fc38[m Not to call NVTX when not available (#5095)
[33m4b7aa16ed2[m Fix a few more signed/unsigned warnings. (#5098)
[33m5e10cde006[m PipelinesForCuda11Cudnn8 (#4938)
[33ma90fae8c71[m unify error handling in pipeline transformer (#5039)
[33m61151af321[m Fix typo in DML native method call from the C# API (#5083)
[33mf7c3e4fa99[m Store/containerized apps support (#4651)
[33m924ecb0623[m Use manylinux2014 for Linux CPU build (#5091)
[33m6594d6672f[m[33m ([m[1;31morigin/stevenlix/parser[m[33m)[m Move onnxruntime.experiment to onnxruntime.training namespace (#5045)
[33m4ccca20def[m Replace MPI Send and Recv with NCCL Send and Recv (#5054)
[33mdbf4e7019d[m Add ability to generate configuration file with required operators. (#5089)
[33m80ada0291f[m Improve the minimal build size on android and linux (#5086)
[33m5019b2f3b9[m fix for x86 android build break (#5088)
[33ma1a81470e3[m Add minimal build binary size verification (arm64) to Android CI (#5087)
[33mb8d63f31c3[m Bump bl from 4.0.2 to 4.0.3 in /nodejs
[33m07bf8b968e[m Register BiasGelu and BiasDropout for CUDA only. (#5060)
[33mf41614a875[m User/brianma/telemetry (#5084)
[33m1b46573bb7[m Update BUILD.md (#5085)
[33ma40d34386a[m Add Linux CPU CI for ORT minimal build (#5074)
[33mb23e08b85c[m Add AutoModel selector in transformers tool (#5051)
[33m4553b2eecd[m Expose DirectML provider to python (conflicts resolved from #3359) (#4630)
[33mc239ff0750[m Modify embedlayernorm fusion due to shape node merging (#4967)
[33m38453acae3[m Further populate Stop Gradient list (#5021)
[33me1ed0fde2b[m Prevent registering both DML and CUDA EPs in an ML op test (#5078)
[33m8d91d4ff36[m Build docker image instruction fix (CUDA) (#5070)
[33m6c33e95b88[m Fix signed/unsigned mismatch on x86. (#5079)
[33m796ddeb2cb[m Remove serialization of outer scope value info in ORT format model (#5077)
[33me03a391895[m Small updates to ORT Mobile documentation (#5075)
[33m36dc057913[m Add unit test for C# setting of session options config entry. (#5073)
[33m5d60d57ce2[m Add csharp API for AddSessionConfigEntry (#5072)
[33m2c1410afe7[m Remove usage of macros for constants in public header. (#5061)
[33m6081c1cfa2[m Update ONNX to latest (#5069)
[33md922cb1081[m Add sequence and map support in ORT mobile file format, add UT (#5066)
[33mde58720a97[m Liqun/transformer test and e2e golden numbers (#5064)
[33m84de14a833[m Register OpSet13 CUDA Kernels for BERT/UniLMv2 (#4856)
[33m370d194db7[m Add a docker file for CI build CUDA 10.2 (#5065)
[33mec88f14a7a[m Implement QLinearMul in mlas (#4593)
[33mb5c2932ae8[m Last major set of ORT format model changes (#5056)
[33m6134994db9[m Parallelizing elementwise kernels (#4577)
[33m0dad79b495[m Add SetLanguageProjection C Api and use it in four projections (#5023)
[33m6dd4af3936[m Fix initializer name only when wrapper is applied (#4920)
[33md792af776d[m Remove Cuda dependency from TensorRT shared provider (#5014)
[33m78bb53381b[m optimize resize op for NN mode for some fasterrcnn model (#4825)
[33m8289981f0e[m Implement QLinearSigmoid. (#5015)
[33m0fc9c504fe[m Re-enable CI tests for the new PyTorch frontend (#5017)
[33mbd215b79a2[m ACL v20.02 (#4981)
[33m73456f10cd[m Fix contrib ops unregister to match pytorch behavior (#5052)
[33md7502eff8f[m Add nodejs samples README (#5005)
[33m4b9b5b6146[m Imported protoc cannot have compile options. (#5030)
[33md7984fe6ba[m Add packages from training docker to cgmanifest. (#5033)
[33mbb13b52291[m to allow parallel training with mpi4py (#4942)
[33m9388d49c0d[m Add warning to non pickable models (#5037)
[33m9d1bdef195[m Update CODEOWNERS and minor docstring fix (#5002)
[33m546965c2da[m Add deterministic path for AllReduceL2 (used to compute gradient norm) (#5027)
[33m9ba2cfb71b[m fix py packaging pipeline (#5038)
[33m22ba266bd6[m Add flag to _internal_use to control export of contrib ops in ort trainer (#4968)
[33m28445c88f9[m Changes to enable saving and loading an ORT format model (#4995)
[33mbbb9d92a5f[m Remove SchedulingParams variants of ThreadPool::TryParallelFor (#5050)
[33mfde7a2c848[m Temporarily switch SafeInt to a fork for an option to disable exceptions (#5041)
[33me0d1cf19a6[m Fix allocator bug (#5042)
[33m3268717615[m Enable TF32 for training on A100 (#4914)
[33ma9db287bd7[m Return windows error code for library loading and unloading failure (#5036)
[33mb4e9e98cee[m Add more huggingface models in benchmark tools (#4986)
[33ma935731bd3[m Neg Gradient (#5022)
[33m4a0f6595eb[m Enable metadata and signature changes in graph transformers (#4783)
[33m4fd4b74149[m Change session option values if they don't work with EPs being registered for the session (#4991)
[33m8a03b6e5c7[m Render Operator documentation as compliant markdown (#3658)
[33me1901a7e10[m Improve performance of CUDA implementations for GatherElements and Greater, Equal and Less (#4989)
[33md5d5e37e76[m Build system enhancements (#5012)
[33maabed34d5c[m Fix checkpoint API and improve loss scaler handling (#4950)
[33meebc2cccce[m Fix fetches when eval_step's input is a subset of train_step's input (#4966)
[33ma6e219deff[m Pass Model Path to TensorProtoToMLValue from Constant Folding for External Inputs (#5000)
[33m5651c23271[m Fix for Android ORT android initOsArch exception (#5006)
[33m44b3accb74[m Missing header for `std::once_flag` and `std::call_once`. (#5010)
[33m9902b57090[m Fix a warning in global_thread_pools/test_inference.cc (#4987)
[33mf38f2d5b54[m Port #4920 into the new pytorch frontend (#4965)
[33md30dd41c0e[m Remove public default ctor in PyInferenceSession and replace it with a protected ctor (#4990)
[33mc6a3620ba8[m Remove evaluate telemetry due to redundancy (#4996)
[33ma47cae031f[m Use raw attention mask in BERT related fusions (#4889)
[33md79af260bb[m Liqun/new api orttraining test transformers (#4982)
[33m64237d999c[m Add Cmake config for onnxruntime_NO_EXCEPTIONS (#4975)
[33mad1701dfb1[m Rename DeviceAllocatorRegistrationInfo to a more generic name; Use OrtArenaCfg for arena members; Remove unused OrtMemType; Simplify CreateAllocator interface. (#4970)
[33mffc2b25a3a[m Quantization tool improvement (#4933)
[33m464bbd27a9[m Zhalei/optimize nms (#4875)
[33mcf1b74396a[m Fix build break for microbench. (#4960)
[33m14b51d6502[m CiPipeline@ReducedOpsBuild (#4917)
[33m7ca8388dc9[m [ORT Mobile] file format schema and file I/O code (#4973)
[33mbca9ccb1b3[m add install sec updates (#4957)
[33m1e1f5a9c79[m support data parallel + pipeline parallel (#4648)
[33m9817b8c8a7[m Fix state_dict/checkpoint issue introduced by #4639 (#4984)
[33m8679a7244e[m Enable rejecting models based on onnx opset (#4912)
[33m50c610e70a[m Stop Gradient at Shape op (#4983)
[33m7af052fd62[m Add CI status badges for Training builds (#4951)
[33m6d9d252bc3[m Disable NegativeLogLikelihoodLoss_LargeSizeTensor test (#4979)
[33mb41e5e88fb[m Add more node debug dump functionality. (#4921)
[33m98f7fdd7da[m Handle MatmulGradient with 2D Weight at B (#4977)
[33mbac41969be[m update (#4948)
[33m64d52ae47d[m Support creating sessions using DML EP via C# (#4955)
[33m7080e485a3[m hHandle upper-cased subscript labels in Einsum (#4964)
[33mf4b057b098[m Fix DML License in nuget package (#4969)
[33mea5732319e[m Add option ORT_NO_EXCEPTIONS to disable most exception/throw in /onnxruntime/ (#4894)
[33m655ffd5d5b[m make (de)tensorization events measure level events (#4958)
[33mcd0f2fb48c[m Add code oweners for pytorch frontend (#4963)
[33m7045910d10[m Support RegisterCustomOpsLibrary via the Python API (#4764)
[33m040c5fa3e0[m Merge pull request #4925 from microsoft/user/dwayner/Iron
[33m1281ff6462[m Put operators in-between Wait and Record (#4916)
[33mb945225de3[m Include DirectML pdb in x86 bin folder (#4953)
[33mc37fa7c278[m Delete Dockerfile.centos6_gpu (#4851)
[33m39382dc6c3[m Update winrt_api.md to address the 1.4 release (#4946)
[33m79429c934b[m Update
[33ma7ce5b2be1[m fix comment and casing of telemetry fields for named dimension overrides (#4943)
[33mdfb9d97ddf[m Support DistilBert's Attention fusion in Optimizer (#4748)
[33me6b6736e48[m update cuda capabilities (#4936)
[33mefdd96595f[m bfloat16 and opset13 related fix (#4913)
[33mf68d5263b7[m Merged PR 5100436: EinSum ONNX 1.7 (opset 12) ORT DML EP kernel
[33mb5c765c76b[m Merged PR 5103319: 8d Update
[33m970ddd56a7[m Fix typo in contributing.md (#4939)
[33m9f5d4918dc[m MatMul Gradient optimization for dB when B's is 2D tensor (#4899)
[33m6dc85b5f14[m wstring_convert std::codecvt_utf8 add ~200KB to inbox windows.ai.machinelearning.dll binary size  (#4932)
[33m2b460eaeca[m Revise IDisposable implementation in C# interfaces (#4915)
[33m08eb15068c[m Exclude the Map types from the build if ML ops are disabled. (#4908)
[33m792ed44537[m Support EmbedLayerNorm fusion for DistilBert (#4928)
[33m00fe718264[m Fix divide-by-zero for SSCE kernel when normalize factor is zero. (#4911)
[33mcac25751bd[m Fix mnist example (#4926)
[33m438babd966[m Fix some Android build issues when ORT_MINIMAL_BUILD is defined. (#4924)
[33mb3783a9f85[m matching multiple choice between new and old apis (#4918)
[33m0d3bbfdd0f[m enable nuget packaging in local builds (#4884)
[33m0a2848d3a0[m Remove cerberus from wheel package (#4919)
[33mcb5e199a79[m Merged PR 5093868: GatherND1 ORT DML EP
[33m5d3638e935[m Fix symbolic shape inference bug when subgraph contains Constant node (#4858)
[33m170fee0987[m User/xianz/fixbuild (#4906)
[33m1161c4d75f[m Exclude MLAS AVX512 in minimal build (#4905)
[33mcb2dfee31c[m Size Op - CUDA kernel support (#4868)
[33m294eaca9ef[m Support double for ArgMax operator (#4907)
[33m3d63d8d4f1[m Extend C++ API for Map/Sequence Type Info (#3517) (#4781)
[33m6c26e52134[m Support accessing a model's metadata in C# (#4867)
[33m26bd8c2085[m Support scalar tensors in c# (#4849)
[33md3cddba8f1[m Add this line to allow collection of AppSessionGuids (#4901)
[33m14c691030f[m Fix build break from removing custom ORT onnx protobuf (#4904)
[33m71d8846635[m Fix telemetry-steps.yml (#4903)
[33mf34ed3a576[m Hot fix for the python packaging pipeline Linux ARM build (#4902)
[33m83b7c1151a[m Merged PR 5086432: Update Operator Pow-12: Allow exponent to differ from base type
[33mdb6a821869[m Enable example transformer test with dynamic size inputs (#4888)
[33m824fcbfd9d[m support Normalized_0_1 and Normalized_1_1 (#4800)
[33m268d2283c0[m Export GPT-2 ONNX model without postion_ids and attention_mask inputs (#4852)
[33m26546f81fe[m Remove the private ONNX protobuf definition file (#4878)
[33mc5cb9d7b41[m match reshape fusion for distilbert (#4844)
[33m744809ceae[m Detect whether the node has been inserted cast nodes twice (#4811)
[33m1542a8a9b7[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m3dd2d53593[m Merge branch 'DmlDev' of https://microsoft.visualstudio.com/DefaultCollection/WindowsAI/_git/onnxruntime into DmlDev
[33m47c4144bd1[m Add gcc/clang flags to make binary smaller (https://interrupt.memfault.com/blog/best-and-worst-gcc-clang-compiler-flags#-ffunction-sections--fdata-sections----gc-sections) (#4895)
[33m8cc5e9748f[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m7c0ff3742f[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33meb05db5a2a[m Fix OptimizerConfig params groups (#4877)
[33m728e886bba[m Add kernel def hash logic for minimal build (#4891)
[33mdb7669b225[m Reduce ONNX dependency in minimal build (#4890)
[33m29dcfb24ab[m Allow multiple sessions to share an allocator, optimize constant folding memory usage, expose arena configs. (#4813)
[33m46863a2868[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mfa68bbc82e[m Relu grad kernel (#4864)
[33mdce2ce7a4f[m Fix checkpoint API and copy samples into build dir (#4887)
[33m6260d073b3[m Glue parallel training (#4550)
[33m9a6db9b9f4[m Fix next node access bug in calibration tool (#4863)
[33m3fa73a5b6a[m ReduceBinarySize (#4747)
[33m82bc21e35e[m Namespace change on ort flatbuffers schema (#4886)
[33mfdd0926d00[m int64_t support for GatherND cuda (#4881)
[33macbf6d15c6[m Improve LRScheduler tests (#4885)
[33me00ad83f2b[m Initial changes to disable code in a minimal build (#4872)
[33mfb43aa0de0[m implement per-channel for quantizelinear and dequantizelinear (#4759)
[33m5427a7e9af[m Update LRScheduler to use scheduling similar to HuggingFace (#4880)
[33m985b741780[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mef19916d07[m Add Node::SinceVersion() (#4874)
[33md4d52056be[m Flatbuffers schema for serialization of the onnxruntime::model/graph (#4870)
[33ma0271f619a[m Range CUDA inputs should be in CPU (#4871)
[33mc5342b5417[m fixed compilation issue for Jetson Xavier (#4873)
[33m730d95107d[m Merged PR 5065263: ONNX backend autopilot crash in WinML ToString running test_cast_BFLOAT16_to_FLOAT
[33m40324e6f77[m Merged PR 5068977: RoiAlign (ORT DML EP)
[33mc6119a548c[m enable telemetry in node.js binding
[33m3a00b50cf8[m [OpenVINO-EP] Updating OpenVINO EP to 2020.4 (#4836)
[33md00a70a432[m Fix broken Nuphar docker file by removing stale build options
[33m7589445e6e[m Add ONNX BERT Frozen Weights and Save as ONNX Tests (#4859)
[33m25cc6158a8[m update golden numbers (#4865)
[33m101cd80bd7[m fixed a warning on an unreferenced local variable (#4861)
[33mdc50aa42d5[m Refactor session state finalization and kernel lookup usage  (#4763)
[33md7233c7c97[m Fix training for models with dict input (#4842)
[33m7cc88ef7ed[m Port legacy checkpoint API into new front-end (#4855)
[33mc8155c79cb[m Merged PR 5051981: ArgMin/Argmax 12: add select_last_index attribute
[33m75ad7be336[m add caching support for dynamic input models (#4702)
[33md350d9ac5e[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mfff0b41fcb[m Nuget build break fix (#4854)
[33m5eaac31faa[m support opset13 on transformers. (#4837)
[33m61a5502af0[m Fix some incorrect operator registrations. (#4838)
[33m1ba07ccfaf[m Codesign validator fixes
[33m0575881949[m Update quantization notebook to pytorch 1.6 (#4834)
[33mdee7596724[m Add a generic collection of session configurations to the SessionOptions (#4718)
[33m81ff168833[m Update stale.yml with current labels and mark stale items as "stale" (#4831)
[33m2605af9a0b[m Fix for mainz model (#4744)
[33mf3b0c93a45[m Fix issue preventing loss scaler to run due (#4833)
[33mc4353b65cf[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33ma3c95374c3[m Support asymmetric paddings in CUDA Conv kernel  (#4627)
[33mc878ecbbe0[m Sahar/csharp support openvino (refined) (#4835)
[33m24d9f4e0c3[m Add More Extensive ONNX BERT Tests (#4827)
[33me98697ec28[m Fix nuget cpu package pipeline (#4832)
[33md3af669980[m Auto upgrade base image dependencies (#4797)
[33mf933910ea3[m Update LambConfig defaults to match backend (#4826)
[33m6a360bad6b[m ReplaceStrncpy (#4823)
[33m32a5f3d5b6[m Check status of element-wise op prepare functions. (#4830)
[33mef20efe015[m Register cerberus license into ThirdPartyNotices.txt (#4828)
[33mea37a4d89b[m Add Trilu custom op (#4537)
[33m1ce2982f65[m Update GPT-2 notebook using IO Binding example (#4799)
[33m360e2ae11b[m Update eigen to the latest to support C++20 (#4817)
[33m94a6f50af6[m Revert "Sahar/csharp support openvino (#4703)"
[33m42408aa3ed[m Add new PytTrch front-end (#4815)
[33m5eec4f66ed[m Refactor manylinux docker image and the related pipelines (#4751)
[33mbf300e3c18[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mea3b4e1f8d[m[33m ([m[1;31morigin/roli/matmul_prepack[m[33m)[m Fix bug in DispatchOnTensorType macro (#4808)
[33m5899c1197a[m add telemetry for named dimension overrides (#4794)
[33m0a0ac70eec[m Sahar/csharp support openvino (#4703)
[33m1b1a6a4ca9[m Bump onnx to get bfloat16 in ops, and some update in ort to support bfloat16 (#4791)
[33m6a638ad22a[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m8ba6b6a21e[m Support usage of C API with C++ standards older than C++11 (#4257)
[33m19494aba7a[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m8d2e22558d[m unattended-upgrades (#4804)
[33m5a8962d327[m Make grad name unique (#4788)
[33m56a5c7fc85[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mafa89566d7[m Using cublasGemmBatchedEx/cublasGemmStridedBatchedEx for training (#4731)
[33mec36c793e8[m Eliminate redundant subexpressions (#3047)
[33mce65275edf[m C# samples: Faster R-CNN (#4733)
[33mde2685261b[m Install AzureML support and commonly used packages in the training image. (#4790)
[33m7acef875bb[m Fix bugs in TensorRT (#4780)
[33maa993e95c9[m enable build flag '--use_openmp' on MacOS (#4774)
[33mf12e9de111[m build fixes for https://github.com/microsoft/onnxruntime/pull/4721 (#4784)
[33mf01579b8fb[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33maca34352a5[m Java API: Documentation cleanup (#4395)
[33m722602f32d[m replace namespace reference with alias (#4786)
[33m5e7a6e78e3[m Changes for BART dynamic shapes in reduction (#4730)
[33m74b3b8448c[m Fix MatmulTransposeFusion::ApplyImpl() setting of modified flag (#4775)
[33m8fb743f767[m Refactor Cast to reduce binary size. (#4765)
[33m9cec98ec1b[m Honor allow_spinning at barrier at end of parallel sections (#4767)
[33m61b2a663a3[m Update Python version support (#4778)
[33mcddddc4d55[m Add missing header file to MNIST.cpp (#4773)
[33ma69ca63895[m add --no_attention_mask option (#4750)
[33madda8c66d9[m Docker image release pipeline (#4682)
[33m8a66ad79a6[m Add Experimental WinRT API IDL as placeholder for adding new winrt features (#4736)
[33m7e955960f1[m Optimize Slice Kernel by Removing If-statement (#4753)
[33mb7254551f0[m Add new api function At() (#4457)
[33m38c804a048[m Fix broken link to ScoreMNIST.java in Java_API.md (#4213)
[33mac725b53f6[m Convert TensorRT provider into a shared library (#4721)
[33mac4997665a[m Make Java Publishing and Java GPU pipelines to run nightly (#4749)
[33mf51385fd1e[m Yanchen/nuphar/clip 11 (#4737)
[33m6037b41c17[m Merged PR 5002755: Add Celu, GreaterOrEqual, LessOrEqual
[33m3530ce541c[m Expose IOBinding features via C/C++/C# language bindings. (#4646)
[33m6c33d7f5df[m Fix bug in Loop optimization  (#4210)
[33m082a741636[m Move DNNL workaround to EP (#4738)
[33m487665c21f[m Transpose MatMul fusion fixes (#4728)
[33m316d1a9e69[m Update benchmark for large model or model name with non-alphanumeric. (#4743)
[33m6499a38b7d[m Add the missing onnx_proto import (#4705)
[33m2e3ccc7518[m Change order of some checks to workaround a linker issue when /LTCG:incremental is set. (#4713)
[33m24d4f76436[m Added explicit instructions to build for Jetson (#4714)
[33mabbb7f6f5c[m Avoid duplicated calls of postprocess in training frontend (#4579)
[33m77c69a0325[m Upgrade TensorRT to v7.1.3.4 (#4704)
[33m9c3153acd6[m Improve shape inference for OneHot (#4452)
[33m9c729d1719[m Update notebook for mac since onnxruntime 1.3 or 1.4 in mac does not have openmp (#4732)
[33m37c45c3d6b[m C# ResNet50 v2 sample/tutorial (#4722)
[33m61726e58f0[m fix (#4697)
[33mc334b5738e[m Remove docstring for removed parameter (#4734)
[33mb22091dc91[m Add the framework to support prepack (#4413)
[33m33fe770037[m Support log sigmoid gradient (#4719)
[33m7905c57f43[m Revert "Remove code which is not thread-safe. (#4454)" (#4712)
[33mfc2f36c608[m Shape independent gradient builder for Concat (#4675)
[33m8507bc1f48[m [Android NNAPI EP] Enable test for BatchNormalization, enable dev_mode for Android, fix some issues in concat (#4715)
[33m4d39c6a6cb[m Wire log(softmax) grad cuda kernel and add log(softmax) grad cpu kernel (#4726)
[33m9a73c8f448[m ReshapeGrad optimization (#4708)
[33m005fa5c3ae[m Add initial Dockerfile for distributed training targets (#4578)
[33me802b0498f[m EnrichPyOpUT (#4681)
[33m43142a8225[m [Nuphar] added Gemm-to-MatMul conversion in model editor (#4691)
[33m5c5efa900d[m Add .NET Core 3.0 nuget e2e pipeline tests (#4695)
[33meb0f57f0e4[m Localized Recompute for Gelu and AttentionDropout (#4402)
[33m0933148fc3[m [Android NNAPI EP] change most of the exceptions to return Status (#4701)
[33m1e054739b8[m Remove the requirement of CUDA's version.txt (#4706)
[33m9d7284fc3b[m Enable MatMul + Scale fusion (#4669)
[33mf9bd52f852[m Log telemetry for WinML Native API for setting intra op num usage (#4700)
[33m4bd9e8d05c[m Stress-test and fix thread pool when work queues are full (#4690)
[33md0297f8d24[m Add 'Install ONNX' step to Windows GPU pipeline (#4696)
[33m49febba3c2[m Support int32 and int64 types for Tile CUDA kernel (#4684)
[33me6ef3653a7[m Add Named Dimension Override API to LearningModelSessionOptions (WinML) (#4606)
[33mbb9b452a88[m resolves #3101 - fix nuget package restore for sdk-style projects (#4680)
[33m0828a900e1[m Support easy way to request verbose logging in test runner (#4676)
[33mf74e55cfc9[m Merged PR 4986854: Opset 12: Clip, Max, Min, MaxPool, ReduceMax, ReduceMin
[33m01ca6392cb[m Avoid building ONNX of every history ONNX versions in our CI (#4678)
[33me70e9e2f67[m refine machine_info and output onnxruntime_tools version (#4679)
[33m6958f49dae[m Added Dockerfile and build instructions for Jetson. Also set CUDA arch set automatically. (#4637)
[33mb1bfff34e0[m Support distill-bert fusion in transformers tool (#4631)
[33m8cf2c1c410[m Modify EmbedLayerNorm to support distill-bert  (#4666)
[33m1eadec0eea[m Update Versioning.md for Windows 10 and Microsoft.AI.MachineLearning NuGet versions (#4659)
[33mc67dd693c2[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33me9d20e9dba[m Revise Send and Recv (#4547)
[33m3588c5b545[m Add GPT-2 test generation to convert_to_onnx.py (#4670)
[33m1fcd3eb376[m cancel night build on pyop (#4673)
[33mf9f25c5559[m Remove featurizer from CI build (#4661)
[33m5ce675c3b9[m Expose Onnxruntime Intra Op thread controls through WinML Native API (#4638)
[33mde0b04b971[m [Android NNAPI EP] Add support for dynamic output (#4650)
[33m282975aefb[m [Android NNAPI EP] Add QLinearAdd op Support, move some throw with return status (#4607)
[33mdaa60c7dfb[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m51332e3c81[m Change Linux CI build time out value to 3 hours (#4664)
[33m319d30e50e[m dnnl only run opset 10 model tests to reduce footprint/runtime (#4663)
[33m0a8bfb10fa[m Inbox WinML tests fail because Inbox loads binaries from system32 (#4660)
[33m382f94c95c[m Fix regression introduced in cast transformer (#4658)
[33mf90a2d46ae[m[33m ([m[1;33mtag: orttraining_rc2[m[33m)[m Changes to support TNLRV3 fine-tuning (#4639)
[33md8f3e46d45[m Readme updates (#4448)
[33mdb475c4f35[m Add option for onnx_test_runner can pause after launch, make create_test_dir work on non-windows os (#4618)
[33m326cc686df[m Update notebook: disable GPU for tensorflow (#4649)
[33m6adc83d660[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m623dd53eb7[m Rename inner-scoped variable to avoid MSVC warning (#4587)
[33mf3fc8ca954[m Add input tensor calibration (#4619)
[33md4983f83ff[m Shape independent gradient builder for ops requiring broadcast  (#4586)
[33m948a33bdfc[m FixPyOpSegFault&MakeItStaticLib (#4600)
[33m6c2bd127ba[m more types for comparison ops (#4634)
[33m72908b146e[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m73ad92e773[m Change ignore_index to 0 in Bert-Loss. (#4640)
[33ma06cf6a3b3[m Show quantization model size in benchmark of transformer (#4626)
[33m73c99f8269[m Set WINVER (#4636)
[33md73e01e5b9[m remove ENABLE_TELEMETRY macro (#4633)
[33mc08e5f55e9[m Fix misleading indentation (#4629)
[33mefa393e596[m[33m ([m[1;31morigin/jetson_compiler_flag[m[33m)[m WinML should dynamically link against onnxruntime.dll and only system32 for inbox builds (#4615)
[33mbee13d657b[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m222fd08f20[m DirectML.dll is loaded via LoadLibraryW but should use LoadLibraryExA (#4616)
[33m1e67fff93c[m Add GetStringTensorElement, GetStringTensorElementLength and FillStringTensorElement API (#4374)
[33mc361a59cff[m disable gpu timeouts in winml (#4604)
[33m48d969f4bf[m Constexpr CreateFeatureValueFromInspectable (#4460)
[33m9510f26744[m [Python] Support more APIs for the SessionOptions class (#4596)
[33m9888c9e944[m SplitTraining op to support split as input  (#4597)
[33maa328c2c20[m Update GratherGard to accumulate in fp32 (#4601)
[33m9c75c29403[m refine opset version getter (#4602)
[33m5189530b7b[m Create the ConcatTraining op (#4595)
[33m15e1a1e1ac[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33md5b98a13c2[m Move ReduceSumTraining op under orttraining (#4588)
[33mf35ce4677f[m add double and uint8_t datatypes (#4603)
[33mde870c9637[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mace41b8064[m Force return_tuple=True to handle transformers breaking change of output format. (#4599)
[33mea87c0d028[m Update Transformer Optimizer documents (#4591)
[33m03ebe33850[m [Android NNAPI EP] Add support for LRN/Grouped Conv ops, fix issues where NNAPI will fall back to CPU (#4582)
[33mc5df918744[m improve calibration tool (#4561)
[33m1b253d18ef[m Updated tags for MCR images (#4574)
[33me2acb165e9[m Add exception check in training_runner when worker runs into error, and misc check on nccl and mpi calls (#4380)
[33mc2ec3b734b[m [Android NNAPI EP] Remove dependency on external JD/DNNLibrary (#4576)
[33m3b53be001b[m Merged PR 4954300: Enable preliminary 8D support in DirectML EP
[33mf0edd074fb[m Optimize CreateEnv by not creating the logging manager instance if env instance has already been created. (#4583)
[33mfa6d035090[m Create WindowsAI zip files automatically as part of the pipeline (#4584)
[33m0b5117958a[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m6b53a74867[m replace invalid sample (#4567)
[33me00e2e84d6[m [OpenVINO] Update MCR dockerfile with Ubuntu 18.04 package names (#4581)
[33mf20afc4991[m Update ACL/ArmNN EP (#4571)
[33m822b23ff2f[m Add support of EmbeddingLayerNorm (#4562)
[33m42d0ad8fec[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mbf78e4d18b[m Handle cases which produce an empty output in the MatMul op family (#4573)
[33m8829d60f94[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m0b4659c3fe[m Populates TensorProto with tensor from protobuf file (#4535)
[33m603f2d1138[m Exclude a few OpenVino flaky tests (#4572)
[33maffdeb53c2[m Add Python API for specifying device options. (#4205)
[33me11629d9e4[m Revert "Deprecate TrainableDropout (#4501)" (#4564)
[33md1500e1fc8[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mab4be8355f[m Add the BroadcastGradientArgs op (#4511)
[33m0008e92b4e[m Internal ReduceSum op that accepts axes as input  (#4522)
[33me92e0860c8[m BERT quantization notebook (#4543)
[33mca0dd8246c[m NNAPI EP, add quantization support (#4530)
[33m7f9d9557b1[m Remove template<T> from RoiAlignBase (#4558)
[33mbbdabc2c48[m Bump lodash from 4.17.15 to 4.17.19 in /nodejs
[33mc2c4e6760b[m Fix code sign validation errors in nuget and nodejs pipeline (#4527)
[33m1c5733ea9d[m Silence binscope warnings (#4542)
[33m9318b3a47f[m Fix a typo in C++ sample application (#4556)
[33m9d80235607[m Reshape inputs for SoftmaxCrossEntropyLoss instead of transposing them. (#4551)
[33m194367a2a3[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mbc1d197ddf[m Re-enable dnnl in CI build (#4544)
[33m0e91e45049[m [node.js binding] use official ORT C++ API (#4552)
[33m08235e1662[m add Output() overloads (#4546)
[33ma15506ee84[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m6c950a1df0[m Exclude weight related types/shapes from bert loss. (#4548)
[33me5716ebe41[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mb42fe49f56[m Add a script to convert gpt2 to onnx (#4541)
[33m0229a6a929[m [C++ API] add SessionOptions::SetLogSeverityLevel() (#4545)
[33m6eb5549cb9[m Deprecate TrainableDropout (#4501)
[33mfdc5c308c4[m introduce macro ORT_API_MANUAL_INIT in C++ API (#4536)
[33m21d2728974[m Revise pipeline schedule to consider communication ops (#4524)
[33m5b7050321f[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m1154b6e579[m Merged PR 4933520: (ap build) Update to GSL 3.1 - Fix signed unsigned cast warning
[33m183098e344[m adding concat logic when initial path is empty (#4525)
[33md1f45f9361[m Handle nodes with dtype attribute causing diffs in inferred and actual types of NodeArgs due to InsertCastTransformer (#4523)
[33m8b86c5cdb5[m Merge int32/uint32 and int64/uint64 MatMul kernels (#4531)
[33m02aea5d2d4[m rename telemetry provider back to Microsoft.Windows.AI.MachineLearning (#4533)
[33m5086e55a35[m Fix condition of running tests in win CI (#4459)
[33m2189c77e5b[m static_typename (#4520)
[33mb43ce2d7ad[m Replace loss function in BERT_LOSS with SoftmaxCrossEntropyLoss. (#4509)
[33m76b31d6ce2[m fix xcode alerts (#4470)
[33m42a5a4bff1[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m8ada440961[m Move model tests to onnxruntime_test_all (#4521)
[33m5f188f4cf4[m ci fix (#4519)
[33m938a4a7fa2[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m0ebe2fab51[m Refactor TensorRT EP code to better handle dynamic shape subgraphs (#4504)
[33mcf92497c16[m Nnapi, add auto_pad support for Conv/GlobalAveragePool/AveragePool/GlobalMaxPool/MaxPool operators (#4499)
[33m34f73fa1aa[m Add sudo --preserve-env option to allow environment to go through to docker commands. (#4512)
[33mf721f5f1cd[m Liqun/multiple choice (#4480)
[33m00d775e567[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m7d96960ec8[m support pipeline partition with shared initializer (#4321)
[33m1ebe598286[m Conditionally compile without std::is_trivially_copyable to satisfy old GCC versions. (#4510)
[33mee5ca27ae2[m Split Microsoft.AI.MachineLearning.nupkg in a NuGet package and symbol NuGet package (#4503)
[33m0714c1db98[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m273a4ff1b3[m Merge branch 'DmlDev' of https://microsoft.visualstudio.com/DefaultCollection/WindowsAI/_git/onnxruntime into DmlDev
[33m25885cf7d0[m Add option --torchscript in benchmark_gpt2.py (#4500)
[33m907952ef8c[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33ma2838d71a0[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m9d10a2d589[m Merge branch 'DmlDev' of https://microsoft.visualstudio.com/DefaultCollection/WindowsAI/_git/onnxruntime into DmlDev
[33ma95ae164f7[m Create N-1 threads in intra-op pool, given main thread now active (#4493)
[33m0bff55512e[m updated expected values for frontend test to pass frontend e2e pipeline. raise tolerance to reduce future risk of failure  (#4497)
[33m7753b8dce6[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33me0eddf502c[m Bump version to 1.4.0 (#4496)
[33m3d4ac85124[m Add quantization benchmark for transformer based model (#4482)
[33ma3c358fd29[m Split the shared ComputePadAndOutputShape into 2 separated functions ComputePad and ComputeOutputShape (#4487)
[33m3441c687b7[m Revert "Remove docstrigs if __ONNX_NO_DOC_STRINGS" (#4495)
[33m5f8f443ac4[m Android CI build, test copy, emulator boot improvement (#4481)
[33mb1b75b35ac[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m35ee00d888[m Pin typing version. (#4490)
[33m07455cff28[m Support double type for Greater CPU (#4373)
[33mf18dee84c2[m Remove docstrigs if __ONNX_NO_DOC_STRINGS (#4494)
[33mc71c49aaa0[m Make TArray safer to use and update method name for consistency. (#4483)
[33m00706e1502[m dont add deps for uwp apps (#4485)
[33m3e48ffd21c[m Move AutoPadType to common.h (#4474)
[33me96a829e84[m Handle multiple embed nodes in transformer optimizer (#4471)
[33m6a9a9a35be[m fix crashes caused by test runner (#4475)
[33m26ebcfab88[m Fix Nuget GPU pipeline (#4462)
[33m9b4c54bcef[m Enable onnxruntime_test_all for NNAPI EP (#4476)
[33m6c7da5e9d3[m Optimize CUDA Sum op kernel and refactor CUDA elementwise variadic input op kernels (#4418)
[33m04586fc09d[m Fix segmentation fault caused by invalid tensor type (#4467)
[33mccbf49e59f[m Fix avx2 load 32 bytes buffer overrun. (#4455)
[33md4db83858b[m Only quantize gather with initializer (#4469)
[33mbec18eb3f4[m [Node.js binding] support CentOS 7 in CI (#4447)
[33mca5af9d622[m Add modern C++ standards for Ort::Value (#4367)
[33m7fb194d03d[m Update convergence baseline for ci_test. (#4465)
[33m3effac2990[m Experimental C++ API examples (#4358)
[33m5dc7339be6[m Add quantization tool to python package (#4458)
[33m0ca4f7eb30[m Update Git submodule cgmanifests. (#4461)
[33mf24d8e4587[m fix build break from PR#2850 api change (#4451)
[33mcb5c4292b8[m GPT-2 Attention Fusion without input mask (#4456)
[33m5222b2c6c0[m Remove code which is not thread-safe. (#4454)
[33m05757b4c3c[m Transformer benchmark: add option to use raw attention mask (#4446)
[33mb156ae4448[m Support training_mode flag in eval (#4324)
[33m71aec2adcb[m Custom op export test template (#4383)
[33m063156d98d[m IOBinding docs (#4432)
[33m6d6b6b54a5[m Support binding a graph output to a specific device via the Python binding (#4439)
[33maa06d308a6[m Build new AVX file with /ARCH:AVX (#4442)
[33me62686c36e[m Remove use of RTTI in CUDA provider (#4444)
[33mfdb4a3a2e8[m Add cppwinrt and cswinrt tests in windowsai nuget pipeline (#4381)
[33m612f52c975[m add bias for DynamicQuantizeMatmul (#4440)
[33m1f1384f8a9[m Update dependency introduced by fuzzing change. (#4438)
[33meabf6dc9ee[m Add Fusion for GPT Attention with both past state and attention mask (#4437)
[33m7baf374939[m  Change the input to NNAPI EP ModelBuilder from ModelProto to GraphViewer (#4389)
[33m632b2896f3[m Onnxruntime fuzzing (#4341)
[33mec35a1b514[m Remove unused initializer in graph after embed fusion (#4436)
[33m3ef449816c[m MLAS: support prepacking APIs for quantized GEMM (#4433)
[33mdd73e8c016[m add function initialization back to graph resolve (#4434)
[33m0fdb1e9f60[m Liqun/roberta (#4408)
[33m3588484336[m use system libnsync (#4377)
[33ma44eb7dd08[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m77cf51b13c[m Fix symbolic_shape_infer for Resize with roi (#4426)
[33m0d4a65eede[m Fix Vitis-AI EP for memory info into IAllocator move (#4404)
[33m8bcdefc9c1[m Optimize GatherND (#4097)
[33mbd11ab6816[m Optimize LayernormGrad (#4156)
[33m33e06be4ac[m optimize transpose CUDA kernel (#4233)
[33mdba22b17b4[m Update BiasGeluGradDxKernel and tests. (#4400)
[33m93d4964727[m Use single OpKernel for u8u8 and u8s8 types (#4414)
[33m4df8a1e240[m Use the file size while reading onnx models. Ensure models are loaded using APIs in model.h for consistency. (#4399)
[33md22f6fddf7[m Add ability to specify just the device when using IOBinding for an output (#4386)
[33m28e4c0edf5[m Keep loss_scale and Whole Loss Subgraph in FP32 during Mixed Precision Training (#4268)
[33m7a05b3ca87[m Increase python packaging pipeline timeout (#4412)
[33m67a7d93b49[m Fuse MatMulInteger and scale followed (#4350)
[33m10c25416bb[m Remove use of RTTI in CUDA provider (#4410)
[33meabc1616e6[m Rename variable in InferenceSession class so as to not clash with an existing var (#4391)
[33mf6bf66c8cf[m Adjustments to MPI and NCCL library discovery on build (#4407)
[33mff64371367[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mf4e0070c2e[m Bump mysql-connector-java from 8.0.15 to 8.0.16 in /tools/perf_util (#4401)
[33m84a34a38d0[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m0bef9d5114[m Fix the broken Android NNAPI CI (#4403)
[33mef602835b0[m update getfunctionbody (#4396)
[33m3bb6a865cc[m Revert "remove openmp and scipy from build pipelines (#4305)"
[33m5cb5081c8f[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m4c0236d6c1[m Update MCR container instructions with dynamic device selection info (#4371)
[33m5c23b17196[m MLAS: more prepacking kernel changes (#4397)
[33md4341ea2de[m Merged PR 4870266: Refactor fused graph kernel so dmlxp and ort share the same code
[33m2d54c89d77[m Update filename and Cleanup unused cudnn kernels (#4387)
[33m010445fc52[m handle Floor and SplitToSequence (#4384)
[33m6ee6fdbbba[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m473cd5545f[m Simple support of MatMul U8S8 on ARM to pass tests (#4392)
[33mbffbae3398[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m7ec9a73202[m deprecate frontend layernorm postpass (#4372)
[33m7fea332f93[m Support builds without RTTI (#4333)
[33m5dcb9b4858[m Liqun/backprop deterministic graph (#4315)
[33m94c98aa0a7[m qlinaradd for arm/sse2/avx2 using intrinsic, enable binary broadcasting parallel (#4216)
[33m49268c42da[m Change the way java home is set on Mac OS for CI and Java publishing pipeline (#4385)
[33m1b26dfc8ac[m Merged PR 4868876: Merge Onnxruntime github with dmldev
[33m531126916b[m Merge remote-tracking branch 'upstream/master' into HEAD
[33m4051667d01[m Merged PR 4868833: FIx merge conflict
[33mf422bcb372[m Merged PR 4868758: Fix merge conflict in merge of Onnxruntime to DmlDev
[33m018269f29f[m Merged PR 4868304: Manual merge of Onnxruntime github into DmlDev
[33m6365760906[m BiasDropoutFusion  (#4167)
[33m0404763f23[m Update function body initialization for ONNX functions (#4332)
[33m7cb2c3f025[m Merged PR 4852260: DML EP remove redundant rank checks for higher dimension support
[33m37b624b688[m Match More EmbedLayerNormalization Patterns for Bert Model Graph Fusion (#4354)
[33m755675541a[m NCHWc + Sigmoid optimization (#4360)
[33m4380b8ba68[m adjust bs size (#4375)
[33m89c6da99b5[m fix output shape calc for matmul (#4362)
[33ma4127fc185[m Add stale bot (#4323)
[33m55f25a4bbf[m Update Attention op to support attention mask for GPT-2 (#4330)
[33m2601f8e1b4[m Support to build CUDA EP for NV Ampere GPU (#4345)
[33m465140b384[m Misc fixes to Conv and ConvTranspose CUDA kernels (#4281)
[33m35a048ef9b[m Ignore one failed test in DML (#4366)
[33m5f4e63ede6[m Add nhwc support for NNAPI EP, add concat op, handle concurrent calls to NNAPI model (#4356)
[33m88402f5293[m Make DML operator registration constexpr (#4219)
[33mee48b89350[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m9d1c86f7a5[m Merge branch 'DmlDev' of https://microsoft.visualstudio.com/DefaultCollection/WindowsAI/_git/onnxruntime into DmlDev
[33m012aaa6491[m Minor optimization in CUDA Reduction ops (#4353)
[33m274e6b4153[m Cleanup SessionState. Move allocator lookup to SessionState. (#4194)
[33m386046426b[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m8b0968b622[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m4a1ecd9879[m [OpenVINO] Upgrade OpenVINO docker base to Ubuntu 18.04 (#4346)
[33md1777910a8[m fix onnx server build failure. (#4347)
[33mc3c4ce5ceb[m refactor prototypes into headers (#4337)
[33mfc5e65a22d[m Add quantization support for GPT2 past state and use model to generate outputs in OpTester (#4340)
[33mceedf126a2[m [nGraph] Deprecation notice for nGraph EP (#4344)
[33m381f4c442a[m LayerNormFusion - Cast support (#4320)
[33m9e0f5fc7af[m The initial PR for NNAPI EP (#4287)
[33m37cbe8551d[m Adding export registration and tests for custom ops (#4248)
[33m990b43ddf2[m Add modern C++ standards to the C++ API (#4217)
[33m72fb5183d4[m Fix Windows ARM64 break (#4343)
[33ma37e2e33b4[m Add compatibility with Protobuf 3.12 (#4291)
[33m5db67ec000[m Fix python package issue and upgrade the linux image to 2010 (#4342)
[33mbfc888613f[m Migraphx improvements (#4328)
[33m0b450dcd9f[m Enable BiasGelu fusion for training (#4146)
[33mc0a3320522[m Merged PR 4851009: move clamp_cast under OperatorHelper namespace
[33mb544f5c83c[m Sample updates (#4303)
[33m645a988c04[m Support binding input only for IOBinding in python api. (#4079)
[33ma08805daf9[m Fix a minor typon in POM file name (#4250)
[33m3fc68cb150[m Remove non-trivially-destructible thread-local from thread pool state, blocking ARM64 builds (#4336)
[33ma3b466cdf1[m fix python ep default ordering.  (#4335)
[33m151ef1c8a5[m Add C++ wrapper for GetAvailableProviders() C API (#4313)
[33ma6d10376df[m Fix build error when USE_NCCL is defined. (#4334)
[33m0d9db2b28d[m add informative error message regarding symbolic dimensions (#4297)
[33m64264c3846[m Allow --cmake_generator to work on macOS (#4278)
[33m15c07c75f8[m [OpenVINO-EP] Upgrade version info to 2020.3 in docs (#4304)
[33ma241eb0bbe[m Renaming --partition_optimizer to --deepspeed_zero_stage (#4312)
[33m7e71ff2a1f[m Match Reshape Subgraph Pattern For GPT2 (#4279)
[33m5c6a27408a[m Remove signed/unsigned compiler warnings, add additional pipeline test case (#4314)
[33m44f06ec480[m Fix memory usage when loading a model + some other minor fixes to avoid unnecessary heap allocations. (#4318)
[33m5dd3ebb3b1[m Tune setting for when to use MlasComputeSoftmax due to changes in #3906. (#4170)
[33mf26c149d7d[m Set NonZero Output Shape for Gradient Building. (#4246)
[33m20e205aa0a[m [OpenVINO-EP] Changed the default scheduler for VAD-M (#4295)
[33m3374733783[m Refactor ReduceMean/Sum Gradient without Shape Dependency. (#4261)
[33mdeea945f80[m Remove openmp and scipy from build pipelines (#4305)
[33m867ba846f7[m Implement MinMax with SIMD (#4285)
[33m5ebdf76aa3[m Merged PR 4822584: change for dmlxp
[33m4e39fda06a[m Fix version of torch and torchvision in install_deps.sh. (#4316)
[33m15cb4b3023[m Fix session load state & run extra_postpasses only once (#4255)
[33m028b75e19f[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33md3c5cb6349[m Use providers_available array from constants.h to avoid code duplication (#4300)
[33m737c22a911[m Refactor Python packaging builds (#4283)
[33m3d64309599[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m9e3b5c62fb[m Use OpenMP-like synchronization patterns in Eigen thread pool (#4236)
[33m57fabfba7a[m Added GetAvailableProviders() to C API (#4247)
[33m175983c082[m Move memory info into IAllocator (#2850)
[33m064afa0f93[m define dim_idx before use it (#4290)
[33m2204d39a06[m[33m ([m[1;31morigin/rel_1.3.1[m[33m)[m Add build option to disable traditional ML ops from the binary. (#4272)
[33m3c633384c2[m Fix TensorRT memory leaks (#4227)
[33ma541d28fb4[m Lazily get allocator when allocating an MLValue (#4276)
[33ma490beedf1[m update tvm submodule (#4284)
[33me08181f74d[m Update Bert Notebooks for ORT 1.3.0 (#4274)
[33m466511c1c3[m Update gpt2 benchmark with position_ids and fp16 (#4275)
[33mefb99c24a7[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m0349479b19[m Fix component governance and codesign validation errors (#4277)
[33md5610e666b[m Support CUDA kernel for Einsum op (#4095)
[33m478b923e19[m Expose ACL/ARMNN providers to Python (#4260)
[33me505faa022[m Fix two compiler warnings (#4263)
[33m5d773ee57b[m MLAS: add sgemv path for aarch64 builds (#4254)
[33m5da849b414[m Fix detection of protobuf with onnxruntime_PREFER_SYSTEM_LIB on Linux (#4230)
[33m43deec2174[m Temporarily remove dnnl from Linux CI build to unblock the whole team (#4266)
[33m1e1ba6cc4f[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m1de79d3158[m Merged PR 4781392: Add 64-bit tensor types to DML EP
[33mb41fcf1570[m Bugfix for shape inference and GetShape. (#4243)
[33m12367a6b11[m [C#] enable string-typed FixedBufferOnnxValue in input (#4178)
[33m189fb60ef9[m Fix a bug and add code to profile memory (#4241)
[33m63bf587623[m Use azcopy to download test data (#4221)
[33m61fa5476d5[m Update PyTorch Bert notebooks (#4239)
[33mf9afd990dc[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m7ccce4379e[m Improve fast_divmod (#4224)
[33m825392c25b[m Fix ORT server CI build (#4165)
[33m5d28efd434[m opset12 code cleanup (#4242)
[33me0334f177c[m Opset12 upgrade for existing models used by perf/e2e pipelines (#4238)
[33m4486c66ed4[m enable conv transpose 3D (#4218)
[33mb08771f00e[m Add ONNX Training Post-Passes to Front-End - Cont (#4041)
[33m0b5bbb16b8[m Benchmark With IO Binding (#4206)
[33mb4b1c6440a[m Enable ORT with CUDA 11 toolkit (#4168)
[33m88a9cceb41[m fix relative links in CONTRIBUTING.md (#4212)
[33md0d31efd86[m fix transformer doc format (#4003)
[33mecc901717e[m Use subset to release gradient tensors earlier (#4222)
[33m886befaba1[m Add BatchNorm and Concat to ACL EP (#4190)
[33m877862184e[m Fix subgraph based reshape fusion (#4185)
[33mbf3c32166d[m fix optional input/outputs (#4229)
[33m5708c4feaf[m Handle corner case in Resize op (#4183)
[33m7a96cfc8f5[m operator code cleanup (#4228)
[33me4d94ee0e3[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mc55f6d76be[m [Vitis-AI EP] Fix to enable multi-output subgraphs inside Vitis-AI EP + edit docs (#4171)
[33me8d4a3d01b[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mde9da123cf[m Enable static memory planning for pipeline. (#4204)
[33mb377266eb3[m Fix Mac build linker warnings (#4155)
[33m91a41298cc[m Fix ORT build when onnxruntime_PYBIND_EXPORT_OPSCHEMA is enabled (#3954)
[33m155e22d1ab[m MLAS: fuse float output into quantized GEMM (#4215)
[33m2e3607c7cd[m Remove hardcoded desktop lib (#4193)
[33m01edd61372[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33mf74861841e[m Fix dangling pointer to local string variable in onnxruntime_pybind_state.cc.
[33m6b4f652017[m Clean up status checks in gradient_graph_builder_test.cc.
[33m7096e6f5ef[m Reduce severity of GraphAugmenter logging statement.
[33m6f4320fb85[m Fix the python package name issue (#4207)
[33m87d68d8531[m matmul integer fusion (#4195)
[33m2605faef88[m Add past state support in Attention Op for GPT-2 (#4107)
[33me6ccb1ac28[m GatherNDGrad for CPU (#4123)
[33m56a2dfd7d5[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m65a682354b[m enable pipeline to run with mixed precision (#4113)
[33m8f8d899bf2[m Enable code sign in c api pipeline and python pipeline
[33m73bc6be5d1[m build: split nodejs binding build and test to avoid timeout issue (#4188)
[33m117b2e7743[m Fix GPU memory leak on TensorRT (#4172)
[33me323411e31[m Merged PR 4790197: Remove hardcoded desktop lib
[33meae841464c[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33maf0750ba1b[m Java GPu artifact naming (#4179)
[33me8ed14bcb3[m disable MEMLEAK CHECKER for openvino
[33mc296884fc3[m bump up ORT version to 1.3.1 (#4181)
[33mc0bdbc0b39[m Enable telemetry for the C API and python pipeline (#4174)
[33m35d9f396c4[m MLAS: refactor quantized GEMM loops (#4182)
[33m9d65ce53bc[m move back to toolset 14.16 to possibly work around nvcc bug (#4180)
[33ma7366d82af[m Disable nuphar large model test (#4173)
[33ma47158e3ee[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33m9eba9fba7c[m Fix for BiasGelu fusion optimizer (#4160)
[33m2b3ce1b090[m add script to support update nodejs binding version (#4164)
[33m559d2c0c9c[m Merge remote-tracking branch 'upstream/master' into DmlDev
[33ma9862b00f3[m Merged PR 4779170: Merge ORT master
[33m4377ff4a1a[m Enable .NET Core 2.0 and .NET Framework 4.6.1 in Microsoft.AI.MachineLearning NuGet package (#4125)
[33m28d12dc4f0[m Try to avoid std::move in return whilst keeping CentOS build happy. (#4163)
[33m541eafb41a[m Fixed the link to model test documenation (#4011)
[33m2ab3a19728[m Enlarge the read buffer size in C#/Java test code (#4150)
[33m045ce7d13b[m Merge remote-tracking branch 'upstream/master' into user/ticastro/update-DmlDev
[33m8eb6a539bd[m Hardcode WinML tests umbrella lib (#4161)
[33m7f5339505e[m Discover trainable parameters using reverse DFS from loss node (#4116)
[33m842be1535d[m [Node.js binding] add linux and mac package (#4157)
[33m653417ae4b[m Fix scaler->scalar typo. (#4142)
[33m6bbd18efd0[m Hardcode WinML umbrella lib to windowsapp.lib (#4133)
[33mee35320974[m The fixings for python scripts in ONNXRuntime (#4135)
[33m3390431d80[m Update MCR image table (#4137)
[33m5a5f44eed7[m Add softmax to the mnist example (#4149)
[33m4e1dac67cd[m Address memory leak and improve memory handling (#4124)
[33mb8db8076cb[m Fix MKLML Tests Run (#4144)
[33m7c8e1580a1[m Add check of graph output in Bert Fusions (#4126)
[33mffed43e9b8[m handle loss and name marching wrappers (#4066)
[33m2aab20b4ea[m [Node.js binding] upgrade node-addon-api to 3.0 (#4148)
[33mea368f69db[m Add Swift/macOS sample, a port of the Windows MNist sample
[33m2e58097f8f[m fix build: pipeline Node.js version to 12.16.3 (#4145)
[33m1e5307d458[m Bug fix for parameter names of models not using wrapper (#4061)
[33m9790e19424[m Handle mem pattern allocation failure better. Make BFCArena behavior more consistent (#4062)
[33m81101c9efd[m Fix DropoutGrad op (#4052)
[33m6199ef1375[m Change group id to com.microsoft.onnxruntime per requirements.
[33m16cef90e29[m General enhancements/cleanups to test exes (#4109)
[33m197da135eb[m Implement quantized Attention on cpu (#4111)
[33m62b44527e5[m Add ArmNN Execution Provider (#3714)
[33m62af8da3f6[m Use OrtMutex and OrtCondVar everywhere instead of std::mutex/std::condition_variable for consistency.
[33m905c535626[m still need to make the test stable. Lower the acc number a bit to make the test pass for now (#4117)
[33md63b90538e[m Symbolic shape inference exit on models without onnx opset used (#4090)
[33m6f8a4f4cad[m Fix Nuphar test failure
[33m32d8a76f2f[m Fix Nuphar build in gcc 7 (Ubuntu 18.04)
[33mf18a99b245[m Exclude non-trainable torch buffers from trainable weights (#4099)
[33me5cec7237d[m Clarify telemetry collection (#4102)
[33mbaa0697982[m [OpenVINO-EP] Add missing dependency libs in Dockerfile (#4064)
[33m647a886587[m [Nodejs binding] create a new pipeline to generate signed binaries (#4104)
[33m3f7b97a63d[m MLAS: more code cleanup (#4101)
[33m08e5f89b37[m Fix the nuget gpu pipeline (#4106)
[33mafca0d15ee[m Create Java publishing pipeline (#3944)
[33m51d78bc5e6[m Fix DML EP doc link to C API (#4105)
[33m6c1b2f33b7[m Fix crash reported in #4070. (#4091)
[33m8813d205cc[m Update GPT2 Model Benchmark Script to Support IO Binding (#4088)
[33mba74914c5a[m Remove evaluation output from training e2e test baseline data. (#4092)
[33m3eaec57c38[m Fix the daily pipeline failures (#4084)
[33mf54518bae9[m Actually switch the spdlog submodule to the master branch. (#4100)
[33m72d508b7a0[m New perf metric - e2e throughput (#4085)
[33m70d91a8550[m re-enable graph optimizations during build phase (#4044)
[33mff16ca54e1[m Fix the flake8 warning in generate_nuspec_for_native_nuget.py (#4089)
[33ma715d55bcc[m Training Python package fixes (#4063)
[33m9d748afff1[m Set spdlog submodule branch to "master" explicitly. (#4087)
[33m1d441f89ac[m Re-enable PEP8 check in Win CI build  (#4075)
[33mb85805ed01[m Handle edge case with implicit input and multiple levels of subgraphs (#4031)
[33mc331d8cffc[m WinML custom operator header is missing from nuget package. (#4083)
[33m6c7eaff676[m fixed typo in readme (#4076)
[33m6404aba5ae[m Orttraining rc1 master merge (#4080)
[33me951b29a0b[m Fix a macro and memory regression (#4068)
[33m38d76cc904[m Clean up training E2E test (#4078)
[33mdd43623da2[m Remove ONNX from requirements.txt (#4073)
[33m348ed698ec[m Add more symbolic compute support in symbolic shape inference (#4057)
[33m2a96be83f6[m skottmckay/bugfix/SubgraphInput (#4004)
[33mc55634d2e6[m Fix initial value of loop variable in RNN op (#4055)
[33m6d03470587[m Add e2e measurement for training (#4049)
[33m847bece23d[m Merged PR 4735426: Merge latest github master enabling disabled tests
[33m5bd82e913d[m Merge remote-tracking branch 'upstream/master' into user/jamather/merge-latest-github
[33m26be762b35[m Make CPU QuantizeLinear support optional zero point (#4065)
[33m60fa4b1f90[m Update benchmark of gpt2 model with past state (#4043)
[33med0a8e5b5c[m Enable disabled tests and add fixed model (#4059)
[33m279f9aa865[m Update WinRT_API.md to reflect 1.3 release (#4074)
[33mc94d9685b6[m Fix a problem in StacktraceTests::BasicTests (#4069)
[33ma859dc422c[m Delete google::protobuf::io::FileInputStream class from our source code (#4067)
[33m1e82ecfd5c[m Fix link in readme (#4058)
[33m7f750b65ce[m support model > 2GB in transformer optimizer (#4038)
[33m9f7d245446[m Add noexcept to various OrtCallback utility class methods to fix warnings. (#4056)
[33m23c313cb73[m fix crash in dequantizelinear/quantizelinear for optional zero point (#4047)
[33m6665d5e2bc[m Liqun/a transformer example (#3845)
[33ma983509ed3[m Pad: Add support for all datatypes in opset-11 spec (#4021)
[33m930c6a59da[m Allow optional cast in embed layer norm be optional. (#4040)
[33mb3ec8035ee[m [Node.js binding] add build flag for node.js binding (#3948)
[33mee6371d0a8[m Clean up CUDAExecutionProvider's associated PerThreadContexts on destruction (#4017)
[33m60aada3862[m Merged PR 4716166: Merge latest ORT Github master into dml dev
[33m633008b5ef[m Add pipeline online partition logic for pipeline (#3996)
[33mc2c45c6715[m Merge https://github.com/microsoft/onnxruntime into user/rylai/fix_github_merge
[33m0d8abc1a99[m MLAS: qgemm refactoring (#4030)
[33mabcd1576c9[m Add Linux bash and Windows batch scripts for running transformers benchmarks (#3997)
[33m212efb6cde[m Match New Pattern for Reshape Fusion (#3931)
[33m7759136610[m Add amd migraphx execution provider to onnx runtime (#2929)
[33m9d0534c0eb[m Optimize OneHot CUDA Kernel (#4012)
[33m0a6d9dd301[m Remove Openmp from the GPU docker files
[33m30efe65e95[m Add use_openmp back to the docker files
[33mbd8993cb15[m remove --use_openmp in build.sh
[33mfaf65e960f[m Refactor delayloading (#4019)
[33m24eda3df33[m Create Utils for Adding Range and Marker (#4013)
[33maafe988a11[m Temporarily disable windows static analysis CI job
[33m7c83118364[m Enlarge protobuf read buffer size
[33m0868a100d5[m Merge https://github.com/microsoft/onnxruntime into user/rylai/fix_github_merge
[33meb3aaa70d6[m Fix compiler warning for openvino  (#4010)
[33m59af3ea278[m Add missing D3D12 resource barriers and fences to Winml (#3941)
[33mce4d05862a[m add bm_fish_720 to collateral for scenario 22 test (#3998)
[33m357bffe47c[m Fix deprecated CentOS link for Linux CI pipeline (#4000)
[33m0a5395bb78[m Remove 'model_.' prefix from onnx model initializers in training (#3881)
[33m08763e80e0[m Fix permission denied while creating directory in azure pipelines (#4001)
[33mdbd5aab6d2[m Update OnnxRuntime.java for OS X environment. (#3985)
[33m34cdd9ab0e[m Merged PR 4687622: ORT DML EP Pads-11 does not support float16 (falls back to CPU)
[33m989fe2498f[m[33m ([m[1;31morigin/stevenlix/test[m[33m)[m Change training perf test build to use "docker" instead of "sudo docker" (#3995)
[33m354e571277[m Miscounted the number of characters in package version of DirectML nuget (#3993)
[33m4e84df25e7[m Merged PR 4700287: Fix 5d concat operator helper
[33m2adb0f8d1d[m Fix 5d concat operator helper
[33m475e7e43e6[m Older flake8 versions report false positives and don't handle the same things in the config file. (#3983)
[33mfb4efafc8e[m GPT-2 training perf scripts (#3974)
[33m36bcb28238[m Add NNAPI in the exclude list (#3921)
[33m64b5f7edf6[m Initial release of Vitis-AI Execution Provider (#3771)
[33mc42867c016[m Update data_frame_tool to latest (#3919)
[33m672c42b396[m Fix std::_Exit workaround for Dnnl crash at unload (#3978)
[33mb8a255e1b5[m Doc Updates for Build  (#3976)
[33m1168f4e85a[m Support session EndProfiling() in the CSharp API  (#3934)
[33mb253f0b0f6[m Do not fuse skiplayernorm if any output of add in graph output (#3981)
[33ma75a83b41a[m Minor android build fix (#3980)
[33m2fa2019daf[m Run docker commands with sudo (#3979)
[33m29c39f867c[m enable tensor core for rnn (#3937)
[33mc6a94f95cf[m Update Android instructions (#3971)
[33m024b92a970[m Use path relative to script location to refer to symbolic_opset10.py from install_deps.sh. (#3975)
[33m9d2d1eb6f6[m [java] Adds a CUDA test (#3956)
[33m1a183784a8[m Fix C# layer in the way it handles sequences (#3965)
[33me259a13f8e[m Initial training Python packaging pipeline (#3767)
[33me55f24364a[m Disable LTO on Windows training CPU build (#3960)
[33m44731e88bb[m Add comments for zero valued normalization factor in SoftmaxCrossEntropyLossGrad CUDA kernel. (#3972)
[33mfd8ea4e466[m Improve handling of symbolic dimensions in the onnxruntime_test.py script. (#3959)
[33m523d70f667[m Improve Transformer Benchmark for FP16 (#3970)
[33m0d11649bb3[m Address comments from #3823 and polish code (#3964)
[33m4ff73d00b0[m Fix python pkg permission issue (#3957)
[33m07e9a4c164[m Update benchmark to reflect those used in our latest results (#3967)
[33m56700bec83[m Add example of python code to readme of transformers tools (#3966)
[33m769c11f217[m Update doc for transformers tools (#3963)
[33ma296b16719[m Prevent divide by zero in CUDA implementation of SoftmaxCrossEntropyLossGrad. (#3962)
[33m132ce3a561[m Fixes for quantizing a BERT from HuggingFace (#3939)
[33m33208c9f6b[m Modify Pipeline Facilities to Fix PipeDream Deadlock (#3823)
[33m999554cc53[m CGManifest - add training entries and generate entries for submodules. (#3933)
[33mbc441b7e5c[m Add cpu/mem usage for perf metrics (#3947)
[33mbe003dbab7[m Fix ACL build break (#3952)
[33m47ae9691fd[m Fix ordering of APIs. (#3951)
[33m9ef376880b[m Add test for If node with conditional branches only containing Constant nodes (#3949)
[33m38467f8c9a[m DirectML Nuget package has different time stamp than Native and Managed Nuget (#3950)
[33me6da5946d1[m Update DML Nuget version and DML EP Doc (#3945)
[33m782c6c24b2[m Rename bert to transformers (#3946)
[33m3c4f3d01cd[m Implement QLinearLeakyRelu (#3648)
[33m5e0928a777[m Enable running PEP8 on python scripts using flake8 (#3928)
[33m39814319b2[m [Node.js binding] fix linux build (#3927)
[33m50f798dad6[m support non-zero zero point for matmulinteger u8s8 (#3883)
[33mf57515aae4[m Update DML nuget to 2.1.0
[33me9a053ff7f[m Fix version number in doc
[33m756767ea78[m Update DML EP Doc for ORT 1.3
[33m9c989c8dd6[m Update build doc for cross-compiling (#3672)
[33mcab21223b3[m Updated TPN for OpenMPI and cleanup (#3932)
[33mcba8bdc790[m Make some compile change for Android NNAPI provider using DNNLibrary (#3935)
[33m84c108a85e[m link to folder instead of READMEs inside folder (#3938)
[33m48f69cfbb8[m Fix DirectML nuget creation in Nuget pipeline (#3929)
[33mf380460a9e[m Update the build steps to support ORT on Jetson (#3869)
[33md80e15fb11[m Fix DmlCopyTensor test (#3923) (#3925)
[33m93eb9bcfde[m Add yaml/perf scripts for new perf test pipeline (#3909)
[33me86214e5c0[m Fix the tensorflow performance test (#3847)
[33m7c774e967a[m support quantization of optimized model with ir<4 (#3853)
[33m25257a661d[m Added onnxruntime aarch64 wheel to pypi publishing pipeline (#3903)
[33m1c1685ad2b[m Fix error handling in LearningModelSession.cpp (#3920)
[33m385073e1cd[m Fix DmlCopyTensor test (#3923)
[33meab61e87ce[m Fix quantization tool bugs when model nodes have no name. (#3854)
[33m9b5daa2039[m patch torch onnx opset 10 (#3910)
[33m7b858d60b0[m Various changes for automated downlevel test pipeline (#3901)
[33m3065219cc1[m Changes related to the release binaries requiring Visual C++ 2019 runtime (#3871)
[33mbccbdd03f1[m User/xianz/enable batch tests (#3914)
[33m18dc0ec39f[m Rework jar by creating os-arch folders (#3849)
[33mc00945ae81[m Build ORT by default for Mac OS X versions 10.12+  (#3626)
[33m99415f09fe[m Fix bug where linear_output_ is not cleared when linear_before_reset is true and no bias input is provided. Requires a batch size of 3 or more to trigger if initial_h is not provided. (#3893)
[33m475ea382f9[m Fix ACL EP convolution-activation fusion optimization (#3896)
[33mf170f31e1d[m Extend workaround with input name matching in DML fused graph kernel (#3918)
[33m0f82b42fed[m Ensure pt model is set to cpu in ort_trainer (#3867)
[33m29496170d7[m Add Benchmark Script for Bert Models (#3829)
[33m2fed37c8eb[m Fix bug in handling of an initializer that provides a graph output. (#3912)
[33m6f729b100f[m use LOAD_WITH_ALTERED_SEARCH_PATH for LoadLibraryExA (#3908)
[33m70abb120b3[m Remove ORTModel from frontend API (#3825)
[33mb12d35b679[m MLAS: tune softmax kernels for partial vectors (#3906)
[33mc46a9e8d65[m Add numerical stability to SoftmaxGrad test inputs. (#3857)
[33maf7d453435[m Merge DML Execution Provider updates (#3885)
[33m0cdc1459c6[m Add a few more things to the helper python scripts. (#3842)
[33m28f693a8a1[m Update TensorRT dynamic shape profile when input shape changed during runtime (#3904)
[33m6d2d927809[m add test to api tests to ensure correct hresult is returned for corrupt model file (#3796)
[33mc7da194313[m remove winrt (#3899)
[33mce3678ffaf[m Added aarch64 build pipeline (#3841)
[33md7e39569da[m Use MlasComputeSoftmax in traditional ML ops (#3892)
[33m06985a9922[m Stop proceeding with constant folding if a CPU kernel is not found found (#3836)
[33m7fd2c8f9e8[m Add signed GPU nuget package to publish ort-nightly nuget feed (#3834)
[33m5e1244eb4d[m Update ONNX submodule to ONNX 1.7 release branch. (#3888)
[33m96030fdcbc[m dashboard integration - output training perf metrics as json (#3809)
[33m8291065e20[m Re-enable Dropout(12) ONNX inferencing tests. (#3833)
[33meb33d5eda9[m Do not register Dropout(12) as training ONLY kernel. (#3859)
[33m408f62dd57[m Load provider shared libraries relative to core runtime executable (#3884)
[33m3c24841569[m Fold Shape Node During Constant Folding (#3748)
[33m890c945d4c[m winml_is_inbox is not accessible in function scope, move it out. (#3886)
[33m672e40bac2[m fix dnnl ep shared lib python packaging. (#3875)
[33m93e39b81a7[m fix build break on Linux. (#3874)
[33mcf6a1c1715[m Fix Windows Inbox build failing on 1) building raw api tests and 2) referencing _winml namespace in onnxruntime.dll (#3872)
[33m22a711457f[m Fix C# log APIs. Also fixes github issue #3409. (#3840)
[33ma9b43b05cb[m Support more types in MurmurhashOp (#3827)
[33m19e3dc47d7[m LSTM performance tweak + cleanup (#3868)
[33mfe5a20f2d1[m Fix initial value of graph optimization (#3856)
[33meb7486d632[m WinML Adapter DMLEP tests (#3752)
[33me981496cf7[m add build inbox flag (#3855)
[33m424a00bf04[m Fix enabling gradient as output for easy mode. (#3866)
[33m4ea10c9202[m bump up ORT version and extend time limit for windows cpu packaging pipelines (#3852)
[33mcb554fbc2d[m MLAS: Add MlasComputeSoftmax/MlasComputeExp (#3846)
[33m914aaaa1c8[m Fuse Attention For One Input bert-base-dynamic Model (#3850)
[33m43b87de7d1[m Support wide char paths in CreateModel (#3835)
[33m3bafc096bb[m Fast exit workaround for dnnl test. (#3863)
[33m0aeb383273[m Support Pipeline in Training Runner (#3770)
[33mc222ed6327[m Optimize Where CUDA kernel for UniLMV2. (#3799)
[33m65bfece19d[m [Node.js API] optimize prebuild (#3844)
[33m9cca219b1a[m Add FAQ page (#3324)
[33m0e59668c1b[m add support for symbolic broadcast for Add/Sub/Mul (#3743)
[33m687edd702c[m Add RelWithDebInfo target to the C# projects so that it correctly finds the native build. (#3839)
[33md38b79c6e5[m [Java] Adding missing methods on Session, SessionOptions and RunOptions (v2) (#3832)
[33md5ec353e58[m Ryanunderhill/mkldnn dll (#3314)
[33m9b02b3df6f[m Update ONNX submodule to ONNX 1.7 release candidate 3. (#3838)
[33mb45ce92542[m Fix 3828 (#3837)
[33mf0c9fbc051[m MaxpoolWithMask (#3831)
[33medaf8a542c[m Initial PR for RKNPU execution provider (#3609)
[33m584facf830[m Fix build error when DEBUG_NODE_INPUTS_OUTPUTS is on (#3826)
[33m6e341c002f[m Add Epsilon Attribute to Skip and Embed Layer Normalization (#3768)
[33me30d2e38b9[m Add guidelines for writing a good PR. (#3830)
[33mef4d73e887[m Update ONNX submodule to ONNX 1.7 release candidate 2. (#3818)
[33m5db30a470e[m [Java] Tidying up the sample MNIST code (#3824)
[33mf7ff5a7aa1[m Fix state_dict and save_as_onnx for training (#3774)
[33m5dfc91db51[m Node.js binding for ONNX Runtime (#3613)
[33mcffa1b7bf2[m Fix (#3812)
[33mbd78364411[m Parallel all the activations ops (#3722)
[33mc11fbf68e4[m Publish gpu package to nuget feed (#3816)
[33mb386b41703[m Fix bug in GRU when linear_before_reset is true and no bias input is provided (#3797)
[33ma24c71af40[m Update Dropout(12) forward kernel with training_mode input. (#3805)
[33m111469728f[m Make Java build and run tests on Windows the box (#3811)
[33m6f95cdfa68[m Use new cost based threadpool abstractions in CPU gradient operators. (#3807)
[33m156368b67f[m Quantize attention with Cuda (#3693)
[33m49f0610447[m Add options --disable_layer_norm,  --disable_gelu and --enable_gelu_approximation (#3750)
[33m2f8a2364c3[m Fix loss function builder (#3801)
[33m785b45124d[m Add CPU kernel for Einsum op (#3575)
[33mc8269e4b89[m move backend test filters into data file (#3798)
[33m2684d47fc5[m Disable data downloading in linux-nocontribops-ci-pipeline (#3803)
[33m37b60251ca[m test packaging (#3756)
[33mee8900e21a[m Update centos-ci-pipeline.yml (#3800)
[33md5b2cd7493[m Add performance best practices to DML EP doc (#2859)
[33m42cf971ca2[m Add a couple of utility scripts to tools/python (#3621)
[33m440f361363[m Remove orttraining-linux-gpu-inference-only-ci-pipeline.yml. (#3788)
[33m43a828f0a2[m Add tests for WinRT Projection Raw ABI consumption (#3718)
[33m3fab8ebfe9[m (MaximKalininMS) Fix Reshape Fusion and Crash in Reshape  (#3777)
[33m15eca74d15[m Make ThreadPool::PartitionWork a bit more user friendly. Update a few places to use PartitionWork. (#3795)
[33m2b8d9ef0fd[m Refactor scatter/gather ops to use the new cost based threadpool abstractions. (#3776)
[33m4f9f6aedea[m CUDA/CPU test for NegativeLogLikelihoodLoss(12) function based loss operator. (#3793)
[33mb1c4d6ff4e[m bump dml version (#3792)
[33m4b8fad214a[m Initial checkin (#3791)
[33m11b819054b[m Fix tree ensemble threading bug (#3778)
[33m2fc3984e70[m Add test that C is unidirectionally broadcast-able before fusing the MatMul with Add. (#3780)
[33me8e95110d3[m add pipeline to distributed context config (#3789)
[33m517bff9675[m Function expansion support and Update ONNX to 1.7 release candidate 1. (#3782)
[33m047975e404[m Address flaky test ReduceApiTest.Sum. (#3716)
[33medd5855fb7[m Remove eigen device from thread pool
[33mdcb1a21552[m fix python package linux gpu failure (#3786)
[33m99ec93ea42[m Apply onnx-tensorrt bug fixes (#3785)
[33me42e0d4787[m Update documentation + Update mlas threading lib to use the new TrySimpleParallelFor. (#3779)
[33m29234458af[m disable cublasHgemm for training (#3769)
[33m98b97be635[m collect the last few iteration latency for throuput calculation (#3766)
[33mad63e2593d[m avoid using LocalFree on FormatMessageA buffer (#3772)
[33mf68a326bd9[m Implement Pow(12) for cpu and cuda (#3727)
[33m027a364922[m Remove usage of openmp in reverse seq impl. (#3754)
[33m62c730a8df[m Revert softmax kernel implementation (#3753)
[33m86eaa71ec6[m sync threads before calling next cub function (#3758)
[33maf3988198c[m Liqun/e2e transformer test (#3540)
[33m177c1357f4[m Use cublasHgemm "back" for fp16 computation with Volta GPU (#3765)
[33m3421ec1110[m Add Threadpool::TrySimpleParallelFor  (#3759)
[33mb9a5ed1fe2[m Add SoftmaxCrossEntropyLoss to mixed-precision-transformer. (#3760)
[33m9f72752397[m Fix 'Install ONNX' CI failure (#3761)
[33m0531acccc5[m Refine GatherND CPU/CUDA Kernels & Add UTs (#3688)
[33m58f53966d3[m Add Distributed Checkpointing support (#3639)
[33m7296e06dd5[m Properly creating arguments to pass to setup.py (#3744)
[33mea0e2d1dde[m fix warning treated as error due to ignoring return status (#3739)
[33me529464a12[m Limit the number of models run on OpenVINO (#3742)
[33m7ff06056bd[m Fix the test coverage pipeline (#3710)
[33m0638565fe0[m Fix evaluation issues (#3538)
[33m939589c265[m Fix flaky test and avoid divide by zero in SoftmaxCrossEntropyLoss-CPU. (#3734)
[33mbad90d7a53[m Fix a perf regression by providing a better estimate for the cost in LSTM's TryParallelFor call.
[33m12d7c2f6e4[m iOS cross build on MacOS (#3699)
[33m29c12c0f07[m Handle dim with value of zero in ConvTranspose (#3728)
[33m9a4d1c7720[m Merge pull request #3708 from microsoft/jeffbloo/MergeDmlDev
[33mf1a948fd62[m Enable telemetry on windows zip packages (#3738)
[33m78fde2c4cb[m add downlevel test artifact to windowsai-nuget build (#3711)
[33mf7cf703d10[m [OpenVINO-EP] Optimize MCR Docker image size (#3732)
[33m1356215bd0[m Fix build issues in the Python Packaging pipelines. (#3725)
[33m1bcfd49918[m Merge pull request #3731 from microsoft/ettao/ort-2-master
[33m6b3b4fe43e[m remove warning message (#3730)
[33m1a11ba8a7e[m Merge remote-tracking branch 'upstream/master' into jeffbloo/MergeDmlDev
[33mf487cc0b28[m Fix Reshape Fusion with graph inputs (#3729)
[33m75c24a5fac[m Revert "Merge from ort_training to master (#3719)" (#3726)
[33mb990ba0059[m Merge from ort_training to master (#3719)
[33m4f887b465a[m Uncomment celu test. (#3717)
[33m7627e6bcc2[m Improve node and node argument name generation (#3649)
[33m407492472f[m Fix build warnings and address PR comment
[33md03c552992[m fix path of cpu_featurizers_kernels.cc and cpu_featurizers_kernels.h
[33m635bc9cd04[m Fix graph transformers to support opset 12 ops (#3715)
[33m0516e7d22e[m Merge branch 'ort_public_ort_training' into ettao/ort-2-master
[33md901640817[m Call optimised version of depthwise ConvLayer (#3664)
[33mc23b484275[m add missing deps in Dockerfile.openvino
[33m1621a1fef1[m Merge remote-tracking branch 'upstream/master' into jeffbloo/MergeDmlDev
[33me51c6c0b3b[m Fix build warning in DmlOperatorResize.cpp and ReadbackHeap.cpp
[33m805ffc01e5[m Temp remove  --enable_wcos --use_winml from CI build (#3707)
[33m735caecfe1[m Copy disabled ONNX backend tests from WindowsAI
[33ma917023f94[m Support for country-specific holidays in the DateTimeTransformer (#3701)
[33m02e8d10f3a[m Fix AdapterSessionTest
[33mbf1caba2b2[m Port MLAS to Power architecture (#3703)
[33mf1c19f8495[m merge master
[33m99a0bdf271[m Upgrade nuget version in dml.cmake
[33m8cc161aec6[m Remove problematic change for dxcore.lib
[33mc49cc0c937[m Increase DML nuget version to 0.0.2
[33me22d97ba56[m Merge pull request #3643 from microsoft/ort_training_for_merge_to_master
[33ma475f2824d[m Create the Nuget WindowsAI Pipeline (#3684)
[33m1c484ce33f[m fix test (#3700)
[33m72b38f0a8b[m Support GPU Event Operators (#3653)
[33m8b5d6fbaf5[m Remove internal work item links. (#3698)
[33m5637cec199[m Merge pull request #3697 from microsoft/ettao/merge-from-master
[33md06763ac1c[m Set gradient as output only for easy mode (#3694)
[33m1b7bf481fc[m Ensure that setup.py works for all cmake generators and working dirs (#3692)
[33me9f1e7e797[m resolve conflicts
[33m4aa033b99e[m Addressing review comments (#3690)
[33m7347c73139[m Revert "resolving conflicts from master (#3691)" (#3696)
[33mf48b9e2ea7[m Add adapter session tests (#3522)
[33mc38a60a450[m resolving conflicts from master (#3691)
[33m63e6c257e4[m Disable GeluApproximation transformer by default (#3644)
[33mad8eb921d3[m Changes on RollingWindow Transformer (#3679)
[33m66343e2fcf[m use map with case insensitive hash and equals functions for learningmodel metadata. add test to verify case insensitive functionality. (#3671)
[33m5c7f616431[m FeaturizersLibrary update and add variadic Input/Output to TimeSeriesImputer (#3674)
[33mb4d4ea2e5f[m GatherND-12 Implementation (#3645)
[33m6d4f2f5bf9[m OpenVINO EP v2.0 (#3585)
[33m2f8a17dcde[m thrustallocator is not needed since cub is used directly for gather now. (#3683)
[33mc929963d74[m type cast for ratio is not necessary for dropout (#3682)
[33mf4a04c04e1[m move cpu/cuda related files to coresponding cpu/cuda folder (#3668)
[33m470f6e34d0[m remove microsoft.ai.machinelearning.dll binpace (#3678)
[33md97cb7338c[m Revert a change in attention
[33m3863bd6f74[m Revert "Try not to modify base name (#3638)"
[33m2ab78c5da1[m Update TensorRT parser (#3650)
[33m5a790a4b42[m Merge remote-tracking branch 'origin/master' into ort_training_for_merge_to_master
[33m939d036660[m Add omp impl for tryparallelfor and modify gelu to use fastgelu impl. (#3667)
[33mdd86e3be10[m Merged PR 4596882: Fix assert in ReadbackFromGpu
[33m6ca44e216a[m Merge pull request #3675 from microsoft/edgchen1/merge_from_ort_training
[33m2659f205cc[m Complex multiplication and conjugate contrib ops  (#3384)
[33m4416d41874[m Merge remote-tracking branch 'origin/ort_training' into edgchen1/merge_from_ort_training
[33mbae1dd7f04[m add test for LearningModel creation from missing model path (#3661)
[33mb4e82913d1[m Merge pull request #3670 from microsoft/edgchen1/merge_from_master
[33m2d2375aa23[m swap float16/float (#3663)
[33mc0e817ff16[m Fix a bug in skiplayernorm fusion pattern 2 (#3660)
[33mdeac467683[m Merge remote-tracking branch 'origin/master' into edgchen1/merge_from_master
[33m3ce31933bb[m Wheel file updates for FeaturizerLibrary data (#3640)
[33mae7da23460[m disable broken test in DML (#3666)
[33m49a1c5e546[m Change CentOS build to use agent pool because builds on hosted agents run out of disk space. (#3662)
[33m336624806e[m Simplify and clean code (#3655)
[33m125f68f305[m fixed mnist bug (#3569)
[33m5777fc18c3[m Removes omp for ThreadPool in TreeEsemble* (#3596)
[33mf1ba9aaf34[m Add pipeline transformer for wait/record node (#3513)
[33m6136fd0789[m GatherElementsGrad Kernels (#3627)
[33md9641f292d[m Try not to modify base name (#3638)
[33mffe19ae49b[m Expand elimination and Expand gradient. (#3610)
[33m37f4f74308[m expose training session so the training app could register custom kernel and transformers (#3642)
[33m02bae6bd06[m[33m ([m[1;31morigin/ort_ta[m[33m)[m Not use OpenMP for android build (#3636)
[33m2dd4f7e96b[m Add check for nullptr in PlannerImpl::FindReusableTensor(). (#3619)
[33m7c0b05eca0[m Merged PR 4593169: Handle empty tensors in DML EP batched tensor copy
[33m0e12d05cd2[m fixes for ort_trainer.py to resume from checkpoint (#3510)
[33m00917917d6[m Downgrade numpy requirement to 1.16.6 (#3635)
[33me4fc83252d[m Refactoring code related to WARP_SIZE. (#3623)
[33m3cf3595579[m Replaced spaces on tabs (#3555)
[33mab2b85649e[m Merged PR 4587771: Merge Github master to DmlDev
[33m26282359bf[m Merged PR 4591959: Fix ORT DML EP's Slice shape operator helper
[33m7837c7efc3[m Add Features to ShortGrainDropper for ONNX export (#3628)
[33mbb9b0ba5b3[m Merge pull request #3607 from microsoft/edgchen1/merge_from_master
[33m70b554cc85[m Add Features to ForecastingPivot Transformer for ONNX Export (#3608)
[33mab70625b29[m Add Lamb shape inference (#3634)
[33m2c74766ad1[m Add new docs around how to bind to the onnxruntime.dll (#3539)
[33m8df5076d96[m Merge remote-tracking branch 'origin/master' into edgchen1/merge_from_master
[33m8d09cefafc[m Merge remote-tracking branch 'origin/ort_training' into edgchen1/merge_from_master
[33mb518cb2a7a[m Clean up OPTIONAL name conflict workarounds in ort_training. (#3622)
[33md3a2ac5c5c[m Eliminate Useless Cast during Transformer. (#3606)
[33md69bc31309[m Refine BERT optimization script options (#3618)
[33mb4508dbdc6[m Improve TopK performance. (#3612)
[33m5492d02c4e[m Remove Windows CUDA 9 build definition and helper scripts. (#3615)
[33md66d5bb86a[m Update Optimizer Domain and Opset (#3602)
[33m47f1758fdc[m Add --skip_onnx_tests to orttraining Windows builds.
[33m297ab43b0c[m Add --enable_onnx_tests to Windows builds to allow set up of test data directory.
[33m2e4b9b1d0e[m Disable CudaKernelTest.SoftmaxCrossEntropyLoss_LargeSizeTensor because it's flaky.
[33m28a0c863b1[m Revert "Convert Gelu to use TryParallelFor (#3599)"
[33md50c3e7a71[m Fix GraphTransformationTests tests.
[33m9636da3951[m Threadpool related changes. (#3564)
[33m3dd3f84116[m [Java] Adding model metadata support (#3573)
[33mc2a01b9431[m Disable erroneous compiler warning in space_depth_ops.cc
[33m1c37d5e6ec[m debug option for dumping tensorrt subgraphs. (#3604)
[33m87fad09c7b[m Fix merge issue.
[33mdaa14b64e3[m Merge remote-tracking branch 'origin/master' into edgchen1/merge_from_master
[33mead00f97f3[m Sync onnx_backend_test_series.py disabled tests (#3603)
[33me233e6ba45[m Refactor - ScatterElements (#3559)
[33m2579a72a88[m Convert Gelu to use TryParallelFor (#3599)
[33m971b98f9a5[m Fix ARM build error
[33m911d125323[m Remove openmp from gpu build
[33m850ab19e62[m Fix Winml test build error
[33m19cdd6f1e1[m Fix chk build error
[33m781e1c36be[m Add front-end MNIST test (#3231)
[33mf180b71f27[m Support ONNX test version parsing from path on Windows in onnx_test_runner. (#3588)
[33m31b6629e99[m Fork WinML IDL Guids (#3591)
[33m381fee47ab[m Added support to build onnxruntime with ACL (#3586)
[33m75426a3091[m Fix build break
[33m5d2874298e[m Merge remote-tracking branch 'upstream/user/jeffbloo/FreeDimOverrideByName' into user/jeffbloo/MergeGithubMasterToDmlDevPlusPending
[33m88732cd092[m upstream/jeffbloo/TrimOnSessionInitializationEnd
[33meceb18869a[m Merge remote-tracking branch 'origin/user/jeffbloo/BatchTensorCopy' into user/jeffbloo/MergeGithubMasterToDmlDevPlusPending
[33macbfa42647[m Merge remote-tracking branch 'origin/DmlDev' into user/jeffbloo/MergeGithubMasterToDmlDevPlusPending
[33m7d523d2580[m[33m ([m[1;31morigin/jeffbloo/TrimOnSessionInitializationEnd[m[33m)[m Merge remote-tracking branch 'upstream/master' into jeffbloo/TrimOnSessionInitializationEnd
[33m414c4174a4[m[33m ([m[1;31morigin/user/jeffbloo/FreeDimOverrideByName[m[33m)[m Merge remote-tracking branch 'upstream/master' into user/jeffbloo/FreeDimOverrideByName
[33m8ee5953153[m Merge remote-tracking branch 'upstream/master' into user/jeffbloo/MergeGithubMasterToDmlDev1
[33ma4e312da43[m Fix build error in D3DDeviceCache.cpp
[33m422266c445[m Support conv transpos 1D in cuda provider. (#3300)
[33m7d5348f87e[m Add ability to batch device copy for graph inputs and outputs. (#3580)
[33mea62b3435a[m Clean up build.py code (#3466)
[33mfcf0f6ee9f[m Generalize reshape fusion (#3554)
[33m14e387aa1a[m Fix WinML namespace build break (#3583)
[33m56b223bc60[m Implement OneHot CUDA Kernels (#3390)
[33m1599562016[m Fix BatchNorm CUDA kernel definition
[33mc365822808[m Refactor some for the calibate.py. Add QLinearAdd and QLinearMul support.  Fix bugs loading jpgs not strict RGB, and typoes in load_batch call. (#3542)
[33mdb9566f70d[m Implement Inverse(12) for CPU and CUDA (#3485)
[33m38a18023c7[m Fix some too popular warnings. (#3578)
[33md68245853e[m Disable downloading test data on Linux (#3581)
[33m3e884b4b6b[m Fix some typos. (#3582)
[33m6fe688c732[m Disabled failed maxpool test on GPU (#3549)
[33m52cfc98ec4[m Merge pull request #3557 from microsoft/havenka/master-merge
[33m811bd67872[m Clean up docs. (#3579)
[33mca1bbff5d4[m subgraph type override handling and unit test (#3560)
[33me2288ff2b4[m Merged PR 4574388: Implement Eyelike int ops
[33mdc576a8de8[m Merged PR 4574316: Pad, OneHot, DepthToSpace, SpaceToDepth, TopK, Where int registrations
[33mc47490ab31[m Bug fix
[33mc170d087a1[m Merged PR 4573751: Add int32 and uint32 support to onnx Elementwise math
[33m7f46f347db[m Add GPT2 Attention Fusion in optimization script (#3488)
[33m5d3b217039[m Update Attention operator for GPT2 (#3474)
[33m2cb8cb816f[m Disable or update flaky tests, improve test random seed accessibility. (#3495)
[33m027b0cb3f3[m Update to match ORT signature
[33mb4457ecb7a[m Fix `gen_doc` build option and refresh documentation (#3545)
[33m5acd8dbe7d[m remove option --enable_lto (#3515)
[33m11baa4b56d[m Merge user/ticastro/fix-wai-build
[33m822883314e[m merge upstream/master
[33mf822a54860[m Make De/QuantizeLinear support half (#3531)
[33mc7b6fab29d[m Fix build break in mlas\lib\quantize.cpp: missing nearbyintf (#3572)
[33meda4df62ab[m Merged PR 4569464: ArgMin ArgMax Integer implementation
[33m43c3a5edba[m update onnxruntime version string for telemetry (#3526)
[33mde543c0308[m Add SafeInt include to WinML targets (#3558)
[33m209b41a67d[m Update dependencies graph
[33m2717c178cc[m Fork the WinML APIs into the Microsoft namespace (#3503)
[33mfcb27c4e8b[m hotfix for skiplayernorm (#3543)
[33m92269ae409[m perf tuning docs update (#3520)
[33m951484ba53[m Dualapipartitionattibute.h header is missing in nuget package (#3350)
[33m1a222b3f6e[m Disable downloading test data on Windows (#3551)
[33mc925156fd2[m Fix build error
[33md40fd897dd[m Support batched copies from GPU to CPU in DML EP
[33m6aa9d14d02[m Address PR coomment
[33m34bba7eac1[m Merged PR 4568892: ORT DML EP OneHot build fix
[33mc7cefe9200[m Merged PR 4558978: QLinearConv and QLinearMatMul implementation
[33mbe3b9244ac[m Fix GraphTest.UnusedValueInfoSerializes.
[33m9fc2b6482b[m Ort training README (#3404)
[33mcc5a565167[m Merged PR 4560079: MaxPooling dilations, TopK, SpaceToDepth, Mvn, Resample
[33m6c1ccb659f[m SoftmaxCrossEntropyLoss-12 forward and backward kernel implementation. (#3465)
[33m757aa0fbaf[m merge master
[33m0ec90f7019[m Put safeint_interface include directory into onnxruntime_common interface include directories to simplify usage by other targets. (#3546)
[33m80e0c64e2e[m merged with master
[33m93b957a55a[m Acl improvements (#3463)
[33mc91527235a[m [Java] Add support for map and sequence information on output nodes (#3468)
[33m7c89f38a34[m Fix static analysis warnings found by VC++ (#3530)
[33m47099a1700[m Merge remote-tracking branch 'upstream/master' into user/jeffbloo/FreeDimOverrideByName
[33m65baa5aae3[m Fix spacing
[33ma3a8a53736[m Enable free dimension override by name
[33m2f16172e69[m Address PR comments and clean up. (#3536)
[33md18f0fc47b[m Fix error handling for OnSessionInitializationEnd
[33mec4f6c099b[m Resolve comments and make minor changes to Featurizer transformers (#3535)
[33mabfb275ac0[m Support listing keys in custom metadata map via C/C++ API (#3477)
[33m72cd61baae[m Removed use of parameters in python wheel build scripts (#3524)
[33mcf2fddf760[m fix nuget build (#3532)
[33m2536e80602[m Rename API to onnxruntime.set_seed(<seed>)
[33m644bc05830[m Add Python API to set random seed:  onnxruntime.seed(<seed>)
[33me89dd92387[m Flush and trim resources in DML EP in new OnSessionInitializationEnd method
[33mb63349c8d6[m  Fix custom op test failure (#3525)
[33mbc9a199b16[m Renaming deviceNum to deviceId.
[33me9dc8954ac[m Adding support for ACL and DML to the Java API.
[33m2c7c45076b[m MaxBatchSize E2E Test  (#3454)
[33ma2feb29b0d[m Fix build break (#3528)
[33m1950391570[m Specific DML version latest and fix compile error
[33me303f458e4[m Add int64 input type for ReduceProd (#3507)
[33m4fa88a0a23[m Remove cast to OpKernelContextInternal to get threadpool and directly use OpKernelContext. (#3523)
[33mf564569a80[m Adapter Model and Environment tests (#3469)
[33m560f4c5b16[m Make GPUTEST macro consistent among TAEF/googletest (#3518)
[33m621b3ac03a[m FFT contrib ops (#3381)
[33m06b63975c0[m Fix fp16 type mismatch when graph output is an fp32-only node (#3411)
[33mbaa86f181f[m Handle the case that initializers are in graph input (#3449)
[33m006c5be1b1[m Optionally produce a python wheel that includes featurizers (#3491)
[33m040c28ff39[m Remove dead code from HandleNegativeAxis
[33mba7225f986[m Update Graph SetInputs and SetOutputs for training (#3446)
[33m06db89cf13[m Using logic for finding README.rst to find requirements.txt
[33m43d9f9190e[m Removing unused six package
[33mc2c3102aba[m Tying install_requires to requirements.txt
[33m66a79d2c9f[m fix (#3512)
[33mefd9b92482[m Handle Scalars in TernaryOps and Where. (#3509)
[33mcbe30f3e19[m update FeaturizersLibrary (#3511)
[33m5aab2671f8[m Fix crash in DequantizeLinear with scalar tensor (#3508)
[33m438353abcd[m Fix TruncatedSVDFeaturizer's test failure and re-enable it's kernel test (#3458)
[33m67443c0e17[m Fix winml test compilation errors
[33m5d99f179b9[m Merge pull request #3486 from microsoft/sedymche/merge_master_ort_training
[33md1384ba27e[m Merge branch 'user/jeffbloo/MergeGithubMasterToDmlDev' of https://microsoft.visualstudio.com/DefaultCollection/WindowsAI/_git/onnxruntime into user/jeffbloo/MergeGithubMasterToDmlDev
[33me3c9fb9fee[m Fix build issues
[33m4e045d39d3[m Merge branch 'master' into user/jeffbloo/MergeGithubMasterToDmlDev
[33m54bbbb78ae[m Change mask_index input of Attention op to be optional (#3459)
[33mbf3df41424[m Put back SubmoduleCheckoutMode parameter into mac-ci.yml.
[33mb670cdc11d[m Remove usage of DeviceProp (which is removed in ort_training) from cudnn_common.cc.
[33m7b2fc196fe[m Get cudnn_common.cc from master.
[33m571a6d52f5[m Add to list of failing backend tests from master.
[33m7f6e407e09[m fix python packaging manylinux1 build break. (#3482)
[33mcffdff6702[m Publish unit test results from Linux and Mac builds (#3480)
[33mf5ba9c922d[m fix internal loss scale (#3483)
[33m4b5f66ad17[m Put dropout_default, dropout_random, celu back in the list of broken tests.
[33m4223591043[m Add automatic generation of tensors for Onnxruntime Perf Runner (#3448)
[33m56e85484ba[m Handle optional inputs and remove more empty shape nodes in TensorRT EP (#3455)
[33m20c7dd9f5c[m Remove orttraining/docker directory. (#3476)
[33m03996c7c08[m Fixes for Where, ConcatGrad and ReduceSumGrad (#3415)
[33md09d4a6b0d[m Fix OS build (#3481)
[33m95ade8f47b[m Add check to prevent storing nullptr in value_info_ when proto has unused value info (#3461)
[33m2ccedb7b4d[m Improve error logging when a kernel cannot be found. (#3473)
[33mbb2f427990[m Remove FastGelu from activations.
[33m739c9d4875[m Always call cudaSetDevice at the beginning of session::Run (#3475)
[33m507d2bb9b9[m Get onnxruntime/core/providers/cuda/math/matmul_integer.cc from ort_training.
[33m1b465ba820[m Get onnxruntime/core/providers/cuda/cu from ort_training.
[33mc5176087bf[m Get onnxruntime/contrib_ops/cuda/bert/fast_gelu.cc from ort_training.
[33m6bbc80951d[m Get onnxruntime/core/providers/cuda/tensor/slice.h from ort_training.
[33m0e4080f1d6[m Get cuda_common.h from master.
[33m84773c61c6[m Rename ONNX OPTIONAL to OPTIONAL_VALUE.
[33ma443b1b6b9[m Revert "Use IMMA for int8 matmul to leverage Turing Tensor Core (#3413)" (#3472)
[33me7297e6c9d[m create pipeline for ci frontend tests (#3422)
[33meaa3f652df[m Fix dynamicslice.cc after merge.
[33m8ea0e596ec[m Fix onnxruntime_unittests.cmake after merge.
[33m6ba7c99e50[m Merge branch 'master' into ort_training
[33mb04e48333d[m Merge branch 'master' into DmlDev
[33m40d80cde8f[m Rework CDist (#3393)
[33ma08f16471a[m Address comments around bfc arena  (#3460)
[33ma298556600[m raid rtol to unblock CI (#3457)
[33m31bb1182e6[m Merged PR 4530161: ORT changes for conversion of DML graph to public API
[33mf73008483a[m safeint for region bytes in bfc arena and code clean up  (#3447)
[33m718068f020[m update C# API to optimize inference latency (#3171)
[33mcdac74b3c3[m Use Eigen threadpool for ReduceSum and ReduceMean. (#3441)
[33m1ddfe1249b[m frontend test to use random seed (#3209)
[33mf8fa1dde55[m Add a list of Featurizers kernels (#3435)
[33m4d71958ccf[m Use IMMA for int8 matmul to leverage Turing Tensor Core (#3413)
[33mde60a14c16[m Fix output range for int8_t QuantizeLinear op (#3445)
[33maabf47b107[m Fix Split CUDA implementation for zero sized input (#2942)
[33m48e96ea65f[m Reduce binary size of Slice implementation (#3238)
[33mff51d752d1[m Merged PR 4527632: Fix race condition creating resource store
[33mb35468289a[m View Op - new unit tests and add support for tensor memcpy by offset/size (#3439)
[33m1fd21c109e[m Fix race condition creating ConverterResourceStore (#3419)
[33m53b9d52fc6[m Rework TensorToTensorProto.  Do not put string data to raw_string. Eliminate redundant argument. (#3438)
[33m43d6c464fc[m Fix ACL EP pooling build breakage (#3429)
[33m4bdb5cc8e2[m Add CPU implementation for FastGelu operator (#3398)
[33m9e65298d7a[m Re-enable tests (#3437)
[33m15e32b44fd[m Merge pull request #3383
[33m8ab09186b7[m Bert Optimization Script Improvements (#3387)
[33m95707d22a5[m Disable gradient clipping for E2E test.
[33mc8f5e6e632[m Implement Min/Max/Clip(12) (#3410)
[33m7c69b1703b[m Fixed a typo (no functional change) (#3433)
[33m4ebad8805b[m change (#3431)
[33m0dcc6035b1[m Disable strong inline (#3399)
[33ma3ab2ba036[m Reapply commit 131c65d; Fix memory regression issue. (#3423)
[33md361121d98[m Do not inline ExternOp's scalar tensor inputs (#3426)
[33m517693a507[m Fix race condition creating ConverterResourceStore (#3419)
[33m33006f48c0[m Update onnx submodule to 1.7.0 release candidate (#3405)
[33md4d19a75ba[m Use MlasConv for 1D convolutions (#3425)
[33m5835349614[m Add #pragma once to providers.h, so avoid 'struct' redefinition error when including the header from multiple places.
[33m82c1e1b3db[m Enable loss scale input from Python frontend (#3327)
[33mf437665360[m Revert "Addressing PR comments (#3334)" (#3412)
[33m14f4c3e25f[m Fix issue in construction of DummyArena. (#3416)
[33m85131e760c[m Enable upsample2x optimization for opset 11 Resize (#3388)
[33md89e5d91a6[m Disable GradientCheckerTest tests for GPU/Debug build (#3407)
[33m675035b1a8[m Disable GradientCheckerTest tests for GPU/Debug build (#3407)
[33m3568f8d186[m Allow a custom op with the same name to be registered for several providers. (#3400)
[33ma5fea26cb4[m Disable model tests for Mac OS X builds
[33me2afe5e054[m Revert Session and InferenceSession implementation
[33maefa466334[m Allow zero in split op (#3389)
[33m1671072b6b[m [WIP] Port image tests from WAI (#3365)
[33m0b1e3f1e10[m Revert _SliceKernel cuda implementation
[33m28ff88ce52[m Disable tests (temporary)
[33m1c334ed0f1[m[33m ([m[1;31morigin/orttraining[m[33m)[m Add Ninja generator to build.py (#3331)
[33medec8043d4[m Fix python examples in documentation (#3379)
[33m2ce90cff4c[m PR comments (#3374)
[33m614eb438ae[m Update Op's Domain and Version (#3356)
[33maccffded5d[m Build options for enabling AVX/AVX2/AVX512 (#3373)
[33m77c7d09ced[m ERROR_NOT_SUPPORTED doesn't trigger Failed Hresult. Need E_NOTIMPL (#3396)
[33m052c1fda44[m fix some warnings in concurrency tests (#3395)
[33m33d3239b67[m Rework SVMClassifier to improve performance (#3363)
[33m6d769d47c4[m Fix InferenceSession API
[33mefc8bd738f[m add pipeline graph split script (#3275)
[33m83c3da3fc0[m Fix code-base after breaking API changes
[33ma61400de01[m Fix ARM cross compilation (related to #3378, #3298) (#3385)
[33mae15c36687[m Merged PR 4500055: Fix autopilot WinML::Engine::Test::BenchmarkProtobuf#onnxzoo_ssd#1.5#GPU
[33m55fd283d20[m Fix a bug in FunctionImpl::FunctionImpl (#3376)
[33ma4fe60c4d3[m OpSet 12 ops (#3341)
[33m044c466158[m Updated tags for v1.2.0 release (#3386)
[33mecbacd7d79[m Add Benchmark of GPT2 CPU inference (#3351)
[33me6e4339f0b[m Merged PR 4408731: Perf: Command lists should be preemptively reset in DML when flushing
[33m759818f2c1[m Merge remote-tracking branch 'origin/master' into thiagofc/ort_training_merge_from_master
[33mace741680d[m Constant-12 support  (#3304)
[33m2332a93db0[m Update onnx-tensorrt parser (#3369)
[33mce9acf0c21[m iOS crosscompilation under linux (#3298)
[33mfb2f97a002[m Address master merge PR comments (#3348)
[33maf618278f6[m fix bugs in quantization and calibration tools (#3329)
[33mf2ca2b2981[m Avoid "infinite" loop in optimizer (#3321)
[33m06fc9506fd[m Thread pool changes (#3153)
[33m0494036006[m fix tensor location mismatch in allocation planner (#3249)
[33m2b10e625f9[m added public value varibale to NamedOnnxValue (#3347)
[33m355f39ddee[m fix cuda build for cmake >= 3.17.0 (#3362)
[33md8f0a0f223[m Address PR comments (#3352)
[33m1bbc421884[m Don't cast to fp16 in LayernormGrad (#3328)
[33m33b5010e62[m skip optional inputs for scan subgraphs (#3349)
[33m324166b9cd[m Merged PR 4471419: DML EP kernels in ORT
[33m5bc81b7ae9[m Fix bad merge (caused Slice to fail).
[33m5972ce5566[m PR feedback
[33mf1a062c292[m PR feedback
[33mffb2a3359e[m Implement WhereGrad (#3343)
[33m351c3c30fb[m Merge branch 'DmlDev' into user/dwayner/DmlEpGatherScatterReverseRangeInfModRoundBitshiftCumSumClip
[33m8ff351ecc4[m Merged PR 4482575: DML EP Slice in ORT
[33m6c960a9417[m PR feedback.
[33mc3cea486d0[m Port ConcurrencyTests from TAEF (#3086)
[33m49e6043d07[m support Huggingface's adamw (#3318)
[33m031647635b[m Delete another litter file.
[33m5feb3c0f19[m Delete litter backup files.
[33m89df6abac7[m Fix slice.
[33mccb840ac99[m Fix slice.
[33m5278f73202[m[33m ([m[1;31morigin/gpt2_script[m[33m)[m Fixed two issues in symbolic_shape_infer script (#3332)
[33m810a10b230[m Enable Onnxruntime Telemetry by Default for 1.3 (#3338)
[33m131c65d23d[m Addressing PR comments (#3334)
[33m2e875f4e67[m Delete outdated page (#3320)
[33m497e83eda5[m Minor update to the issue template. Add a line to attach model where applicable. (#3339)
[33m0a6ec0df56[m Merge pull request #3285 from microsoft/xuzhu/merge_from_master
[33md143b41b81[m Expose frozen_weights in PyTorch Frontend (#3317)
[33m0e81962e98[m correct the cmake version to 3.13 for Arm build (#3333)
[33m13dabd97b6[m Slice
[33m66c7579c93[m address PR comments (#3312)
[33m5f6ec8ea6d[m Fix a bug in Maxpool v8
[33mdee4fc8b8a[m Apply the same check for no_transpose from the Reduce* ops to ArgMin and ArgMax (#3315)
[33m51e95ea946[m Make ort errors appear in winml exceptions (#3316)
[33ma031af8cfc[m fix windows build
[33m9eb792a5b3[m move env to .cc file
[33mb38fc0d541[m Add bias correction in Adam & Lamb for C++ frontend & python frontend (#3301)
[33m0f6ace2c36[m Fix comments with stale todo's.
[33m55d32085f6[m Update comments.
[33mcc095fefbb[m Fix squeeze.
[33me9877850a4[m fix python error
[33m4db01309cb[m Use GEMM for SVMRegressor. (#3305)
[33m5366273110[m Fix GatherND and ScatterND.
[33m6474801ceb[m Update ort_trainer.py with lazy onnx export (#3244)
[33m19edad132c[m Move AzureML Bert notebook from onnx tutorial (#3302)
[33mfef7989866[m Replacing CudaAsyncBuffer with TArray to improve perf (#3303)
[33m98c28060b0[m Aggregated Send/Recv (#3232)
[33m271126a86e[m Fix clip.
[33m1df264f4b3[m Fix Range.
[33mef7b98f988[m Support DisposableNamedOnnxValue inputs in c# Run() (#3175)
[33mfb5ab858d2[m Update BUILD instructions (#3282)
[33md15c74e713[m Implement pipeline event generator (#3206)
[33m8f7bd51f7a[m fix pybind issue introduced by merge
[33mb72fe13941[m Update WinML Projection to accept sequence of tensors (#3287)
[33m7f610caca0[m Make gradient clipping configurable. (#3243)
[33m843ee346a8[m Implement struct TArray and simplify code. (#3291)
[33m57468c651c[m QLinearMatMul speed up (#3283)
[33m9c3b6d2e4b[m Fix warnings in nuphar
[33m9dbc50c438[m fix build break
[33m403f99cd77[m Use yapf to format python (#3276)
[33m84015d9491[m Fix post merge test. This doesn't get triggered as part of gated PR checks. (#3277)
[33mccc3535e72[m resolve conflict
[33mb880c48c4c[m Make reduction ops handle Scalar input (#3260)
[33m5c52332223[m unittests comments (#3278)
[33mc5149e89d9[m Wangye/shortgraindropper (#3273) (#3274)
[33m1d9be2baed[m Add Notebook for Bert Model exported by Keras2onnx (#3271)
[33ma69d859912[m fix quantize_bias (#3270)
[33md521efd904[m refactor frontend (#3235)
[33md9f628cb1d[m Remove orttraining/tools/scripts/profile directory. (#3268)
[33m6dc25a60f8[m Make the reduction ops more consistent in checking if no transpose is required and skipping the copy of the input data if that is the case. Significantly better performance when this is done (2x faster for model calling ReduceSumSquare with input of {2048,10}). (#3265)
[33mca7985fd9f[m Address PR comments (#3256)
[33m8f00147c14[m Fix a few warnings
[33m3bdb0b620a[m Fix WCOS/Win32 linking bugs (#3126)
[33m61e8a24340[m Address PR comments (#3255)
[33md82f72e65c[m Add ort_training build status file. (#3257)
[33m435f014d71[m Add support for sessions to share a global threadpool. (#3177)
[33m03d14bae2b[m Register ONNX Training Ops (#3252)
[33me03b8a1e2f[m Move path_lib from onnxruntime/core/framework to onnxruntime/core/platform. (#3253)
[33m61621d4053[m Add extra fields to ORT telemetry (#3234)
[33mbd348ec6ca[m Add unit test to cover TreeEnsembleClassifier applied to binary classification and 2 classes (#3230)
[33m88c65f8add[m Fixes GTest deprecation warnings
[33mc5576d70a6[m Fix build issues (#3214)
[33m0700d13ece[m Add Bert Optimization Notebooks (#3204)
[33mf6211217d8[m Fixes
[33m8bc4e3195d[m Updates to roadmap (#3155)
[33me63f817eb6[m avoid IDXGIFactory 6 where possible to enable WinML GPU Path downlevel to RS3 (#3180)
[33m682dde2b3b[m add dml_ep_lock (#3200)
[33m4b2c8e884e[m Udpate License Header (#3212)
[33m6319357a99[m Reduce number of allocations in TreeEnsemble (#3217)
[33m0fceb33288[m Fix onnxruntime server docker file build failure (#3219)
[33m3a7539e071[m Update bert-base convergence values
[33mdc11b82956[m Tweak the dropout calculation.
[33m88c20eaef1[m MLAS: rename AVX512BW->AVX512Core (#3216)
[33m551d28be9a[m Update.
[33md489288e3c[m Add kernels, including stubs.
[33m2a6e5ce978[m Speedup and reduce binary size for TfIdfVectorizer (#3197)
[33mfe0b2b2abd[m QLinearConv speed up (#3196)
[33m0a1257e467[m Adjust the grouping logic in ThreadPool::TryBatchParallelFor (#3207)
[33m5bc0d8be5c[m Fix TopK Cuda implementation (#3176)
[33m93569bf0f4[m fix regex to populate dll version information correctly
[33mc69194ec4c[m fix the missing return in _get_quantize_input_nodes and format code with yapf (#3199)
[33md99554bea1[m Improves implementation of tree ensemble regressor and classifier (4 to 5 times faster) (#2692)
[33me9d5ed270f[m Normalizer performance improvements (#3201)
[33m890cb78b20[m Use Eigen::logistic instead of manually computing values. (#3186)
[33mb8575dda7b[m Avoid some heap allocations in the InferenceSession and Model classes (#3103)
[33m24793f5fc7[m Revert change from RelWithDebInfo to Release in OnnxRuntime.CSharp.sln.
[33m2cad08bd60[m Merged PR 5688: Upgrade ONNX submodule to the latest from github ONNX master.
[33m2f1e997e5b[m Merged PR 5686: fix P100/fp16 issues
[33m75025461e2[m Initial implementation of graph cut and pipeline
[33ma02638eb46[m Adjust the threading logic in ThreadPool::ParallelFor (#3178)
[33mf49912c42a[m Performance improvement to Transpose when moving single axis. (#3173)
[33mfa4dd51e3b[m Add back orttraining-linux-gpu-inference-only-ci-pipeline.yml. (#3182)
[33m3af5a2a2cf[m Change Tensor::[Set]ByteOffset() to use ptrdiff_t.
[33m80dd62a240[m Enable CI for training.
[33me542cfd0e0[m Introduce training changes.
[33m6791ed0217[m Documentation updates for 1.2 for WinML (#3149)
[33ma912415bac[m Support custom ops targeting the CUDA EP (#3165)
[33m3464801c3e[m Explicitly specify NugetPackage parameter while validating nuget in some release pipelines (#3139)
[33m3de1fc096d[m Move zero point inputs of MatmulInteger to CPU memory (#3159)
[33m51a8c82908[m Update bert optimization script for SQuAD model exported by keras2onnx (#3163)
[33mbe0c0da9ef[m Merged PR 4408735: Fix control over metacommands being enabled or disabled
[33m876d0c5430[m Make quantization parameters as constant weigth instead of overrideable (#3160)
[33m3d928de778[m Use GEMM for LinearRegressor and LinearClassifier operators to improve performance (#3154)
[33mf87b6913cd[m Add package download step before pushing to feeds (#3162)
[33m6ed5d7c332[m Update post_binary_sizes_to_dashboard.py (#3161)
[33ma59243090a[m Publish release symbols (#3152)
[33m781a6ebb06[m Updated Ruby supported versions
[33mcfd18b583a[m Help output typo fix
[33m5be6665b86[m Update Gelu Fusion to support new graph pattern from PyTorch 1.4 (#3148)
[33me2894c5ffb[m Fix package name overrides (#3150)
[33m1d2b8115e2[m Support u8u8 in quantization tool (#3140)
[33made4fa108f[m Disable delayload for cuda dlls (#3147)
[33m2c446a7f2f[m Add push to ORT-NIGHTLY. (#3146)
[33mfbb658e603[m Implement QuantizeLinear and DequantizeLinear (#3098)
[33m83753bcbe3[m Suppress maybe uninitialized warning in gcc-9
[33mef8768a53f[m Override native package name. Preserve managed package name the same. (#3133)
[33ma2eeb126b9[m Optimised kernel_dot() in SVM op (#3135)
[33m9d874c1225[m Add bert performance and correctness test tools (#3108)
[33m84ad4eda8b[m Implement MatmulInteger on GPU (#3070)
[33m12605f05d1[m Fix CUDA PATH (#3131)
[33m6cdd2b4934[m Enable DML Nuget Package for x64 or x86 architectures (#3120)
[33me45326b5df[m Create NuGet packaging pipeline for ORT Featurizers (#3125)
[33mb538cb7e46[m NCHWc Upsample/Mul optimizations (#3116)
[33m4188b1111a[m Add a summary for each ExecutionProviderAppend methods in SessionOptions.cs (#3111)
[33m37f5fd8fb8[m Add support for loading TensorProtos with external data from optimizer Initializer (#3045)
[33mc6ed077441[m Add d2FH4- flag to cuda (#3105)
[33m86b755774f[m Create a separate Nuget hosting just managed assemblies (#3020)
[33m5008fc5b00[m Featurizers: Import fix for Linux build adjust linkage (#3089)
[33md72639ef77[m Fix CUDA 10.1 DLL names (#3102)
[33m37a905f557[m Make Java API available on Android (#3030)
[33mca2ed17ba7[m Bump up version number to 1.2 (#3097)
[33mf1ba531d9c[m Disable test_zfnet512 and test_bvlc_reference_caffenet for x86 in C# tests (#3094)
[33m04063aa324[m optimizer shouldn't depend on inference session
[33mbf7afbef23[m Changes in the props file to support .NET + AnyCPU configuration (#3091)
[33m5e0f7412cd[m Properly handle downlevel and WCOS scenarios (#3075)
[33m57384d5077[m Add disclaimer to DataFrameTool header (#3085)
[33md7500b26bd[m Remove Publish Build Symbols from pre-checkin  CI build (#3088)
[33mf4a5d17294[m Upgrade to CUDA10.2 for TensorRT (#3084)
[33md7f2cdcc7e[m Fix target platform of managed OnnxRuntime dll and enable x86 .NET testing (#3056)
[33m9ba05a4a1c[m Merged PR 4349264: Updating 8 Bit Kernels
[33m92d8d90d24[m Comments
[33mf407de6da1[m Updating 8 Bit Kernels
[33mb23b7f0fea[m [java] Adds the provider compile-time flags where the JNI code expects them. (#3082)
[33ma506911208[m No need to create a copy of graph proto when checking to see if there is fp16 input (#3061)
[33mdae9a31719[m Introduce new Featurizers packaging pipeline. (#3068)
[33mb8628404f3[m Replace hardcoded include path value with the advertised setting. (#3083)
[33mfb7317173d[m Doc updates for 1.2 release (#3069)
[33m0d30b42c7b[m Fix python gpu build (#3081)
[33mf367fd921c[m Use a custom allocator for temporary buffers in reduction_ops.cc (#2775)
[33m61ae134469[m Fix binary size report (#3080)
[33m3e371575ea[m Relax testing tolerance of NchwcOptimizerTests::BatchNormalization (#3078)
[33mae1f35fb9f[m Ignore GCC no-deprecated-copy warnings (#3074)
[33ma0c9f679fc[m Add logging to nchwc_optimizer_test.cc (#3073)
[33me38df45587[m Add missing include to dnnl_conv_batchnorm.h
[33m64feee1b52[m Logging in framework.cc should use the session logger (#3059)
[33mfb871978b5[m Adjust build flags for the release pipelines (#3066)
[33ma7541f9753[m [Java] Fix for incorrect input and output lengths in run call (#3064)
[33m21cc2d88b4[m Move some vectors out of loops to minimize memory allocations/reallocations (#3062)
[33m7ffb36be44[m Fix softmax cpu code for double type (#3065)
[33m179603775f[m Use CUDA 10.1 for Linux build (#3057)
[33mbe12fb3143[m include winml x86 binaries in the drop-signed-nuget artifact (#3058)
[33m752d74928c[m Improve the efficiency of SVMRegressor code (#3054)
[33m92b8a7a2be[m GPT2 Gelu Fusion & Test (#3009)
[33m932ecaea34[m Some documentation updates. (#3060)
[33mc033cfee92[m Check python version (#356)
[33m45ba325fa6[m Remove USE_NSYNC macro (#3052)
[33ma1db87b382[m Add SafeInt bounds checking to memory allocation size calculations. (#3022)
[33m21f9a8bdc2[m Allow creation of string tensor sequence (#3048)
[33mcb24e2a214[m Update nsync
[33m85c0989e6f[m Fix build errors in benchmark
[33m5306a1241b[m Server: Add build options for the other EPs
[33m44d5eaf3d7[m WinML exists in the nuget packages but does not publish its WinMD and headers (#3037)
[33mbcbc5ee815[m Improve error message for type mismatch between data in initializer and graph usage of the initializer.
[33mdde4df148b[m Add and run spotless formatter for Java and Gradle
[33mef2bba316b[m CUDA 10.1 for Windows(#3049)
[33m18aa0940c2[m checking condition is wrong (#3025)
[33me3c27536d0[m Python binding doesn't need to link to the python lib on Linux
[33mdaf8c4bee4[m Remove faturizers from CPU MLDNN and NoContribOps builds. (#3039)
[33m411b3aa801[m Java build system enhancements (#2866)
[33mecdcd682bb[m NCHWc ReorderOutput->Transpose(NHWC) fusion (#3035)
[33m71ca43b345[m Revert an op version change (#3026)
[33mcc8adc87c3[m fix NCHWc intermediates as graph outputs (#3033)
[33m4ca50d9352[m Update DNNLibrary to v0.9.0 and update NNAPI GetSupportedNodes
[33maea76b0786[m Bert optimization for onnx model exported by keras2onnx (#3014)
[33m3626c46fad[m Optimize Math::Im2col + ConvInteger pointwise (#3017)
[33mf98f0f8717[m fix type constraint name of Resize (#3019)
[33m2b77cb19bd[m merge training kernels to master (#2999)
[33m584ba71485[m TensorRT dockerfile updates (#3016)
[33mc9f18756b9[m Avoid unnecessary copies of ModelProto from being made in the InferenceSession class (#3012)
[33m69bc8ce3c2[m Upgrade protobuf to 3.11.3
[33m5f29c9c366[m Add some test cases (#3010)
[33mc6b499bfc9[m Fix batch mode output for TfIdfVectorizer (#3008)
[33mda653ccdac[m Upgrade TensorRT to version 7.0.0.11 (#2973)
[33m273868eaa5[m Disable NuGetPackaging on Linux GPU and remove DML from the pipelines (#3006)
[33med0875909e[m Reorganize and update readme (#2916)
[33me5f7e04e6f[m Use target_add_dml function (#3005)
[33mabb626ff60[m Provide alternative std::mutex implementation on Windows (#3000)
[33mc1997db85e[m Exclude faturizers from Linux NuGet packaging.
[33m36915b3674[m Temporarily remove Featirizers from packaging-pipelines
[33mce713823cc[m enable winml in the gpu ci pipeline (#2993)
[33m5c5ac34b5c[m Disable use_dml in nuget pipeline (#3001)
[33mfb2182f3fc[m Release ARM/ARM64 Nuget packages (#2987)
[33m3afb83ac3c[m Support a few new C/C++ APIs (#2794)
[33m7437928f47[m Replace hardcoded State serialization for Featurizer kernel tests (#2992)
[33m64deb8030f[m Update ABI_Dev_Notes.md (#2959)
[33mb8d7d81506[m Calling WinML enables telemetry by default for 1.2 (#2988)
[33mca7626d739[m Winml should be built against v2 of the capi as that includes the new type info apis (#2991)
[33mc8ea154e55[m Package data_frame_tool, include featurizers into Manilinux2010 (#2989)
[33m62383b0328[m Improve BERT optimization script: Gelu and LayerNorm for models from Tensorflow 2.* (#2957)
[33m0beb75ce77[m populate file metadata for onnxruntime.dll (#2978)
[33m4f4f4bcd92[m Handle dynamic shapes and reshape the input according to the model (#2986)
[33mec07fdc5b0[m Update ThirdPartyNotices.txt for eigen (#2985)
[33mbc9f55df47[m Change eigen submodule url (#2975)
[33m8888b71562[m Add CounterVectorizer and TfIdfVectorizer. (#2981)
[33m0e5582bcc3[m Publish nightly NuGet packages to a new Vsts feed (#2976)
[33mf03e720727[m Disable _tlgPragmaUtf8Begin and _tlgPragmaUtf8End as well. (#2977)
[33mc32cedc6c9[m Merge windowsai (winml layering) into master (#2956)
[33mc86db8067d[m Deliver a list of Featurizers (#2958)
[33md5efbcb8d8[m MLAS: Apply 'small-M' optimization for column-vectors (#2971)
[33m7ff5c0e5a3[m CMake changes (#2961)
[33m1d79926d27[m Add int64_t support for split (#2944)
[33m79f1756d8e[m Removed build.py unused test_data_url and test_data_checksum options.
[33m1e4080061b[m Added support for double in batch norm (#2941)
[33m51595d6a4a[m Add Int64 support to Neg
[33mc23bd93ea5[m The closed variable in OrtEnvironment should be volatile to ensure threads see changes to it.
[33m4cc0031177[m Java - Fixed a reference counting bug in the OrtEnvironment close method. Added a unit test for the bug.
[33m7bb5c357a8[m Adding some unicode to the String inference test to make sure it doesn't fall prey to #2690.
[33mf33759883c[m keep output of bert model as float32 when converting to float16 (#2913)
[33ma319ad29b3[m Do not link onnxruntime jni output with JNI_LIBRARIES
[33m8a1de1a582[m Java - requesting JNI_VERSION_1_6 rather than JNI_VERSION_1_8 to support Android.
[33mf60badc1f3[m Documentation for API Breaking Changes (#2927)
[33m1239de3efe[m Fix output shape computation in ConvTranspose op (#2688)
[33me03e6676c0[m Add support for int64 to int64 LabelEncoder (#2926)
[33m645d8fb213[m Jignparm/upgrade macos vm image (#2928)
[33m653ce36ccf[m[33m ([m[1;31morigin/wiu[m[33m)[m Disable stacktrace on android
[33m49ce4891bc[m Add noexecstack linker flag
[33m0279682147[m Add document for onnxruntime server.
[33m546d8f71ab[m Contributing: fix typos (#2905)
[33mdaff4240f0[m Updated README.md (#2910)
[33mcd876720d9[m Only fuse when output count of add is 1 (#2884)
[33ma92e924ab2[m Revert "Use IArenaAllocator::Reserve for initializers and mem pattern planner blocks (#2835)" (#2904)
[33me0c9cdaa73[m Fix the nuget pipelines (#2901)
[33m17b72d5578[m Fix NCHWc BatchNormalization regression (#2903)
[33mba336b5583[m Disable DML EP on software adapter, fix float16 fallback bug, re-enable DML in CI (#2896)
[33m201b089a36[m Fix some warnings on Windows (#2560)
[33m49725f896c[m Disable openmp for the nocontribops pipeline. (#2888)
[33mfc51473b09[m Update BFCArena logic to use backoff if cudaMalloc fails. Makes behaviour equivalent to when a CPU allocation fails. Add unit test. (#2748)
[33m061f10fcd5[m Fixed typo in ORT_RETURN_IF_NOT() message. (#2862)
[33m9f5e8c4ae8[m InferenceSession::Run needs to call OnRunEnd for any EP that OnRunStart was called for so they can cleanup. Currently it only calls OnRunEnd if the Status is OK. Due to this the CUDA EP will throw during shutdown as the per-thread information has not been cleaned up prior to the CUDA library shutting down. (#2881)
[33m38b34babe0[m Rashuai/boost cuda TopK performance (#2826)
[33m08113b80cc[m Optimize BatchNormalization to NCHWc Conv (#2855)
[33m807a59c55d[m Add calibration tool (#2845)
[33m22d9f3998e[m Fix positive raw scores for TreeEnsembleClassifier (#2824)
[33mb21576eeb0[m Support non-sequence tensor fed through as a python list (#2782)
[33mf9f25ec047[m Fix spurious component detection warning (#2857)
[33m25d7ad187f[m Add float16 support back in the bert fusion script (#2870)
[33m95f3eb6aeb[m Bert fusion script for Tensorflow squad (#2858)
[33m01f3a33c38[m update protoc path to match protobuf version (#2865)
[33me6f7658ade[m Update Windows GPU build to use cudnn 7.6
[33m3853ddf9c7[m Fix topk type handling to accommodate more types. (#2842)
[33m47e27ec9a1[m Disable DML in Windows GPU CI build (#2856)
[33m724ff0753b[m Use IArenaAllocator::Reserve for initializers and mem pattern planner blocks (#2835)
[33m928b6bb210[m MLAS: enable threading for quantized GEMMs (#2844)
[33m5db8543018[m update optimization doc for BERT related fusions  (#2819)
[33m56030f8d74[m Fix Linux CUDA nuget packaging pipeline break
[33mcff266e1b9[m Fix cgmanifest.json generating script (#2770)
[33mdb05436fc0[m User/orilevari/32bit comparison warning (#2800)
[33m8643f3ebbb[m add domain check for nodes + update documentation (#2831)
[33maa37dea598[m Convert ExternalProject Featurizers into git submodule (#2834)
[33m98cb41aa03[m Ignore allocator type in ExecutionProviders allocator map. Make default initialization of OrtMemoryInfo more clearly invalid. (#2768)
[33mb308e826a8[m Add support for int64_t for topk CPU. Fixes github issue #2806. (#2833)
[33m5c391854f4[m Upgrade gtest to the latest version (#2827)
[33m120433c29d[m Add OneHotEncoder and HashOneHotEncoder kernels. (#2830)
[33m723cf83793[m Update Ubuntu & TensorRT version  in README (#2820)
[33m07502ec14e[m Fix dnnl wheel package name (#2823)
[33m7c6242b024[m update default optimization level + fix gemm_activation fusion (#2791)
[33mcc75e5a162[m update quantization doc (#2783)
[33mc4e4abce73[m Run static code analyzer on most of our code (#2817)
[33me37cdbed74[m Add manifest missing comma
[33mc4f6db7796[m Fix memory leak in TRT (#2815)
[33mafa48b7e13[m Add timeseries imputer transformer featurizer kernel (#2813)
[33m48e042868f[m Update test data (#2356)
[33m31200ed92c[m speed up Windows TRT CI (#2811)
[33mb0019ac7fe[m add interface to copy batch tensors. (#2807)
[33m7ef6570e27[m MLAS: update SGEMM threading parameters (#2808)
[33m71b5165ed3[m Initialize max of softmax with lowest of float (#2786)
[33m2c8179bee4[m ML.NET team needs featurizers within a package (#2789)
[33m1978376e1e[m add session creation time cost. (#2798)
[33m32c5e76a16[m Improve bert optimization script: (#2712)
[33mf84240db2b[m add uint8 support to where op (#2792)
[33mebfcad1c90[m Add script for release Nuget validation (#2719)
[33m3e6f1836eb[m ACL EP convolution improvements (#2774)
[33mfdc0106f83[m ACL EP GEMM improvements (#2780)
[33mf22bffe0f6[m Contributing: Fix a typo (#2784)
[33m72bdfc8cd4[m Implement a more stable softmax (#2715)
[33m6f66260372[m Import more featurizers (#2781)
[33m1b23118056[m Fix nightly build version number issue
[33me3f674b563[m Disable featurizers in python packages
[33m7ace7a5bcd[m Pass BUILD_BUILDNUMBER to linux docker
[33m7666d130e5[m Rename MKL-DNN to DNNL to fix broken link (#2730)
[33m3d75c1b6be[m Fix typo in error message (#2736)
[33m013642ed37[m Revert "Change default optimization level to All (from Basic) (#2745)"
[33m2096f324f4[m [NupharEP] fix a race condition when multiple sessions running different models concurrently (#2772)
[33ma2c8981a9e[m Add basic stacktrace output for posix debug builds. (#2749)
[33m382fa86af8[m Pipeline changes for python 3.8 (#2753)
[33mfd334aff44[m Update numpy to 1.18 (#2758)
[33m56bb503c2f[m Change default optimization level to All (from Basic) (#2745)
[33m90b708f8a9[m Update protobuf to 3.11.2 (#1928)
[33mb40a85a0e8[m Fix build for Python 3.8 (#2747)
[33mc7a9c6b488[m Split onnxruntime server to a separated folder (#2744)
[33m6e4ec9b049[m fix ngraph wheel (#2737)
[33m9013fe6340[m Fix build on Mac OS (#2731)
[33mf142b683a1[m Fix broken python docs links (#2740)
[33mebf23744eb[m MLAS: ARM64 build fix (#2734)
[33m71ce0b8e0a[m remove 64bit warning message from python validation. (#2727)
[33mabda478083[m [server] Add supposed for model_name and model_version as cli parameter (#2708)
[33mcd6ff42442[m Add schema for new Qops (#2611)
[33m71940c0915[m Update Nuphar tutorial notebook (#2721)
[33mbbe32f0990[m Extend DML kernels (#2641)
[33m4b900dc585[m Simplify cache implementation and avoid static variables that may carry over between models
[33mda03ed4473[m Tiny fix to codegen
[33mb42cb61904[m Packaging pipeline changes for VS 2019 (#2711)
[33mf0046a1531[m switch back order of session_state_ and execution_providers_ in InferenceSession.h (#2714)
[33m7c0235c15a[m Propagate documentation modification from rel-1.0.0 (#2713)
[33m967ffc03cc[m a subset of the models in testdata were missing an ir_version. update this ir_version to 3. (#2702)
[33m72286d91e7[m fix the CUDNN_BN_MIN_EPSILON difference issue between cudnn7.3 and cudnn7.6 (#2681)
[33m64112db346[m Fix C# handling of unicode strings (#2697)
[33m233bdd268b[m Advance Featurizers commits and fix up ORT lining issues. (#2705)
[33m9b14d8fd67[m Update rnn_benchmark to reset OMP threads (#2698)
[33mbb7f43ee91[m Documentation update: build instructions (#2636)
[33mb3d0b114fe[m Support Round op in the CUDA EP (#2601)
[33m715e365723[m Enable int8 GEMV tensorization (#2696)
[33m971bc439b5[m Support CumSum op in the CUDA EP (#2647)
[33m9017e93701[m [NupharEP] fix for Windows build and VS 2019 (#2694)
[33m89d6bfaa94[m VS 2019 build pipeline changes (#2693)
[33m0d5504877b[m fixed "unreachable code" warnings for Windows build (#2682)
[33m504ba6f2ca[m Remove a warning
[33mce7a180f21[m Import more featurizers with tests (#2685)
[33mc767e264c5[m [NupharEP] update tutorial with GPT-2 (#2677)
[33mb38b36a941[m Increase max_num_graph_transformation_steps from 5 to 10 (#2633)
[33m9dddabf237[m Miscellaneous DML EP fixes (#2634)
[33mc907881852[m MLAS: optimize QuantizeLinear (#2660)
[33m47503ec7a6[m Initiate the build scripts for ARM ACL (#2652)
[33mf7412899a1[m added cache version for nuphar JIT binaries (#2646)
[33m7c87070b24[m Import Featurizers (#2643)
[33ma46a28b7d8[m Windows CI changes(#2650)
[33m18bdde34dc[m Fix memory exception in Layer Norm Fusion (#2644)
[33m1996129ddf[m Improve performance of resize() in Nearest mode (#2626)
[33m6e68007d2d[m fix build error for ARM (#2648)
[33mfff1ed9bfc[m Optimize cuda scatter() on 2D compatible. (#2628)
[33me31be23c42[m Cuda pad optimize when no padding is needed. (#2625)
[33m8631b70c73[m Improve cuda expand() opeator's performance. (#2624)
[33mac08b58867[m Add shape inference to ConvTransposeWithDynamicPads schema (#2632)
[33m4dbf9442cc[m removed unnecessary batch file and fix path (#2640)
[33mc7cd336917[m epsilon attribute for layernormalization fusion (#2639)
[33md6f33dceb1[m fix float16 comparison in initializer (#2629)
[33mc04647b952[m Improve Embed Layer Norm Fusion for SQuAD with static input shape  (#2621)
[33m6859d92e2b[m Make sure fenced tensor could not reuse other tensor. (#2561)
[33mb2d65b447f[m Remove unnecessary parameter in some places in GatherElements implementation (#2612)
[33m8729784635[m Allow providers to be set for InferenceSession at construction (#2606)
[33m1ee250def8[m EmbedLayerNormalization Fusion For Dynamic Squad Model Opset 10 (#2613)
[33m2ca9733cee[m Dump subgraph ID and fused graph ID (#2607)
[33m45babd6c00[m symbolic shape inference: fix warnings in GPT-2 model (#2608)
[33mbc89eccb21[m Support opset 11 subgraph of Squad model in Embed Layer Normalization (#2605)
[33m796948c6ae[m Rename automl python tools folder to featurizer_ops. (#2593)
[33m6858f0a06a[m Add support for opset 11 in reshape fusion (#2592)
[33m35ceb1a6a6[m Java API for onnxruntime (#2215)
[33mb0128a4843[m Fixed an issue in updating realized dims (#2597)
[33m78099701b4[m Add missig env variables for mac pipeline test (#2595)
[33m41fc820f76[m add path to build dir before test run (#2590)
[33m6e08efa6a2[m Fix lto bug for protobuf and ubuntu
[33m62de8fa841[m[33m ([m[1;31morigin/winodws[m[33m)[m Update docs for Android NNAPI EP (#2586)
[33m0ab54521f4[m Temporarily exclude vgg19 test from Python backend test
[33m36eb1771ba[m Update version (#2584)
[33m200f4b4ea6[m EmbedLayerNormalization Fusion Improvement (#2553)
[33m0f12346d76[m [Nuphar EP] fixes for some object detection models (#2581)
[33mcbc398bb75[m Ryanunderhill/packagename test (#2582)
[33mc06dbd8311[m Add ConvTranspose1D (#2578)
[33m79847f39b3[m Fix file not found error during docker build. (#2569)
[33m5575766a53[m Add more check on SkipLayerNorm and BiasGelu fusion (#2574)
[33m262ee9dc5a[m Fix a warning found in the latest VS release
[33m34beafc51c[m make layernorm fusion to support opset 11 (#2545)
[33meeb28a80c0[m setup java ci mac (#2570)
[33m038ee91da5[m Allow sequence length to be symbolic (#2559)
[33m73c682b97c[m disable onnx_test_runner -x invocations for dnnl (#2568)
[33m7eddac16c2[m Re-enable Windows C# tests (#2564)
[33m854362cf05[m Update win-x86-ci.yml (#2557)
[33mace132f9aa[m Fix android build (#2558)
[33m4c996a8699[m DNNL CMAKE update (#2548)
[33m53a6bc2f07[m Fix a bug handling negative begin pad values in Pad op (#2550)
[33mbec4abf074[m Add back executable bit to build.py
[33m281933fa1c[m Fix C API tests for centos and mac (#2544)
[33md34fb62012[m Introduce container type runtime checks and other improvements (#2522)
[33mbe56d77a66[m Fix integer overflow in cuda NonMaxSuppression implementation (#2540)
[33m3e7aaf8fa1[m User/xianz/telemetry (#2458)
[33m293b15480b[m Add dynamic shape support in TensorRT execution provider (#2450)
[33md748f891d8[m Revert "Disable thread pool creation when enabled OpenMP (#2485)" (#2535)
[33m5c2e474751[m Add provision in ORT for session options to be parsed when available via model file  (#2449)
[33m178d059111[m Setup java ci (#2528)
[33mb50878dcf0[m Disable Attention fusion tests when DISABLE_CONTRIB_OPS is defined (#2529)
[33me32eff826c[m enable nuget package testing on centos7 (#2527)
[33m85a4ed8cf7[m fix cuda kernel causing invalid mem access (#2523)
[33m66254eb25a[m Update BERT model optimization python script (#2521)
[33m31ea11a696[m Renaming MKL-DNN as DNNL (#2515)
[33m3d627362a0[m Upgrade Windows CPU CI pipeline to use VS 2019 (#2519)
[33me8b327d657[m Fix constant folding of node assigned to CUDA (#2510)
[33m4354023913[m Make link time optimization work on Linux (#2477)
[33m25c260fdef[m Add parallel for tensorized gemm (#2517)
[33mc1be615c45[m [NupharEP] refine parallel schedule control (#2514)
[33m784eca0dcd[m Cuda pad() for opset 11 (#2490)
[33mb9faa0b6fd[m Fix kernel registry validation to reenable DML kernels
[33mddaad86605[m CUDA Loop (#2444)
[33m50eb140119[m Cuda Resize Operator for opset 11. (#2484)
[33mc42148a0c3[m Improves softmax function for standard ml
[33mec88f6d8d6[m Add DataFrameTool (#2456)
[33m89824b35e9[m optimize CPU implementation of Attention (#2496)
[33m0f57e0a49e[m Change mask input of EmbedLayerNormalization op to be optional (#2495)
[33m0edd4ef6ca[m EmbedLayerNormalization fusion (#2452)
[33m60208463a9[m [NupharEP] Enable parallel schedule (#2505)
[33m005305be6e[m Implement AddGelu and SkipLayerNorm (#2487)
[33mee0bde6b69[m Enable three type of Equal() to version 11. (#2508)
[33m75b4747701[m Fix a memleak in pybind. (#2503)
[33m1fdf1006ac[m Various fixes coming out of discussions in #2436 (#2497)
[33m04b6097db4[m Cuda Clip() for op set 11. (#2411)
[33mccbd778d0d[m optimize CPU implementation of EmbedLayerNorm (#2491)
[33me57b735bb9[m Add a transformer to use Gelu approximation for cuda provider (#2480)
[33m7c7d5a149c[m Disable thread pool creation when enabled OpenMP (#2485)
[33me29fb5cef1[m Add BatchParallelFor, TryParallelFor, TryBatchParallelFor into ThreadPool (#2476)
[33md6c84925d5[m move logSessionCreation after session is initialized (#2481)
[33mca8ff8c91c[m Enable conv/conv_transpose for opset 11 in cuda execution provider. (#2401)
[33m1ca0e0866e[m Revert "Remove DeviceAllocatorRegistry class (#2451)"
[33m4cac18f666[m Optimize CPU Transpose for a single axis moving (#2461)
[33m882f28a74b[m Fix NuGet end to end tests for custom op dll (#2472)
[33m5dce9be4f9[m Add Attention Fusion Transformer (#2445)
[33m4caf5c9c13[m add additional test data set for nuget pipeline (#2448)
[33me0b51e4d95[m Symbolic shape inference improvements: (#2460)
[33ma01816335d[m Allow more than one invocation of CreateEnv in the same process. (#2467)
[33mb3bfc094b9[m Fuse SkipLayerNorm with Bias (#2453)
[33me7131f6d12[m Pull the latest image before running docker build
[33m0341ee9060[m Clean up build.py (#2446)
[33md49cbf6e08[m Parallel Gelu with ParallelFor (#2399)
[33mca0ed96621[m CSharp api and test for loading custom op shared library (#2420)
[33m6a88d03621[m Remove DeviceAllocatorRegistry class (#2451)
[33md486481455[m Correctly handle implicit inputs for fused nodes (#2390)
[33m6bcf95477e[m Fix Windows GPU C API packaging pipeline failure (#2440)
[33m87d3794ad2[m Add CUDA Scan operator. (#2403)
[33m9b7b5e2c27[m Adjust codegen vectorization width from target (#2439)
[33ma5daa6faea[m add Im2col<uint8_t> (#2438)
[33m3be554c2fb[m Fix the type constraints on CUDA If operator to exclude strings. (#2431)
[33m8647201ac7[m Improved documentation for onnxruntime::utils::SwapByteOrderCopy(), added precondition check.
[33mbe12cdc73f[m Add CUDA If operator. (#2377)
[33m1cb6bdc33c[m Added support for Pad-2 operator in OpenVINO-EP (#2405)
[33m95e8c3377e[m onnxrt server documentation update (#2396)
[33m0e947bd328[m feat(treeregressor): Update TreeEnsembleRegressor for type support (#2389)
[33m367361fc74[m Fix the issue in matmul_add_fusion (#2407)
[33maa7c79eac9[m [NupharEP] Update notebook and docker image (#2416)
[33me1c17fd126[m Add Reshape Fusion (#2395)
[33mf268e69c79[m Minor optimization: if a node has already been placed, there's no need to find a kernel for it. (#2417)
[33m5ab7041fa7[m fix cross compile bug (#2415)
[33m1e03ce84eb[m [NupharEP] force some low/zero cost ops to be inlined (#2409)
[33mc1d757a00b[m Add opset 11 versions of the existing CUDA operators that had negative axis support explicitly added. (#2398)
[33m6cc57721f4[m Change CUDA implementation of Transpose to support all fixed size tensor types (#2387)
[33m109b3cb450[m Avoid using the default logger in the graph lib and optimizers (#2361)
[33mb15e43a541[m [NupharEP] Multiple optimizations  (#2380)
[33m7e164eaa6a[m Fix reuse logic in allocation planner. (#2393)
[33mb90d55b7ea[m Fixed compilation with ngraph (#2388)
[33mdde410e073[m fix BUILD.md typo (#2375)
[33m51571030ef[m Another try to stabilize CUDA CI (#2383)
[33mffa2812587[m Skip layer norm transform (#2350)
[33m8ed2928dd5[m Fuse Add + Gelu (#2360)
[33m4b72fedbd5[m Layer Norm Fusion Fix (#2379)
[33m8c733c8d82[m Add opset 11 version of Split to CUDA ops (#2376)
[33mc0d23d5ffe[m Fix bug with Slice. Need to pass in flattened input dimensions so the initial offset into the input is calculated correctly. (#2372)
[33m9e26f4de6f[m Extend OneHot CPU kernel to support more types (#2311)
[33m437772d5bc[m update output size calculation for resize (#2366)
[33m192dcfaa8e[m Fix a bug in TLS refcount that may destabilized CUDA CI (#2374)
[33m41b9f01e4c[m test bidaf with nuphar for avx target (#2370)
[33mfc6773a65b[m Add Tracelogging for profiling (#1639)
[33m0c6e9f94d0[m fix builds enabling onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS (#2369)
[33m53ed36a3da[m Add helper to create output to minimize binary size. (#2365)
[33maa37e2de8f[m Direct use python numpy array's memory if already contiguous.  (#2355)
[33med6da0d191[m Implement cuda nonzero op. (#2056)
[33m3d3cf0e159[m Openvino EP R3.1 onnxrt server (#2357)
[33m599d72a94f[m Fix/test dim value of 0 handling in a couple of places (#2337)
[33m25b3c51661[m Introduce PrimitiveType into a Type System along with an integer constant (#2307)
[33mfa30b1e758[m Set ElementType to String type of node metadata, instead of byte[] (#2348)
[33m7fcd752393[m Cuda Reverse Sequence Op, maping types of same size using same template function. (#2281)
[33m080a0a3186[m Nuget pipeline changes (#2305)
[33m5a3ea7469a[m Remove unused initializer from GraphProto as well as name_to_initial_tensor_ in CleanUnusedInitializers. (#2320)
[33mda3c0ba14b[m implement CPU contrib OP Attention (#2333)
[33mb539cc74c7[m Add FastGelu Cuda Op for Gelu and Add bias fusion (#2293)
[33m259bff8cf1[m Layer Normalization Fusion  (#2319)
[33m553537ed52[m Add CUDA GatherElements kernel (#2310)
[33m6651d2f662[m Make elementwise op run 4 items per thread (#2335)
[33mba0e7daf20[m update dockerfiles/README (#2336)
[33m0f1e24f4a9[m [NupharEP] tensorize int8 GEMM for avx (#2142)
[33m58e6aaa414[m Fix crash in releasing TLS from CUDA EP dtor (#2329)
[33mc0b8926863[m implement CPU contrib OP EmbedLayerNormalization (#2332)
[33m06a6d74a67[m update ngraph dockerfile. add python lib location to LD_LIBRARY_PATH for cuda/tensorrt Dockerfiles. (#2330)
[33mace19129b9[m MCR Docker Images v1.0.0 refresh (#2302)
[33m151075790d[m [OpenVINO-EP] Update to latest version: OpenVINO 2019 R3.1 (#2308)
[33mdb454beacf[m TensorDesc::Placement test failure - cherry pick Vibranium fix. (#2328)
[33m67ec626d88[m Copy blocks in Slice when possible (#2312)
[33m104f3b2a59[m Exclude candy from CUDA tests
[33m143ae98a37[m Fix a bug in onnxruntime_pybind_state.cc when TENSORRT is enabled (#2326)
[33m8a102c6e99[m apply eigen patch only for ACL.
[33m5ce4d4fc49[m Fix a test failure when it runs on FreeBSD
[33m035913d42f[m Support int32_t for Reduction (#2317)
[33md5c36bfff2[m Updated links in docs (#2303)
[33m556bae17a5[m Fix versions table (#2309)
[33mcba93f7c8d[m fix Gelu CPU: remove MayInplace() declaration (#2306)
[33m204a6872d3[m remove unused param 'input_count' in ConcatImpl (#2304)
[33ma6b2c9fc09[m Fix mask in EmbedLayerNormalization (#2300)
[33m6e65dcf588[m [NupharEP] symbolic_shape_infer improvements (#2299)
[33mbc85d43809[m Dump cuda tensor data (#2243)
[33m7a5de9c958[m Add a python script with a number of helper actions for creating/editing/dumping onnx test runner format pb files (#2294)
[33m358b517d49[m [v2] Add ACL (Arm Compute Library) execution provider (#2258)
[33mbf7fa091cc[m NonMaxSuppression cuda implementation (#2082)
[33m67755adfd8[m Bug Fix: NodeArg class has a move constructor but doesn't have a move assignment operator
[33md6849bd26c[m Rashuai/cuda top k (#1919)
[33m4bcd8bfca1[m Fix CUDA Reduce ops (#2268)
[33ma5da5ff6f4[m Remove onnxruntime_USE_EIGEN_THREADPOOL cmake option
[33mff64d1f55b[m Relax check for optimized model saving (#2291)
[33mecfbb1bb99[m Add missing guards to profiling calls (#1374)
[33maa041026e3[m update Dockerfile.openvino (#2286)
[33m427e627805[m Support for the Expand op with constant shape inputs (#2278)
[33me18c9582a8[m [NupharEP] performance improvements (#2283)
[33m63e9961637[m fix typo
[33m8dabe0502b[m merge two RUN to avoid making docker image too larger
[33m7b11f05a97[m Update version number
[33m2172a9e5ed[m Fix an issue in the nuget run tests scripts
[33m138a7f194e[m Add cleanup step
[33m002d9c335b[m Add node and op type info to error message if there's a type or shape inferencing exception thrown by the ONNX checker (#2277)
[33m8d231a32f2[m Remove the libc version check in C# code (#2282)
[33m983a616bda[m Revert to using opset 7 as the default for OpTester. Add explanation as to why that is: (#2256)
[33m47f40ca204[m Cleanup add/remove of initializer (#2274)
[33m09eb8ff8b8[m make sure samples run (#2276)
[33md1096b524f[m Fix fns candy build error on Linux
[33mb0359b5622[m register where kernel (#2245)
[33m5611a528f6[m onnxruntime_perf_test: Add -u option to save optimized model (#2227)
[33m3ecdd985cb[m MNIST Sample Fix (#2259)
[33m0b88eff43a[m add docker file to build onnxruntime with different execution providers
[33m3926ce33f4[m add --parallel to speed up compiling source code
[33m4eda08534f[m make smaller step in Dockerfile
[33mce23d628a5[m fix bug in cmake/onnxruntime_server.cmake
[33mbe7c24247f[m register execution provider when onnxruntime server creating sessions
[33m1fa956fb3f[m Undo integration test skip (#1917)
[33ma2596b706b[m FreeBSD compatibility patch. * Treat the 'amd64' architecture the same way as 'x86_64' * Use thr_self() instead of gettid() on FreeBSD
[33m88c58c19d4[m Improve code readability and performance. (#2257)
[33mce14b07b1c[m Fix the GPU nuget pipeline failure (#2255)
[33mc7599d0705[m subgraph parse error fix (#2254)
[33m6a0ee7eff6[m Fix model path marshalling in csharp, and re-enable the pretrained model tests (#2236)
[33m8be48f47dd[m Added Graph::ReplaceInitializedTensor() function. (#2230)
[33m7b4e6636f8[m Add default params to Env C++ constructor (#2246)
[33m63acd4e89b[m Adjust the nGraph EP to the newest CI test data (#2180)
[33me250e51e65[m clear cache when moving to next channel (#2253)
[33m7494500221[m Fix csharp CXX sample (#2251)
[33mf7b4bc15e1[m Updated documentation for VAD-F (#2248)
[33m20e6a2b6da[m Disable optimizers for OpTester operator unit tests  (#2237)
[33m77d8d6f767[m Remove the OrtApiBase base_ member from OrtApi (#2242)
[33m6a27cb5ad6[m Fixed tensor reference to const data and cleaned up Env API. (#1979)
[33m557243dce9[m Add handling of zero dim to broadcasting and a few other ops (#2217)
[33mfef721c4f2[m Update build instructions. Make samples build and run. (#2244)
[33mbede664af7[m mimalloc allocator (#2071)
[33m90858b732a[m handle Concat-11 (#2240)
[33meb75388cd5[m Minor optimization: don't log all node names if they've all been assigned to a single provider. (#2229)
[33m41d55ea274[m Update the GraphProto for subgraphs when saving the Graph.  (#647)
[33m6fca8b0a94[m Move CXX API global into the header (#2228)
[33m90b6ff927f[m Implement EyeLike Cuda Kernel to improve performance (#2139)
[33mac9425c119[m Update ORTSRV integration test model path (#2225)
[33m4b62241c77[m Update ONNX to 1.6.1 (#2235)
[33m81d901cb60[m remove nuphar scripts (#2233)
[33mab39f7ec99[m Jeffbloo/fix dml rnn failures (#2234)
[33m041a1cab54[m update libmkldnn.so version (#2220)
[33m6ac3e31047[m Avoid printing a misleading message exposed by a previous commit + register float type for Slice cuda op. (#2219)
[33m04b8a4bb34[m Log node placement info in verbose logging mode + turn on verbose mode in onnx_test_runner -vv switch. (#2221)
[33m384c686f40[m Update README and other files with the correct cuda version used for 1.0 release. (#2222)
[33mff2c4a4d7e[m Added more input data types for pad (#2179)
[33mb23cc04f34[m Handle the case when scales is constant but size is 0 (#2218)
[33m856c6cae0a[m Edgchen1/endian utils (#2181)
[33m3507197599[m The Conv+BN fusion is missing a check that the BN node does not have optional outputs. If it does, it cannot be fused with the Conv node. (#2216)
[33mb344670351[m Updated Perf Test readme (#2212)
[33m5eb42f4452[m Add uint8 support for BitShift operator (#2214)
[33m91122a2cf5[m Fix GELU fusion (#2213)
[33maef055ebe8[m Update nuget pipeline to use CentOS6 (#2211)
[33m303a78c301[m Update Python documentation (#2210)
[33me8ec52814f[m Remove some node tests from exclusion (#2168)
[33mcdcca43aa3[m[33m ([m[1;31morigin/cudaResize[m[33m)[m Skip GemmNoTrans_f16 test for CUDA if the hardware does not support fp16
[33md197079473[m quantization script updates (#2208)
[33mb6b44c90ac[m Fix MaxUnpool behaviour when output_shape is provided and doesn't match the inferred shape (#2193)
[33m6699c19010[m Add script to find if optimizer updates are required due to onnx operator updates. (#1957)
[33mdc5efbf5ce[m enable exclude outside for resize op (#2203)
[33m3cda9f717b[m Relax shape inferencing error handling if model uses an old opset (#2199)
[33m02dc3a9dcb[m build break for arm64, adding advapi32.lib (#2206)
[33mfcf50ca081[m Fix nuget mklml pipeline (#2204)
[33m5c86889beb[m Fix linux build issue with debug dump of shapes and data. (#2202)
[33m07e9f500da[m Add back Keras Mask RCNN to CUDA test exclusion (#2201)
[33maae18a3fe3[m Upgrade onehot to OpSet 11 (#2185)
[33m69970d1f2a[m Include the new Privacy.md file in all release packages. (#2200)
[33mcf7ee5f6e8[m Support negative axis in unsqueeze elimination (#2158)
[33m33c639a022[m Slice elimination support for opsets 10 and 11 (#2171)
[33mcff7879d89[m Update C API pipeline to use CentOS 6 (#2198)
[33m0dd781fd57[m Perf tuning doc update with latest API (#2128)
[33ma9f01a5f29[m Fixed node index remapping issue in TensorRT graph partitioning (#2155)
[33m7b18bd563f[m Commit formatting and end of lines (#2161)
[33m763af5d42a[m Remove Keras Mask RCNN from CUDA test exclusion list (#2196)
[33m18b192a45b[m Implement Range Cuda Kernel to improve performance  (#2148)
[33m7efc9bdcc7[m Some condition fixes on nuget pipeline, to get it green (#2195)
[33m836d22cd4c[m Update readme.rst for pypi, change documentation style (#1663)
[33mac3d2ad897[m Implement ConcatFromSequence (#2106)
[33md1159b7008[m Adding platform telemetry (#2109)
[33mb1096424f0[m mkldnn cleanup. add EP_FAIL paths for unsupported mkldnn nodes. (#2182)
[33macec4b446f[m Make CentOS 6 CUDA build and run (#2159)
[33m96b33f4597[m Add support for double to SplitToSequence op to allow test_sequence_model7 to pass. (#2173)
[33mf8c30b8aa9[m Disable DML builds for now until further investigation since the tests are very flaky. (#2194)
[33m6d4682581e[m resize opset11 (#2088)
[33m021073b5e5[m  Update python packaging pipelines (#2167)
[33md15021f42b[m Disable some tests for DML and Android EP pending investigation. (#2187)
[33m35dae992f1[m Fix nuget gpu ci test error (#2164)
[33mecf5ae8b76[m Askhade/disable csharptests (#2172)
[33m62281ff3b9[m Add empty tensor support to the DML EP (#2163)
[33m5eb4e81f80[m move some optimizers to level1 (#1566)
[33m47bc351265[m Fix wrong usage of GetScratchBuffer, like: (#2101)
[33mfc3c168402[m Graph Optimizations Doc (#2050)
[33m13f8b49d58[m Fix kernel registry bug (#2137)
[33m2bf1778a5c[m Fix ORTSRV docker build (#2160)
[33m00e2d1c604[m update (#2140)
[33m0e6ac2961e[m Adding a line beak to BUILD.md (#2156)
[33mf6c82358e9[m Use built-in wstring_convert on Android (#2095)
[33m86af54ded8[m Add roadmap file (#2127)
[33m72110d3508[m Patch for the MKLDNN v1 segfaults (#2145)
[33m4006e29601[m Implement SplitToSequence op. (#2131)
[33m70e7eaf1e8[m Update DML transformers with the new Graph API and re-enable DML in the GPU CI build. (#2147)
[33m95fef56dc8[m MKL-DNN EP (#2149)
[33m6445e7182c[m Disable DML build temporarily until we fix the removal of the IsNodeOutputsInGraphOutputs Graph API. (#2144)
[33mb0f8ec7a7d[m Script for converting BERT model for performance optimization (#2037)
[33mec136ac60f[m Documentation Refresh (#1990)
[33m3fcb4ee7d4[m Refine optimizers (#1407)
[33m485c24b62d[m MKL-DNN 1.0 (#2134)
[33m6857bb8aba[m Fix bug in GatherElements (#2130)
[33m7ef02f14d2[m Add missing test model file for symbolic dimensions (#2123)
[33m4090d0d0de[m Add DirectML Execution Provider (#2057)
[33mb101f1bcee[m Nuphar: Fix a bug in weight layout where read may go out of bound (#2129)
[33m5c2803f2d5[m various fixes for shape inference script (#2124)
[33m95ab5ad39f[m Support non-spatial mode in BatchNormalization (#2092)
[33m2536553136[m use cublasHgemm for Volta GPU (#2074)
[33m8c5db7f973[m use legacy stream mode (#2076)
[33m80d09f0c59[m Allow creation of empty tensors in c# (#1976)
[33m640f71c91b[m Enable Gpu multi-device test for CUDA EP and Trt EP
[33mf93be8af90[m Update nGraph to version 0.26 (#1965)
[33m91db840b6b[m Introduce execution mode enum for clarity and extensibility; Change Python, C and C# APIs accordingly; Removed EnableSequentialExecution, DisableSequentialExecution in favor of the more general SetExecutionModeAPI. (#2098)
[33m5558b80774[m clean up ubuntu docker scripts (#2103)
[33m9363c14d23[m Fix a bug in nuphar settings where existing options cannot be override (#2113)
[33mb829d55320[m Fix invalid logic that ran past end of nodes and double increment. (#2117)
[33meb24617d2e[m Add ability to get symbolic dimension info for graph inputs and outputs. (#2051)
[33m20515363e5[m Add int32 and int64 types for Equal(11) (#2112)
[33m50faab308b[m[33m ([m[1;31morigin/0[m[33m)[m Remove 'Ort' prefix from OrtAddFreeDimensionOverride for consistency. (#2099)
[33me8e33977da[m Ryanunderhill/customop dll (#2002)
[33mc24d7a8a0a[m Update eigen to the latest version (#1910)
[33mbdfff800ea[m Move access to intra-op threadpool into OpKernelContext. (#2091)
[33m368bdfd936[m Update README.md (#2070)
[33m3b335c933f[m Fix issue that TRT not work for device other than device id 0
[33mffb94fd170[m Fix bug with delayed allocation of If and Scan outputs. (#2024)
[33mca1b88c069[m Added support to infer Pad11 (#2085)
[33m8803f6fff4[m C# end to end test fix, and make end to end tests mandatory (#2079)
[33ma314402097[m Downgrade python gpu package to CUDA 10.0 (#2086)
[33maf9dbb70f2[m Introduce a separate check and conditional for AVX512BW build (#2083)
[33m2ba705ed99[m Handle nodes with subgraphs in ORT function handling implementation (#2053)
[33m2d4d0abd36[m Add support for output seq(tensor) in python binding and test framework. Implement SequenceConstruct, SequenceEmpty, SequenceInsert and SequenceErase ops. (#2040)
[33mddbc2086e4[m Add support for opset 11 Clip in optimizers. (#2059)
[33ma41c71cbf2[m check and fix CUDA kernel launch errors in several OPs (#2047)
[33mb4a98aab78[m change MatMulInteger/MatMulInteger16 fallback option (#2064)
[33md186c19c45[m Add opset-11 TopK CPU kernel (#1912)
[33m8fda6593fe[m Update failing tests (#2038)
[33m57e0099425[m MLAS: Implement U8S8 GEMV kernels (#2069)
[33meee9c55030[m C++11 fix for memcpy_transformer_test.cc (#2061)
[33mcefae93305[m Add a test case for linearregressor (#1962)
[33mccaf692ff2[m Run auditwheel for manylinux1 (#2063)
[33mcae571c713[m Add a test for AVX512 compilation before compiling 512 asm (#2055)
[33maf8fe0f980[m Replace make_unique in cuda_utils.cu (#2052)
[33mdb0dd09ded[m Cleanup some aspects of the Initializer class used by optimizers (#2005)
[33ma00ca56ae1[m Remove gcc from manylinux1 docker image (#2048)
[33mb82de794d5[m Weba/update nuphar doc (#2026)
[33mf501b6e234[m pack pyop in nightly build (#2018)
[33me9bed8b23b[m Change python packaging pipeline to use manylinux1 (#2035)
[33m3053af812c[m Fix a crash in deep_cpu_gru_op_test.cc (#2028)
[33m71b389322e[m Implement cuda scatter op. (#1991)
[33ma94c9bd88d[m throw exception using dmlc::LogMessageFatal (#2033)
[33m19b0d0af87[m Enabled bool input type for Equal for op_ver 11 (#2034)
[33m203c2f5b59[m updated reduce_ops for op_ver 11 (#2039)
[33mf13b66768a[m Fix build for gcc 4.8.5. (#2036)
[33mb70fc34fae[m Fix C# end to end tests in NuGet pipeline, failing for missing test data file
[33mb0feaef9de[m Update the C# pretrained model test to include opset9 and 10 models (#2003)
[33m0bd807f3b3[m trt provider status return cleanup (#2032)
[33mb2c1937523[m Add EmbedLayerNormalization and SkipLayerNormalization ops for bert optimization (#2012)
[33m8f7657fa32[m Ignore some gcc warnings (#1996)
[33mea60469af5[m Support seq(tensor), implement 2 sequence ops that use the new type. (#1983)
[33m00e24ae4fe[m refactor Cuda Ops Sum, Max, Min, remove dup code (#1946)
[33m7b39f5090c[m Add Attention op for multi-head self attention in BERT (#1984)
[33m7d2f0c79bd[m Bumped up to op_ver 11 for a bunch of Nuphar Ops (#2025)
[33m3c26ae5b6d[m ThreadPool fix for roialign and CropAndResize (#2020)
[33m4cdb95e436[m Resort to sequential execution if the inter op thread pool ptr is nullptr; (#2023)
[33m544e53e24e[m Update TensorRT to version 6.0.1.5 (#1966)
[33m4bb6385dca[m Weba/merge ngemm (#2021)
[33m0b5aac0a2e[m fix python setup (#2022)
[33me8285a7996[m Added GatherElements to Nuphar (#2016)
[33m1ba76c5f74[m add support for empty version and score route (#1995)
[33ma9e04a29b3[m Ignore a test: ParallelExecutor.StatusPropagation (#2019)
[33m2a2e6e6641[m Handle nullptr for NodeArg.Shape() (#2009)
[33mf528da35f2[m Update ONNX to a newer commit (#2015)
[33mf5a8a23951[m Replace std::regex with re2 bc CentOS std::regex is broken (#2017)
[33me071a1249b[m Android CI (#1600)
[33mbfa1b0e96e[m Fix logger regression (#2011)
[33mb322e072b9[m added the overridableinitializers api (#1977)
[33m19873c70dc[m Implement Cuda Kernel of  Where Op (#1997)
[33ma6bf1d0ad8[m use mlaserf (#1999)
[33mfdbe365c37[m Add BitShift operator (#1981)
[33md5d1719c1f[m[33m ([m[1;31morigin/rashuai/PyOpPipeline2[m[33m)[m Fix integration_tests/test_main.py to have correct exit code (#2010)
[33mace0b2ca1c[m CentOS CI (#1998)
[33m534660bf2c[m Support opset-11 Range CPU kernel (#1980)
[33ma7414287a9[m fix Conv/Add fusion with no bias (#1978)
[33md80f324fd3[m Add Pad test to NGraph specific exclusion list (#2006)
[33me58827fa62[m Add Unique operator. (#1900)
[33m74517bb742[m Support opset-11 GatherND CPU kernel (#1969)
[33m627f853a44[m Downgrade compiler to CentOS 4.8.5 (#1985)
[33m931975e3fe[m Add opset-11 Pad CPU kernel (#1963)
[33m15138908e7[m Yanchen/nuphar/scatter elems (#1992)
[33mc86d17754a[m Dockerfile for CentOS CI build (#1986)
[33ma1f8fe1463[m Add layernorm operator (#1967)
[33m6b6d0aa888[m Fix the NGraph backend test exclusions (#1988)
[33m9959e84906[m Gelu fusion - kernel and transformer (#1746)
[33mb0665262c0[m Fix how failing tests are defined. Merge of old PR didn't detect conflict with some new sections in the script. (#1982)
[33mc79195fb3b[m Add GatherElements CPU kernel (#1735)
[33m9f633c5bd9[m Update Cast op to use precision of 8 when casting floating point numbers to strings (#1210)
[33m9e975f64c3[m Add scatter_nd cpu (#1603)
[33m7c77a01ce7[m OpenVINO dockerfile for ORT (#1892)
[33m103b92889e[m Opset-11 support (negative axis) for reduce ops (#1929)
[33mf9bf546e3c[m python session.run() fallback to CPU/CUDA provider for EP failures. (#1960)
[33m622ea4248d[m fix build instruction (#1970)
[33ma5e134405d[m Support opset-11 Gemm kernels (#1923)
[33m31aff686e0[m Register opset-11 CPU kernel for 'If' op (#1948)
[33md1b1cdc5c4[m Replace GSL with GSL-LITE submodule and fix up refs (#1920)
[33m983ed43f0a[m Fix declarations for opset 9 versions of Gemm, MatMul and BatchNormalization (#1956)
[33mb355193841[m Add Date-time stamp in NuGet package versioning for appropriate ordering of the packages (#1951)
[33maef49d1f22[m Update ops that had strides/dilations documentation updates to default to 1 (#1913)
[33mdf472cbfbd[m quantise: Don't error when initializer graph input is missing (#1872)
[33me361174f78[m Add nuphar python scripts to wheel, and notebook tutorial (#1952)
[33m4c995d3251[m MLAS: add DGEMM support (#1953)
[33m9fc5598b7e[m update nuphar ci llvm version and uncomment unit tests (#1954)
[33m611dd3ea0c[m update ort-tvm version (#1945)
[33me4b8494eaa[m Add a test case for ml_commmon.h (#1947)
[33m02c122d6e4[m   Add OLive in perf tuning section (#1772)
[33m8df3e87b70[m OpSet 11 Update for Neg Axis (9 Ops) (#1893)
[33md370aad80c[m Register CPU kernel for NMS (#1941)
[33m174c142eff[m Clean up code (#1939)
[33m1649374a5c[m Some bug fixes and support for Gather/ScatterElements (#1940)
[33mceaaff0f81[m [OpenVINO-EP] Enabling VAD-F in OpenVINO Execution Provider (#1885)
[33m650fb8754b[m use MLAS for nuphar's pool ops (#1937)
[33mc3ffd1f47d[m added continue on error for the linux cleanup step, to mitigate the build failure. root cause unknown (#1936)
[33m2ecac41614[m update python examples (#1935)
[33ma5a57a49c4[m Changed ConvBase into a class member variable (#1927)
[33m7e22ed41b9[m Fix sample tests (#1926)
[33m09cdbe9d76[m Update test data (#1932)
[33m67be535030[m Fix a typo (#1934)
[33md669fc78c3[m Revert "use MLAS for nuphar's pool ops (#1914)" (#1933)
[33m80ef629c02[m Add CumSum and Round for Opset 11 (#1705)
[33me6ce384402[m add dependency 'cub' as submodule (#1924)
[33m9ed85987e3[m ReduceMax/Min performance improvements on CPU (#1925)
[33mc9b9e79e38[m logging related fixes. (#1930)
[33mbd2d6af9ca[m Filter out info from non-const initializers during shape inferencing  (#1806)
[33m8c809dcc99[m use MLAS for nuphar's pool ops (#1914)
[33md46e023ee4[m Remove toolset=14.11 for CUDA build (#1921)
[33m052339d9dc[m Fix python packaging pipeline (#1922)
[33m76f76251fa[m Rewrite the softmax op (#1911)
[33m4d26f2ce86[m Address two issues: (#1905)
[33m30c7c76552[m fix the output size param's location in the csharp OrtRun interop call (#1903)
[33mbaf75c44e7[m Remove registration of Aten op. (#1908)
[33me769617f75[m extract pooling attributes into a separate class (#1906)
[33m0317e825f1[m onnxruntime_perf_test: Add -y support to control parallel executor #threads (#1902)
[33mdbff8272e7[m Update ONNX to newer commit (#1907)
[33m28a62f7728[m MLAS: add U8S8 MatMul operation (#1895)
[33md3cb2a5572[m Add ScatterElements CPU kernel  (#1796)
[33m034aa80167[m InferenceSession ctor with byte array in C# (#1883)
[33m294db0f978[m Implement Determinant operator. (#1880)
[33maa92daecc5[m Revert "A small improvement to the parallel_for  when task count > thread count (#1839)" (#1901)
[33m686bd36210[m Remove ml_status.h, add StatusCode to pybind exception mappings (#1889)
[33m77176e8678[m Fix broken link to mnist model (#1896)
[33m3d73a69eda[m Stablize Nuphar test (#1894)
[33me288b871ea[m CUDA Equal Greater Less can't support multi-directional broadcast
[33m1a3ded6a7b[m Add C API for free dim override, fix missing API mention in InferenceTest.cs, fix confusing print statement in perf_test. (#1884)
[33m49a4233bf3[m Account for Constant node being versioned in opset-11 (#1875)
[33mca89387817[m Build OnnxRT with Openvino EP on Windows (#1865)
[33m1f4190de3c[m Disable Linux x86 builds as they're not required any more. (#1887)
[33maacfa2af65[m Bump up ONNX to the latest commit (#1868)
[33m9707b39a67[m Duli/clip cuda (#1677)
[33m5781222456[m Ryanunderhill/api interface (#1855)
[33ma7beed798e[m Implement L1 graph transformer for free dimension override (#1825)
[33m561f2c4a9a[m Update pybind (#1876)
[33m6a9ae65f41[m Expose GetOverridableInitializers via Python and C/C++ API (#1878)
[33m429f05138a[m [OpenVINO-EP] Disabled div unit tests for GPU (#1853)
[33m60e5eee52a[m Improve Session Capabilities in ORTServer (#1862)
[33mb43254282f[m Handle bad alloc exception in bfc arena (#1846)
[33ma9ce941579[m Refine threading control options and move inter op thread pool to session state. (#1841)
[33m938b3627b8[m Improve error message if node throws (#1847)
[33m6792e00e1e[m Revert accidental TVM change (#1874)
[33m55f5a52b23[m Support opset-11 DepthToSpace CPU kernel (#1759)
[33m80bda77203[m Fix symbolic shape inference for faster_rcnn, mask_rcnn, yolov3 (#1867)
[33m582a27f546[m remove sudo from the cleanup step for Linux so that we don't need the sudo access for vstsagent build user
[33m6e4e764146[m upgraded CSharp test and sample projects to netcoreapp2.1 (#1869)
[33mc0d953a268[m Support opset-11 Loop CPU kernel (#1816)
[33mdc03ce0278[m New OP: CDist (#1808)
[33md646dc73e4[m OpSet 11 Operator Update: Supporting Neg Axis (#1835)
[33m2f7f83c655[m ROIAlign: add cuda kernel implementation (#1823)
[33m71d414cacb[m update tvm submodule to the latest (#1849)
[33mfc1c9971a3[m Support replacing OrtValue of feed in IOBinding instance (#1819)
[33m166b1f86db[m A small improvement to the parallel_for  when task count > thread count (#1839)
[33m8a9c4cd936[m ROIAlign: fix bilinear interpolate in 'max' mode (#1821)
[33ma1eecd8087[m Fix C# build (#1834)
[33m125900c961[m Enable integration with mimalloc memory allocator (#1673)
[33mbd5451b4ed[m Don't define USE_OPENMP if the compiler doesn't support OpenMP (#1836)
[33maac6021549[m Add NuGet feed publish to nuget pipeline (#1833)
[33m2a21df2309[m Updates to CUDA and TensorRT dockerfiles for v0.5.0 (#1731)
[33m634f554471[m python api's for execution provider registration (#1826)
[33mcf22ea6893[m Upgrade TVM for a fix in tvm::Integer with int64_t input (#1824)
[33ma60283845b[m Update link format and example sections in readme (#1729)
[33ma0ba25f98f[m Fix the issue that it run into alloc failed on multiple cuda device. We have some place hard code the allocator always use device 0. (#1815)
[33m18f7377269[m [Nuphar] improvements in symbolic_shape_infer and model editor (#1787)
[33m8712a523a4[m Bump onnx to latest (#1756)
[33mf8c3442880[m Part 2 of renaming AllocatorInfo to MemoryInfo. (#1804)
[33m397713a2d1[m Add Int64 support to ReduceMin, and Add Double support to Neg op (#1812)
[33m2b8677b210[m Enable Openvino nightly build on edge device (#1684)
[33mfe8915863c[m Implement C API entry points for creating and fetching non-standard types to OrtValue (#1714)
[33md9fa632863[m Add Cuda Kernel for Not operator (#1801)
[33ma9e4de2cea[m Follow up on proto3 compatiblity. (#1799)
[33m3b7f047a49[m General performance testing tooling improvements (#1577)
[33m6586afc8eb[m Refine the output shape calculation to avoid unnecessary re-allocations and vector insert operations. (#1781)
[33m35c5c4d418[m A subgraph may have no inputs (e.g. subgraph in If has no explicit inputs) or value infos (e.g. a subgraph with just an If node in it). (#1083)
[33m206278ca44[m Fix error message in Cast op (#1792)
[33mf9d85d654a[m Add GetDataTransfer() interface in the EP. (#1773)
[33mbd48660592[m Add Cuda Kernel for Less operator (#1790)
[33mb32f24a3f9[m added support for Less(double) (#1722)
[33m0b609d3e68[m Add make_unique implementation for use with C++11. (#1793)
[33m98dbdb1e0b[m Rework the feed/fetch copy setup so that it can be calculated prior to subgraph execution (#1761)
[33m2e242a4089[m Clarify naming of the API involving the RunOptions terminate flag. (#1768)
[33m75f241d02c[m Enhance compatibility with proto3 and replace or abstract has_*() methods. (#1778)
[33m6a5b11756b[m Conditionally export execution provider apis in chsarp (#1724)
[33m071a0c2522[m MLAS: MlasSgemm refactoring (#1749)
[33ma324ad7b96[m MLAS: clang u8u8 GEMM fix
[33mb2a2326a45[m add dequantize and quantize back to contrib ops (#1712)
[33me1a12b1760[m Fix some unnecessary copies of the Node attributes (#1763)
[33m52fe574fed[m Rename OrtAllocatorInfo to OrtMemoryInfo to make it more obvious. (#1758)
[33m58fe5a6bf1[m Enable Nuphar docker build, and reinstate Nuphar tests (#1757)
[33meddb9d78f9[m fixed "unreachable code" warnings on Windows (#1755)
[33m7c5b3a5ecc[m Update coding guidelines to prefer using make_unique for heap allocations (unless where not possible). (#1730)
[33m3d44c55092[m Updated docs related to base images (#1753)
[33m4ed8d4b30e[m Put the initializers at the end of the cluster inputs list (#1751)
[33m9523977cc2[m Added emotion ferplus support (#1752)
[33m94d9161166[m Add nuphar to Linux CI build (#1750)
[33m0f6cf9a335[m enable quantizing specific nodes (#1742)
[33mad7ab3d880[m Enforce shape validation. (#1716)
[33mc9240f4e93[m Implementation of Nuphar execution provider (#881)
[33mf4a6d267c1[m MKL-DNN EP:  control flow fix (#1740)
[33m259863758e[m Fix typo in NMS code
[33mdc9c89546d[m Update the docker file for OpenVINO (#1741)
[33m833e18345d[m Publish perf tool with nightly build (#1728)
[33m810ee0068f[m Fix a issue that CUDA EP fallback to much nodes to CPU for some case which cause huge data copy. If the node's inputs are all initializer, we shouldn't fallback the node to CPU. (#1727)
[33m25d02a33c8[m Fix reading of onnx domain causing one of the automl models to break in 0.5 release. (#1694)
[33me54904e6a3[m add implementation for dynamic quantize linear (#1697)
[33m4b5b037289[m Support 'Bilinear' mode for 2D inputs in Resize and Upsample kernels  (#1679)
[33m0f7c01b49b[m Use exec form of ENTRYPOINT for docker server (#1690)
[33m068b568472[m Add support for int8 x uint8 for MatMulInteger, and int16 x int16 custom op (#1391)
[33m8fc8910a0e[m Allow input used across execution providers as long as they use the same allocator device (#1715)
[33m81ad48080b[m Remove TaskThreadPool (#1713)
[33m73312b8195[m MLAS: Android sgemm kernel build fix (#1710)
[33m14eae293bf[m remove @PCGOTREL x64 usage (#1707)
[33md9cdf4b4ed[m Doc updates (#1522)
[33m8813b79c5b[m make gemmlowp default for arm (#1701)
[33m121d308a33[m Python API naming and other cleanup (#1678)
[33m938200de9b[m fix typo in max batch size error msg. (#1687)
[33m961b14ac4a[m use MLAS for QGEMM in matmulInteger and convInteger (#1692)
[33ma8998b07b5[m treat zero point properly (#1686)
[33mf25847bccd[m More fixes on the NuGet CPU CI pipeline (#1688)
[33m5873bdbb3f[m Share default CPU allocator with Mlas preferred alignment (#1682)
[33m4035fe842e[m Don't create the default allocator every single time. Rename API accordingly. Expose Session/Run log severity levels. (#1615)
[33m7408dec0bf[m Added some mo optimizations to improve performance (#1674)
[33maddf32fa2a[m int64 support for 'where' op (#1666)
[33mc9a4fe2b7b[m Add support of ReduceSum int64 (#1664)
[33md2569d3761[m update clip for opset 11 (#1661)
[33m4de0aa8049[m Optimize kernel index (#1672)
[33ma818740d91[m Support Tensor<bool> and Tensor<Int8> in C# API. Support Tensor<string> as input. Fix a bug in the InferenceSession Run() with RunOptions (#1671)
[33mb53f40a886[m update set fetches for execution with allocation plan. (#1668)
[33m6f70a78e1f[m Fix a few errors in the NuGet pipeline (still broken) (#1656)
[33m97d0a46afc[m nGraph EP Optimizations (#1630)
[33ma68a20e415[m Add details of which node was not able to be placed on an execution provider. (#1665)
[33me652a236b4[m cudnnRNNForwardInferenceEx doesn't support 0 sequence in the bathes
[33md0d82432f3[m Update PyTorch Section for supported onnx version (#1635)
[33m5311c1b2b5[m Check return value form CreateFeedsFetchesManager. (#1653)
[33m7be5695fad[m Remove --whole-archive (#1655)
[33m68d496c7ca[m fix bug on windows where ops were always getting dumped. (#1648)
[33ma1b3c64038[m Fix memory leak in mlas unitest (#1654)
[33m377dcf60ac[m Update onnx test runner documentation (#1651)
[33m224dde7ef1[m Allow user disable multiple threading (#1647)
[33m6f3a835d38[m Update perf tool documentation to reflect the new graph optimization enums. Relax constraint for enable_all. (#1650)
[33m413730365f[m MlasGetMaximumThreadCount: plus 1 to the NumThreads from ORT thread pool (#1646)
[33mbdc694314c[m update MKLML to version which contains fix for thread hang. (#1636)
[33mb963e4b5c2[m Add uint8 Support for NonZero Op (#1614)
[33mbc72c2dba7[m MLAS: add U8U8 MatMul operation (#1644)
[33mfbd790f703[m Add AutoML to 3 main builds. (#1631)
[33m372b657900[m update TRT EP CI's to use latest model.zip (#1637)
[33m6b89c7ad04[m Let mlas use session thread pool (#1609)
[33m44a42a6a98[m Fix parsing initial hidden state in RNN (#1626)
[33mf9834105aa[m removed --gen_doc (#1633)
[33mc9eb13a638[m Copy System.Numerics.Tensors sources from dotnet/corefx into onnxruntime (#1605)
[33m0044be6259[m update onnx to latest commit (#1622)
[33m1835640d94[m Support int64 for ReduceMax (#1625)
[33m17c8fe44e3[m Integrate featurizers (#1573)
[33m7545b795df[m Fix incorrect box offset computation in NMS op (#1624)
[33m0c5d2c998b[m Generate documentation from the registered operator kernels (#1395)
[33m8d12ce45cf[m Use a friendly enum for graph optimization level. (#1586)
[33m24d17f4353[m Fix trtlogger segfault. re-enable SoftPlus unit test for TRT. add docâ€¦ (#1623)
[33m09db1e06b5[m Make changes to pipeline template to include missing headers in tars/zips (#1617)
[33ma6a5acedda[m Cleanup csharp API SessionOptions and RunOptions to be consistent with other APIs (#1570)
[33mbd64ca3019[m Kezhan/execute graph refactoring (#1553)
[33mb405482cfa[m Remove copy of generator in Multinomial (#1611)
[33mb5de1324ef[m Fix log message truncation on Windows when printf formatting is used.` (#1599)
[33ma50a63aa9e[m Serialize optimized onnx model (#1470)
[33m8a559d75ae[m Minor perf improvements. (#1580)
[33ma6a4c4c079[m Fix perf test executable. (#1598)
[33mce3c8f98dd[m Fix for CPU random ops seed narrowing conversion. (#1594)
[33mdf9b1b8ec8[m Include io_win32.h only if builds on windows (#1587)
[33m69baf9e800[m Update nGraph to v0.22.1 (#1582)
[33m7be40b2946[m put all gemmlowp common code in one place (#1590)
[33m59c9d83f35[m add int64 support for less op. (#1604)
[33m0187d876cb[m Implement new LabelEncoder in opset 2 in ML domain (#1393)
[33m6d783e8a07[m Added license files in the base image (#1595)
[33m9b83545f66[m Optimize Fence checking performance (#1593)
[33m1c5b15c2b8[m Remove memory copy between TensorRT and CUDA (#1561)
[33m38d78542c3[m Fix race condition issue in RNN/LSTM/GRU (#1544)
[33m6e430c0526[m A few performance improvements coming out of ssd_mobilenet and ssd_resnet34 analysis (#1578)
[33ma443b013dd[m Remove unneeded C APIs + some refactoring. (#1555)
[33ma93ece2727[m update quatizelinear to process int8 input (#1576)
[33maeb0bcb4a3[m parallel build
[33m9a34089f67[m Add more type support for OneHot op (#1565)
[33m9e926fef1c[m  Add a doc for cmake (#1524)
[33m65ff02fdb0[m   Set job timeout for code coverage pipeline to 120min(#1563)
[33m16087f3133[m update default values for weight quatization (#1564)
[33m7ee8aca1bf[m Avoid downloading test data into C:\ (#1562)
[33m05bbb3065c[m [OpenVINO-EP] Update hardware branding of VAD-R as VAD-M (#1552)
[33mceb8f1c1a2[m Modify the kernel declaration for Shrink op (#1554)
[33m6c271c63ac[m add test cases for commit c019bb9355a511f471e55e7302b26e1d370ed46a (#1556)
[33m8a6bfe00af[m roll back model test update for ngraph provider. (#1551)
[33ma098be12ba[m Register kernel for Greater int64 (#1546)
[33mcb71c69d5e[m checking execution provider logic updated. (#1547)
[33m93cb29f958[m [WIP] NNAPI EP Update (#1540)
[33m9fb8867a24[m Don't create implicit input for outer scope value if there is a subgraph input with the same name. (#1186)
[33m1cf5ebc4c5[m copyfromhost/copytohost are not needed for mkldnn ep (#1532)
[33m624411bb69[m Upload correct ESRP signed package (#1531) (#1534)
[33m3045a5f88b[m Update test data (#1512)
[33m465b30e3ca[m Bug fix for shape of optional output in Dropout op (#1507)
[33m57e2482089[m Fix a bug in Expand cuda op implementation. (#1528)
[33mb599360014[m enable sse4.1 optimizations for gemmlowp (#1529)
[33m28a6f6b11b[m Add back MacOS leg of the Python packaging job (#1523) (#1526)
[33m4d768b3a0f[m Fix inclusion of ARM binary in the release pkg (#1513) (#1521)
[33mfb5d0fc538[m Publish nuget package to azure blob store (#1525)
[33m0b0e32909a[m NCHWc: Enable Conv/Add fusion for stride=2 convolutions (#1518)
[33m14d46ee890[m Init prev_Ht for zero length sequence to avoid valgrind warning. (#1516)
[33mfb7bdd177b[m Profiler-IsEnabled (#1503)
[33ma86486ab7f[m Post binary sizes to dashboard database (#1517)
[33m44ab301586[m More C API changes. (#1519)
[33mcf73f63cb9[m Enable float16 MatMul+Add -> GEMM fusion for performance boost (#1506)
[33mcf5a4b5856[m remove the GetStream from cuda ep. (#1514)
[33md6a30485be[m Rename Tensor.Size() to Tensor.SizeInBytes() (#1502)
[33m6f538dc861[m Support missing optional attribute in Squeeze operator (#1505)
[33m717e764e8e[m Move Class CudnnDropout to cudnn_common.h  (#1492)
[33m8589be69b2[m Organized build instructions (#1504)
[33m33ae28ccb1[m Empty double quota `""` is passed to `find_package(Thread)`, causing a test command `gcc ... "" ...` failed while trying to compile a source file with empty name. (#1508)
[33mbe16b274fc[m Upgrade mklml and set march with official option. (#1469)
[33m1a115ed8cb[m Fix buffer overrun bug in CPU upsample op (#1501)
[33m6df4bc2ebe[m Update scripts to access pipeline variables correctly (#1499)
[33me0829b2b13[m Revert the last changes on tree ensemble classifier (#1498)
[33m4ace393bea[m Fix sign-compare warnings with gcc
[33m6625eecd09[m Temp fix for a crash in fused graph (#1488)
[33ma7223ed801[m Fix android build (#1489)
[33mf052966972[m Remove special casing of "None" as a dim_param (#1482)
[33ma8e3ff47fd[m Add no scale check for resize and upsample (#1484)
[33m258ff06e42[m Revert "publish nuget package to azure blob (#1309)" (#1485)
[33mec3c553501[m NNAPI EP Update (#1483)
[33mc0f927c57c[m docker updated to support openvino R1.1 (#1475)
[33m91d32c9060[m Add docs for the fns candy demo (#1479)
[33ma8e9e1878e[m Reduce artifacts size (#1477)
[33mbb26865758[m Optimize the resize and upsample (#1426)
[33m4aa4ca1502[m Relax shape validation checks. Log a warning instead of returning an error. (#1476)
[33mc5f2f0f15b[m Upgrade version number for ORT in preparation for release (#1468)
[33m1601650161[m publish nuget package to azure blob (#1309)
[33mbe02214a17[m Add a comment to onnxruntime_cxx_inline.h (#1466)
[33mb41f6eef52[m Jignparm/copy cuda extensions (#1462)
[33m818c023535[m Add/correct missing SAL annotations + avoid using unsigned types (except where counts are involved). (#1451)
[33m387d4c72bb[m Strip invalid dim_param and dim_value values out. Allow re-use in event of shape mismatch if buffer is large enough (#1439)
[33mbbe92035c6[m OStreamSink produces interleaved output due to issuing multiple operator<< calls to the underlying stream. (#1465)
[33m768ced703c[m Expose provider factory C API, especially for CUDA users (#1461)
[33m31838fc9ee[m remove const_cast which makes it's not thread safe. (#1463)
[33m6be93f11e5[m build mklml/ngraph without openmp (#1460)
[33m1f13a9f982[m Update to include more samples (#1381)
[33m1fc6f8ee5b[m Support double type for a few ops (#1450)
[33m9d67292c8c[m Document for the C/C++ samples (#1442)
[33m29de25c5a7[m Mention OrtCreateSessionFromArray in C API doc (#1459)
[33ma5f57f43c2[m fix mkldnn linux build break. (#1458)
[33mf938a6e53a[m Add test for LSTM/GRU which has shorter sequence in the middle (#1437)
[33m227734139a[m Fix ORTSRV nightly build (#1440)
[33mac25a2643b[m add VS2019 CMake generator instrs (#1441)
[33m2c05291908[m Jignparm/patch 0001 (#1419)
[33m1a957e0642[m Update C-API packaging pipeline to use CUDa 10 (#1445)
[33m9e4ac8c66a[m remove mkldnn from gpu nuget package (#1443)
[33mdf3a157dd1[m Add noexcept to cxx api (#1448)
[33m995ec04c7b[m add float support for equal op. (#1449)
[33m414a07a85b[m Support Sum opset6 for ONNX 1.2 models (#1447)
[33m9e2fa69785[m Ryanunderhill/c api string arg (#1436)
[33mf0b9a814e5[m fix return of flakey mnist test on gpu. (#1446)
[33m950b863e22[m Update ONNX Runtime Server documents for build and usage. (#1444)
[33me5107fd0cb[m Support MultiD input data for OneHotEncoder op (#1343)
[33m751ee7bb23[m Fix bug in TransformerMemcpy  (#1413)
[33m4cbc6e1cf5[m Validate input shapes. (#1352)
[33m638398e675[m sync onnx to get equal op with float support (#1432)
[33m7717ed71a9[m Fix for issue #1397, disable onnxruntime_PYBIND_EXPORT_OPSCHEMA is --gen_doc is not set up (#1398)
[33me9e777925f[m [OpenVINO-EP] Added support for OpenVINO R1.1 (#1438)
[33mf3c74ec3e9[m Reduce memory footprint of MKL-DNN EP (#1429)
[33m887930e6c2[m inference overheads optimizations (#1392)
[33m07ecd59e8f[m flatten conv2d when input_width==kernel_width (#1435)
[33mc843c393e4[m More code cleanup (#1406)
[33mbbf64c2c45[m Update cgmanifest.json and ThirdPartyNotices.txt for DNNLibrary (#1431)
[33m7a681fb964[m Improve build throughput and enable using the Visual Studio 2019 cmake generator (#1411)
[33m5ee0f185dc[m Add GRPC support to ONNX Runtime Server (#1144)
[33m6c41809655[m Build Shared Library with cuda 10.1 (#1418)
[33m02ded802ab[m cleanup more useless unique_ptr (#1427)
[33m1ff957f96e[m CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED works with CUDNN_RNN_PADDED_â€¦ (#1428)
[33mf720166887[m register gpu data transfer only when there's nvidia gpu related eps. (#1420)
[33mdb61eb4cd7[m Update ONNX_Runtime_Perf_Tuning.md (#1378)
[33mf47f6fd020[m Fix MaxPool when using dilation > 1 plus non-zero padding (#1320)
[33mfbdd905440[m Switch some of the linux pipelines to use the new data download script (#1379)
[33m859a57d781[m Updated Dockerfile for OpenvinoEP (#1362)
[33m93fb62bb3e[m More code cleanup (#1405)
[33ma7b1a8969c[m simply nocontribops-ci and fix build break (#1422)
[33m4383615cf6[m implement conv+clip fusion (#1412)
[33md2cc086bee[m [OpenVINO EP] Minor bug fixes (#1388)
[33m8720fe62e3[m Added missing libraries to Windows wheel (#1415)
[33mc2aa2056b5[m Sample for imagenet and batch prediction (#1372)
[33md38badffdb[m Disable mklml in Windows Build
[33ma203077dcd[m Relax timeout in CI system (#1394)
[33m07a2466d9f[m Use INFO instead of WARNING for an unused graph input. (#1235)
[33mfa4b956f12[m replace onnx:: with ONNX_NAMESPACE:: (#1376)
[33m61b733ce6d[m Update optimizers to be able to utilize a constant initializer from an ancestor graph (#1346)
[33md4ce31ea6d[m cleanup fused conv activation handling (#1403)
[33mc139e3ab33[m Remove a few useless unique_ptrs (#1401)
[33m719e58d831[m Use MLAS to retrieve the CPU preferred tensor buffer alignment (#1377)
[33m5a6f1c10d6[m Add OrtCreateStatus to the symbol list
[33m3bf0e364e2[m Move CopyTensor out of IExecutionProvider interface. (#1268)
[33me580b76305[m Fix ARM64 build + Add NuGet pipeline including ARM binaries (#1335)
[33mbfda9ca1c1[m Make sure submodule urls are up-to-date (#1357)
[33m20f6c84fd2[m Switch to use nvidia-docker2 command format
[33ma7fcd60572[m Add missing 'openvino' option in perftest Usage message (#1367)
[33maba7271ad7[m Fix links (#1371)
[33m823fa3f39c[m Integrate MLAS NCHWc support into ONNX Runtime (#1327)
[33m42c18762f3[m Update the log message for fallback case. (#1370)
[33mc483a1e3c6[m Use simpler GEMM function for MatMul operator (#1365)
[33m57225cd4ee[m Add C++ API test for NuGet package (#1364)
[33m298f30546b[m Fix the random UT failure for RNN/GRU cases which have padded sequencâ€¦ (#1361)
[33m27da857b51[m Fix an SAL annotation in onnxruntime_c_api.h
[33m6b32c77804[m Dockerfiles for TensorRT, CUDA, build from source (#922)
[33m3cae067a9b[m fix non-standard u_int32_t type (#1358)
[33mac6a4afb0f[m Add validation of shape when re-using a buffer in ExecutionFrame (#1356)
[33m58d6ff3f13[m Remove AgentPool setting in CI yaml
[33m3a588860cc[m remove unused math routines (#1354)
[33me9ce51ead4[m Make GetTensorShapeFromTensorShapeProto return TensorShape and not it's internal representation. (#1353)
[33m5b93b02c69[m Issue template update (#1339)
[33mb7ae0d5694[m Fix link (#1351)
[33m93528d9b3c[m Reduce memory footprint of nGraph (#1296)
[33m9f9ff19bdc[m Copy shared library after build ORT Server (#1347)
[33m2714576d0a[m Update ONNX Runtime server doc to reference Jupyter notebook (#1340)
[33ma8ff209ab6[m Refactor Onnx runtime Server to only use public APIs (#1271)
[33me3919d3fce[m Cleanup naming of test input to use .onnx for models. (#1337)
[33m0d204f3f06[m Implementation of TVM codegen library (#888)
[33m9d3b6b3a49[m Disallow overriding initializers if IR version < 4  (#1324)
[33m2a6c69de2b[m Implement the Concat CUDA kernel (#1333)
[33m5e54bbffec[m PyOp documentation Revisions (#1318)
[33m1bf80e30fa[m Ryanunderhill/MNIST sample (#1330)
[33mbf6a9f9c27[m Rashuai/py op example (#1325)
[33mc65489a47f[m Initial PR for NNAPI execution provider (#1220)
[33m98ea675e40[m Fix typo: op[s]iops -> op[t]ions. (#1329)
[33mf67a1629fc[m Documentation reorganization (#1143)
[33m5af2aec3a2[m [OpenVINO-EP] use logging infrastructure to display EP log messages (#1289)
[33m28759e2f6f[m Uninstall the preinstalled cmake in tensorrt image because it's too old (#1316)
[33ma077ac8df5[m Support non-default negative axis value and intuitive data type combination for OneHot op (#1317)
[33m2698edbc98[m enable tests (#1310)
[33m2f698bd54b[m Fix NMS const_cast that modified kernel state creating (#1303)
[33m04d581995d[m Use manylinux2010 image to build linux python wheels (#1282)
[33m0951f53c80[m Update ONNX to d94f99d21a9a0820d58966410ceaf525132f85f1 to pickup change to checker that makes ssd_mobilenet model load 20x faster by avoiding unnecessary copies. (#1307)
[33m59de37af1f[m Add CUDA Expand operator (#1292)
[33ma79ab5ec5b[m Add document for ONNX Runtime latency profiling and JSON file viewing. (#1301)
[33mb8d370029f[m Check that specific inputs are constants in Conv(Add|Mul|BN)Fusion rules (#1270)
[33m089b1ef3bb[m Enable max/average pooling onnx_test_runner tests (#1129)
[33m05a222a961[m enable quantization tests (#1293)
[33m3ebad81abc[m MLAS: NCHWc low-level changes (#1283)
[33ma462328d9d[m Handle case where the Loop 'M' and 'cond' inputs can be considered scalars but the rank doesn't match the subgraph. Use the subgraph rank when creating the MLValue instance for the subgraph input. (#1285)
[33mc0cf2213bc[m Parallelize TreeEnsembleClassifier batch predition (#1276)
[33ma56b294428[m Activate compliance tasks for private builds, and also set a daily scheduler (#1280)
[33ma542769b50[m Fix misleading notion that Flatten op is not supported for opset 10 (#1107)
[33m86dc3b4360[m Fix bug in the transformer that removes unnecessary Cast nodes where it was re-processing removed nodes leading to multiple calls to RemoveNode for the same node. (#1291)
[33mc9d83a52a8[m Implement contrib op CropAndResize (#1277)
[33m06642dbbac[m selectively enable quantization tests for ngraph (#1290)
[33ma571ea74a6[m update onnx (#1287)
[33m01715c0ff1[m update doc "How_To_Update_ONNX_Dev_Notes" (#1288)
[33m92dc5c506d[m move all contrib ops to contrib ops namespace (#1190)
[33m12d70abd29[m Propagate errors from parallel executor (#1262)
[33m671c15a56a[m Treat attribute warning as non-error on cross compiling ARM (#1261)
[33m2bfbcd323a[m fix OrtValue Release condition (#1182)
[33m204bd38d6a[m Add ability to set graph optimization level in onnx_test_runner. (#1275)
[33mc8db2d507e[m Actualy add the C++ headers to the nuget packages (#1267)
[33m4d765dc6d0[m Return error message from status instead of swallowing it. (#1221)
[33m18b7d2b18a[m Add document of ONNXRuntime performance tuning (#1266)
[33m3b71701f91[m Update onnxruntime server docker file with ONNXRUNTIME_VERSION in cmake files (#1259)
[33m3275e44c62[m Change the memory alignment for default cpu provider (#1269)
[33meb833057d2[m Update Model_Test.md (#1264)
[33md3e5474c1d[m Refactor CI pipelines - add GPU NuGet pipelines and ESRP code signing steps (#1247)
[33m766c6b6163[m Add an API for retrieve ORT version (#1263)
[33m5b87f07d80[m enable matmul tests (#1255)
[33mba25ea3643[m Allow building Docker container based on a different git repo. (#1222)
[33mdf68111b98[m Fix a bug that fused func manager in subgraph session state is nullptr (#1251)
[33m23838d9c2a[m Add enable/disable mem pattern api for python and csharp. (#1227)
[33me26e11b9f7[m Quantization tool to support quantization of Conv and MatMul nodes. (#1057)
[33m051ee681a3[m Add a few suggestions to coding guideline (#1238)
[33mc96049fe4a[m Update ONNX version to include new fixes/changes (#1250)
[33m6477d4e756[m Return better output shape for Loop with zero iterations (#1233)
[33ma4148c85a5[m call install_onnx.sh with relative path (#1225)
[33m2d0e5231da[m Fix the build issue with gcc 9.x (#1242)
[33m08ff75930b[m Add pull request template (#1249)
[33maae24f7f9e[m Return right category of error. Use INVALID_ARGUMENT when the input is incorrect. (#1248)
[33m48df19f53d[m perftest: verbose logging if -v is given
[33m8d15ffd8f5[m Initial commit for OpenVINO Execution Provider (#935)
[33mf22d1df04f[m Fix a bug that constant folding doesn't check the returned value of OpKernel::Compute (#1243)
[33m723e30b361[m Refine node selection logic in ShapeToInitializer optimizer (#1219)
[33me84cb7b579[m Revert "Use shared threadpool in LSTM (#1167)"
[33m40ec69191a[m Revert "Let mlas use the session threadpool for gemm functions (#1196)"
[33m13d8558404[m move environment.h/cc from framework to session project/folder. (#1241)
[33md448f39832[m refactor a little bit to not ask every execution provider to give an implementation of getkernalregistry. It's not needed for a runtime-based exp actually. (#1231)
[33m6d7081f33f[m Add PyOp doc and UT (#1200)
[33mf9374217c6[m Add -P flag to perftest & repurpose -x (#1236)
[33m5f21eedcbd[m Script for uploading code coverage data to dashboard (#1209)
[33m08731589c9[m Refactor CI pipelines, and add YAML NuGet package generation pipelines ( for CPU, MKLML, NoContribOps)  (#1223)
[33m2148827d3a[m Implement CUDA kernel for Shrink operator (#1208)
[33m6850e55966[m Fix install_onnx.sh issue (#1201)
[33mfc9a895b46[m Add shape inference logic for Crop (contrib) op (#1157)
[33m6c17567d7b[m Add C++ headers to nuget package (#1218)
[33m065e9dc1ba[m Block size mismatches are expected if sequence length varies or there are NonZero ops. Reduce log severity of message due to that. (#1211)
[33mfa2eea7339[m Use cmath instead of math.h for fabs (#1217)
[33mc1a34a8ba6[m Add ability to dump node input/output (#1202)
[33mbbdd1d658b[m use cudnnRNNForwardInferenceEx for unpacked (padded) layout case (#899)
[33m38963d81eb[m Simplify some CustomOp code (#1206)
[33m87d65389e6[m Add ability to change the logging severity of the default logger. (#1165)
[33m15bcde5053[m Fix a build break in tf_test_session.h (#1205)
[33m6d5ea08936[m Add nsync lib to onnxruntime_mlas_test's deps (#1199)
[33m0b9b429fe1[m CPU GRU and LSTM Ops: Address corner case where output is uninitialized (#1193)
[33m24d6b0f5c4[m MKL-DNN Subgraphs (#1116)
[33m3c3186c761[m Convert more C APIs to return OrtStatus (#1194)
[33m011957995e[m add immutable exclude list (#1181)
[33ma92998c235[m Uncomment ConstantOfShape tests. (#1059)
[33mf72c1501c5[m Optimize concat PrepareForCompute perf by reserve vector size. (#1198)
[33m97dfd5ee21[m Add code coverage (#1192)
[33m280ab9a2d0[m Let mlas use the session threadpool for gemm functions (#1196)
[33mbe36385a8c[m Delete docker/scripts/install_deps_x86.sh and enable onnx tests for x86 (#1191)
[33m6b586bc041[m Avoid warning status in python release pipeline (#1195)
[33m71466fc805[m Fixes two broken links. (#1081)
[33mccab8165eb[m Delete scripts/install_ubuntu_x86.sh (#1189)
[33m32c6c71e86[m Convert Shape operator to initializer (#1159)
[33mcdb27de090[m implement python opeartor (#1045)
[33m8d68098c20[m ConstantOfShape CUDA implementation (#1168)
[33me43e64bf84[m Implement Equal for CUDA. (#1183)
[33md33dbb23b2[m replace onnxmltools by keras-onnx in one example (#1151)
[33md8ac0d64d0[m Make C API capable of defining CUDA custom ops (#1178)
[33mb68bb51dd0[m Change SessionOptions APIs to always return a status (#1171)
[33mb23ab6a06e[m Implementation of sparse tensor (#1121)
[33m7a80770b52[m  Remove filtering from the backend scripts runner (#1169)
[33m1a86421aff[m Create a syslog sink for logging in !Win32 env (#1163)
[33m88ea58a383[m Add double tensor support for Div and Sub (#1172)
[33mc6abb17b8d[m Use shared threadpool in LSTM (#1167)
[33m7cd2d9f3c4[m Change Path_lib to not use Shlwapi.dll if compiled as WINAPI_PARTITION_APP (#1161)
[33m7c4494a0bc[m Fix CUDA thread_local to allow multiple CUDA execution providers (#1149)
[33ma863c67ef8[m Fix error message for legacy opset (6 and lower) models at model load time (#1147)
[33m7316e54153[m re-enable disabled tests on nGraph after fixing remaining subgraph resolve error (#1158)
[33m148141dd5f[m Change Compute function to return a status code instead of an integer. (#1139)
[33mc18de6817b[m Rename MLValue to OrtValue (#1154)
[33mb8a699f70b[m Update MaxPool & AveragePool to support opset 10 (#1141)
[33m10ea77a3d1[m add details aboud adding execution providers in the C api to comments and docs (i.e. need OrtSessionOptionsAppendExecutionProvider_CUDA to get CUDA)
[33m6c9d815de5[m Revert "Remove openmp flag (#1140)" (#1146)
[33m71cbd7679c[m implement cuda slice opset 10 (#1137)
[33ma7137a0f9d[m Remove openmp flag (#1140)
[33m05110a6558[m Adding custom op ConvTransposeWithDynamicPads. (#638)
[33m6c408c3a75[m Simplify ONNX Runtime Server CI build (#1136)
[33mfacdf77f84[m Fix shape inference bug in GatherND contrib op (#1132)
[33m4757933afe[m  Exclude test by onnx version tag (#1073)
[33mf9f6818e4c[m Add comments and organize the C++ header into the main header plus a separate one of the inline methods. (#1130)
[33m66a6f2b0e3[m Add a check for onnxruntime_USE_MKLML AND onnxruntime_USE_OPENMP (#1131)
[33m4e231ad907[m Split binary/symbol and then upload ortsrv nightly build to blob storage (#1120)
[33m2072d34d15[m Fixing broken links for graph transformations in High Level Design doc (#1128)
[33mf51b081ec2[m Revert "fixing clang build failure" (#1055)
[33mef66395060[m remove unnecessary lock and code clean up (#1114)
[33meda4c5cb47[m fix ngraph build (#1124)
[33m8c7e4eb3fb[m Fix run_model api. (#1111)
[33me19bc2d074[m Raise max request size in ORT server (#1119)
[33m1ea3e8633c[m CUDA opset9: Update Cast/MatMul version, add Erf (#1106)
[33m71560843f8[m Add Boost dependency for onnxruntime server. (#1112)
[33m2cf56639ed[m Minor update to NuGet package tests -- allow model download in separate step (#1115)
[33mb9e8aac5f6[m Enable some more tests (#1101)
[33m8808efd9e3[m Add zero size check before setting thread pool so that the zero default value won't cause a failure. (#1109)
[33mf6df36b68b[m Add rewrite rule to handle Relu + Clip (#1105)
[33mb54a292ba2[m Add version and latest commit id to ONNX Runtime Server (#1078)
[33mea29a664cd[m Fix android build when API<23, fix android test, update build doc and pipeline (#884)
[33m2d92b95729[m Enable Unsqueeze elimination (#1104)
[33mee6217972b[m Fix when rewrite rule gets registered to multiple op types; update constness of rule methods; enable dropout elimination (#1098)
[33m9129a652c5[m Ryanunderhill/cxx api2 (#1091)
[33m723d5c782a[m Improve TensorRT GetCapability to Enable More Models (#1012)
[33mb44a30bca7[m CUDA CPU/GPU sync optimization (#1100)
[33mcd9b9e6102[m Accelerate CUDA transpose (#1102)
[33mf4a9ccae99[m Enable nGraph Debug ci test. (#1000)
[33m4a8d75386b[m Clarify/state expected usage of non-const references and 'auto' in coding conventions (#1096)
[33m11243253f2[m Disable mvn model test when contrib ops are disabled since this model uses a contrib op (#1097)
[33mc7d1c007d5[m Fix accidental copy where a reference was fine. (#1090)
[33m0157b6c209[m Enable specifying tests for onnx_backend_test_series.py to run via the command line  (#1099)
[33m7421755198[m Optimize ExecutionFrame to avoid mem re-allocation. (#1085)
[33m055f5af78d[m Remove path change in build.py (#1089)
[33md865d34968[m Fix CUDA crash in fast RCNN model (#1092)
[33m2a07dc2fbf[m Add provider information for kernel in perf test. (#1082)
[33ma6a4fef677[m Support both Scalar tensor and 1-d tensor for Loop iter/cond input (#1052)
[33m376a8240ac[m Add x86 legs to CI builds (#1005)
[33m602028ef19[m Remove tests from exclusion list  (#1077)
[33mbc01f7b16f[m Ensure the Eigen code that is getting #included is licensed under the MPL2 and possibly more permissive licenses (like BSD). (#1076)
[33m9f79ff52ba[m update nuget version (#1075)
[33m9673f3d494[m Jignparm/minor update linux test (#1074)
[33mc7cb0c052d[m Add the onnx inference on AKS (Azure ML) notebook from //build (#1071)
[33mc124f7e81c[m Uncomment mvn test. (#1072)
[33m2e01018e33[m Fixes #1007, base_value in TreeEnsembleClassifier (#1015)
[33mc1b2bd937c[m Add -M and -A arg to onnxruntime_perf_test (#1070)
[33mbf6f19c6b7[m Use auto when possible (#1058)
[33m15561581f9[m Change the INCLUDE path for gemmlowp (#1066)
[33m64aa55eac8[m Re-order InferenceSession::session_state_ in the member declaration (#1068)
[33ma42222f9de[m bump onnx version & fix conv/pool tests (#1067)
[33m3209204ef2[m Uncomment tests. (#1069)
[33m2ad626752a[m Use local ort python package in server model tests (#1027)
[33m32da12491d[m x86 support for C# API (#962)
[33m3a32b0eb99[m Change function kernels to use CustomOp APIs (#1020)
[33m7763f62a09[m fix ngraph build (#1062)
[33m58d9f6a145[m Enable greater/less tests. (#1061)
[33mf90bd234ff[m fix warning in scatter op (#1054)
[33mfd5eb3b351[m Remove dropout nodes during inference (#1018)
[33m2663b9c443[m  Remove unnecessary casts from OrtValue to MLValue(#1051)
[33ma7039601c4[m setting input/output for partitioned function subgraph (#1019)
[33m11069765dc[m Fix C-API sample (causing internal build failure (#1047)
[33m99556b111d[m Make MemPatternPlanner on/off switchable in model weight loading  (#989)
[33m7bce377113[m Fix LTO build failure on ubuntu (#1048)
[33m2324f65a22[m Fixed typo on paragraph 14 (#997)
[33me4225f8234[m Combine OrtValue and MLValue into one type (#1043)
[33m6c65640708[m Update SessionState::GetKernel to just call find() instead of count() and find(). (#1046)
[33m2e19b14e4e[m Fuse elementwise add/multiply into convolution (#1028)
[33md14e65a224[m Finer control over when Python tests are run (#1023)
[33m303f3c1278[m drop GIL before Run to enable multiple python threads to execute in parallel (#1042)
[33md3c0cd24fc[m Change the cpu allocator info used in OptimizerExecutionFrame class (#1036)
[33m5062be612e[m update (#1041)
[33mfc17a8bc08[m Fix MIN and MAX aggregation functions (#1022)
[33m875c4c2f3f[m restore ninja compatibility
[33mec2a8b2386[m delete test/onnx/simple_thread_pool.h
[33me42099480e[m Clean up code (#1033)
[33m46bf6fd1ef[m Replace fabs with std::fabs (#1035)
[33m9029c496b0[m Currently download_test_data in build.py supports only the standalone version of 7-Zip by looking for 7za.exe. Add support for the standard version which has 7z.exe. (#1030)
[33m3ac4826268[m Don't force the install of a specific numpy version unless explicitly requested to when running build.py. Validate that just the minimum version required is available. (#1031)
[33ma63598ac5d[m remove old name tables (#1029)
[33m0f6b3ea575[m Improve the performance of Scatter (#991)
[33mcb25fd4d8a[m Updates ARMv7 Dockerfile to use newer CMake (#1017)
[33mf5dfde33d0[m generalise strerror_r preprocessor switch (#1026)
[33md32d2fbfb7[m Fix svm runtime (replaces #91, #33) (#101)
[33m406770c484[m Enable ONNX Runtime Server Model Tests (#1002)
[33mf7e57a3d16[m Prune containers and images (#1003)
[33m9330a42fae[m Optimize upsample (#1008)
[33m30f87c7526[m Update build instructions based on recent experience. (#1011)
[33m3408494407[m More C++ API improvements and conversions (#998)
[33mc69dff7928[m Implement contrib kernels for Pad (changed interface) and Unique (new ONNX op) (#1006)
[33m49a2928a59[m Support string type for split op (#1014)
[33m31cbb5d33d[m Add support for int32_t in CPU provider's Where op (#1009)
[33m4e5fdd3167[m Removing one of the generate tranform tests (#1010)
[33mc0acb8b6c3[m Allow loading model from in-memory byte-array (#718)
[33maf7090c25f[m Fix server's executor memory leak and add tests (#984)
[33m3fb24f6409[m Improve error messaging based on raised issues (#988)
[33mb08dbd37cb[m Adding Min cuda kernel (#992)
[33m2de1f43a40[m Move EP docs to the docs folder. (#996)
[33ma463f765fc[m Minor fix to pass x86 native build (#994)
[33m2512b0ebeb[m Adding the onnxruntime Dockerfile and instructions (#968)
[33m9a4128efac[m Enable model test in Mac pipeline (#990)
[33mc2b412f7be[m Update the ONNX Runtime Server CI pipeline setup (#986)
[33m47171a076b[m Addressing #956, deprecating old CPU and GPU quickstart dockerfiles (#987)
[33m9263932861[m perf test: fix an index out-of-bound bug (#982)
[33m403fb703a0[m Avoid using transformers that rely on contrib ops in tests (#983)
[33m17690355ed[m Support for building ngraph EP on Windows (#978)
[33m7c514d6fef[m perf test runner: support NCHW->NHWC rotation (#976)
[33m34e8bea487[m Uncomment mod tests and make infra run them (#971)
[33mf2999cf4c2[m move non_max_suppression source code file to object_detection folder (#973)
[33m468de7c8af[m Zhalei/erff (#846)
[33m7e88ca19ee[m Support the option to disable memory arena in MLDNN provider (#970)
[33m8b3c8561ce[m Avoid to call memory allocation if tensor size is 0 (#972)
[33maf4a41fd13[m change impl of CUDA Greater kernel to avoid data corruption. (#969)
[33mf73ce305e9[m C++ wrapper for ABI (#958)
[33m7329e99d52[m Extend IsSupportedOptypeVersionAndDomain to support multiple versionsâ€¦ (#963)
[33mab3355f6b4[m Add Split op CUDA implementation (#964)
[33mf4fd36ee91[m merge rel-0.4.0 into master (#959)
[33m306453f9d6[m fix the link to the script in the doc. fix some error messages (#960)
[33m0b5f06b0fd[m removing LLVM dependency for ubuntu tensor_rt build dockerfiles (#954)
[33m628f4c3aa3[m Remove unnessary logger from GRU (#951)
[33m2c46fff69a[m Enable gen-doc on windows CI (#716)
[33ma02ff0bd06[m Fix ngraph build on Redhat Linux
[33m6550bb5a52[m Add Max Cuda implementation (#950)
[33mfeab3088fb[m Conv(Add|Mul|BN)Fusion as rewrite rules (#863)
[33m0ad940027c[m Use ConstPointerContainer for Node::ImplicitInputDefs() for better consistency with InputDefs() and OutputDefs(). (#894)
[33mdf513c7fe6[m Perform shallow clone for nGraph (#938)
[33m7f14326dab[m nGraph EP documentation (#939)
[33m1978b3c953[m Add an HTTP server for hosting of ONNX models (#806)
[33m6f5c28fd3a[m Accomodate missing optional 'axes' when 'steps' is present in Slice op (#945)
[33m62b340608c[m Execute one task in current thread (#947)
[33m3b0dda0aca[m nGraph: Avoid input and output data copies (#940)
[33m01cd7eaca8[m Bump up onnx version (#936)
[33m2d00c62005[m perf test: support more data types for the TF backend
[33m1b7d1f2645[m Convert constant folding to a transformer (#866)
[33m5bcd77e488[m Use O_TRUNC when saving ONNX models to prevent possible file corruption. (#887)
[33m1658efd953[m Adding Resize CUDA kernel (#869)
[33mded7eeb033[m make builds more robust (#906) (#932)
[33m8d6114038f[m Adding cuda Greater kernel (#933)
[33mf39a8d1f59[m allow users to set graph inputs and outputs fully. (#905)
[33mbb58806872[m Adding versioned dlls to tar/zip packages (#928)
[33m93d798b8ca[m Add locale configuration doc.
[33m71ddba7254[m Disable flaky model test in CUDA build
[33m861b9fda45[m Add link to build within Nuget package (#926)
[33m06e0f7e3e7[m Minor changes to support inclusion of x86 bits in the Nuget packaging pipeline (#916)
[33m7a42ffd15f[m Fix in Slice Elimination (issue #885) (#918)
[33m90544ed766[m bump version number for release (#911)
[33mb5ea3973c4[m nGraph EP disable new quant tests (#920)
[33m3812c881f7[m Readme updates (#912)
[33m38f1f69432[m Add a temporary bypass of artifacts permission issue (#921)
[33m5ed3db914e[m Update custom op help (#914)
[33m0cef3b53df[m Fix scatter assertion offset failure (#913)
[33m8633e9ffda[m Fix a issue that ort will crash if the model has subgraph created by controlflow ops like loop, if, scan. (#917)
[33mda0f9bf9a4[m fixing a bug in resize op (#910)
[33m5e3a266709[m Rashuai/top k0 (#909)
[33m0d2181cf85[m Remove parallelfor for certain ops (#908)
[33m893b48e92a[m Implement Mod operator (#900)
[33mb8eaa88bd4[m Migrate ReverseSequence from contrib op to ONNX opset 10 (#896)
[33m8ed3eed7b5[m Fix ceil_mode not defined for mkldnn pool.cc warning (#907)
[33m80ac858016[m Remove OSes/architectures that we don't build on and have no CI for. (#904)
[33m125a77bec4[m MaxPool+AvgPool - opset 10 [Dilation and ceil_mode] (#873)
[33m3ff97de8da[m Modify roialign to conform with the new onnx spec and take it out from contrib ops. (#901)
[33m73bc09421c[m Fix deadlock in parallel executor (#891)
[33mba3b82648e[m ng ep update1 (#895)
[33m95ac7a2f35[m Implement separators as regex (#857)
[33m1f066d4dc4[m Update onnx (#893)
[33m9d89b23d81[m BatchNorm CPU does not support non-spatial cases - explicitly handle such cases (#890)
[33md0f846aad5[m Tuning GRU performance for batch size >= 2 (#644)
[33m80d69515ed[m C API: catch exceptions in OrtCreateStatus (#821)
[33m11806529d0[m Update test data (#864)
[33m4b4b585f58[m Fix minor bugs in RemoveDuplicateGraphTransformer (#883)
[33mfb3b63438d[m Add python api for graph optimization level (#882)
[33mb0a37477db[m Fix memory corruption issue when CPU->CUDA memcpy is involved (#879)
[33m7d7627b1ac[m Implement IsInf (#871)
[33m0bf12e9dbf[m Add option to enable/disable memory pattern back (#872)
[33me8d722003a[m Move NMS to Onnx domain (#865)
[33m2947e1f9d4[m Fix onehot code arm build break.
[33m2879ee8bd2[m Fix a few warnings (#762)
[33mcb69c65756[m Update MLAS to be able to build standalone again (#874)
[33ma4d7052aeb[m Add nGraph Execution Provider (#832)
[33m7e1edbb9a2[m Fix a build error in onnxruntime/core/common/threadpool.cc
[33md78c340eac[m update onnx (#861)
[33mb2268a6378[m removing specific target framework for c-api test (#860)
[33m07a4ecbddb[m Disable tests for certain models (Cherry pick from 0.3.1) (#842)
[33m780aad8fd0[m Eliminate unused code and data from Linux binaries. (#849)
[33mf09a76d669[m Don't trigger constant folding in subgraphs (#858)
[33m687bac455d[m Convert eigen to a submodule and update it to the latest version
[33mada90086f7[m More efficient rule-based transformer (#815)
[33med0c86cd90[m update onnx to fix matmul shape inference (#847)
[33mf2694ab526[m Enable provider unit tests for TensorRT (#802)
[33mff253631b5[m Enable use of session based threadpool. (#854)
[33mac82c1f483[m enable android build (#715)
[33m951c428ee1[m Simplify the validation in Run call (#850)
[33m38a0c0b0a7[m Fix a bug in perf test runner
[33m2a2de42bb2[m Add docker image clean script (#844)
[33mf1af493b75[m Fix some issue in CUDA GRU and ReduceSum (#845)
[33m9fb7e98c0b[m fix the allocator type in lru of cuda conv algorithm cache. (#848)
[33m41dc3130f5[m no need putting initializers (for constant node) into graph inputs. (#665)
[33m60d71d63b5[m Rashuai/onnx test reduce mem (#790)
[33m3a8b9a4918[m fix trivial size_t warnings (#843)
[33m14d63b5f45[m generate transformers bug fix (#838)
[33m1818835795[m Adding kernels for Resize op (#809)
[33m29ad798c56[m Update license - came up during IP scan (#841)
[33m07e6dfa7ab[m update onnx and enable tests for qlinearconv (#840)
[33m7775551a6f[m Refactor C# and native packaging tests (#825)
[33m54e04cb8bb[m cherry pick PR from 0.3.1 release - enable MSVC static runtime (#837)
[33mb2658b3594[m Cache CUDNN convolution benchmark results in cuda::Conv kernels (#712)
[33mf19d9a4907[m Reduce code size of kernel registration (#833)
[33m049ba2d747[m Exclude tests that fail when contrib ops are disabled. (#835)
[33m4b4a359943[m Exclude unreferenced global data and op doc strings in the opschema object. The first causes a decrease in the binary size by at least 85k. The latter reduces resident memory size. (#823)
[33me999af61b2[m bug fix for shape inference (#834)
[33mfabdbdc130[m Update test retrieval following #828 (#836)
[33m6194a92249[m Fix empty input handling in Tokenizer. (#826)
[33m2c0b8e965e[m Disable test data local cache in Linux CI pipelines
[33me493ba2219[m Fix memory leaks in perf test runner
[33m1936d141a7[m Create nightly build for python packages (#817)
[33mc55e2de593[m Status class optimizations (#824)
[33mb6936e71cb[m Avoid postfix iterator increment in a loop in Slice op and some minor formatting fixes (#820)
[33mccf3566c35[m Register kernel for Dropout (opset 10) for opset compliance  (#813)
[33m6577c3dddf[m Extract debug symbols in a separate file and strip the binary. (#811)
[33m1ff29bfb3d[m Fix x86 calling convention break (#814)
[33m0741baf867[m Update NMS to support max_output_boxes_per_class = 0. NMS will do nothing for this case. (#816)
[33m56749a84ee[m Implement opset v10 changes for Slice operator (#772)
[33m53038b33ed[m BuildFusedKernelDef uses N^2 algorithm verifying input constraints; session load time is huge for fused nodes (#804)
[33md17ae5c093[m MKLML pipeline - update C# and CMake to handle dll dependencies (#810)
[33m24d80b4bda[m Add support for BrainSlice execution provider in Python, if onnxruntime is built with it.
[33m10b113f144[m update onnx to bring in quantized ops (#808)
[33m4bc3d6027d[m Build perf test runner only if onnxruntime_BUILD_SHARED_LIB is ON
[33m3dcf82a1f9[m Disable some flaky tests with CUDA9 (#805)
[33m4e3391ef60[m Refactor NuGet to allow arbitrary PackageId names (e.g. Microsoft.ML.OnnxRuntime.MKLML) (#797)
[33me7090d7202[m move all removed exp ops to contrib ops (#786)
[33m0d4055def4[m Integrate tensorflow into onnxruntime_perf_test tool
[33m9467c5f967[m Update version to 0.3.1  (patch release) (#798)
[33mccd7e801a0[m Fix #612, TfidfVectorizer handles empty matrices as an input (#702)
[33m39951f35f4[m Use template windows-build-tools-setup-steps.yml in win pipelines (#794)
[33md91555f99e[m fix for tensorrt_basic_test not being run. (#792)
[33m5cf72030b2[m Rename misleading test names in ConvTranspose op tests (#788)
[33m571291c323[m build.sh: don't require user to set --use_full_protobuf with --use_tensorrt option. we can set it implicitly. (#780)
[33mcea2a40bf1[m Clean up ExecutionProvider in CSharp (#783)
[33mfda1d0dce9[m Ryanunderhill/ocr custom op (#744)
[33m58ef1306d4[m Copy inputs and outputs directly in InferenceSession::SaveModelMetadata (#777)
[33m3eddb2d61e[m Add optimization level as cmd line arguments (#776)
[33m36ed91ee9f[m CustomRegistry should use composition instead of inheritence
[33m867e961ee8[m Remove mkldnn_sgemm from math_util.cc
[33mffd9071168[m expose graph node name returning non-zero status code (#714)
[33mf4021cf30a[m fix a minor inaccurate error message
[33mef9a4d98cb[m Expose parallel execution option in C# API (#767)
[33m43521c0de7[m update
[33m65c50bb25b[m Create NodeArg for all initializers if IR version is > 3. (#742)
[33m2674d9bd8a[m Fix profiling with C API (#710)
[33mc35d9797d7[m Add unique identifier in function subgraph (#771)
[33m289663fd85[m reformat onnxruntime_c_api.cc
[33m290112d614[m Update onnx (#761)
[33m261a9078a5[m Remove redundant code in ml::write_scores
[33m512cfdd9fe[m Generalize node removal (#743)
[33m7af35ac1e6[m Fix two warnings in graph lib
[33ma196085471[m Add error messages to FunctionImpl::FunctionImpl
[33madc00ab5fc[m ARM32v7 Dockerfile and build instructions update. (#737)
[33m8bc532bfb9[m update onnx and add removed experimental ops to contrib ops (#723)
[33m6e9ed17adc[m Fix a shape inference bug for FusedConv and MaxpoolWithMask (#748)
[33mfc26b24138[m onnx_test_runner: use c api for loading non-tensor test data (#751)
[33m0cd4a9381c[m Handle seqence length == 0 for RNN (#749)
[33m2dbce4ebcf[m csharp api for graph transformers (#741)
[33m06888437dd[m Update onnx-tensorrt submodule to master (#753)
[33macc8ac58d2[m Fix C-API sample. Update Issue template. (#750)
[33mafe3aae29f[m Support empty tensor concats in Concat op (#735)
[33m7d47cd39b6[m Change bind2nd to bind (#747)
[33mb1115f49cd[m Update NMS to compatible with both TF & Pytoch models (#636)
[33mf4b47ad9f6[m Move call to log and fmaxf outside of inner loop. (#745)
[33m40839f1f84[m Enable multiple session runs for TensorRT (#724)
[33m6df54f0285[m Eable some onnx test cases (#700)
[33m7f96c7f028[m Use forward_inference to speed up convolutions with MKLDNN (#731)
[33me6a2bdfacd[m Handle incorrect perm data in Transpose op gracefully  (#739)
[33m667fa39551[m fixing spacing for TensorRT documentation (#645)
[33m73fc91dc59[m Fix preFast native rules warnings (#682)
[33mb9b6e3abcb[m ReverseSequence contrib op (#728)
[33m333171f602[m Bug fix for Range op (#734)
[33me643ce0e08[m Fix inconsistent dimension data type in C-API (#726)
[33m165657ee1a[m Refactor the /Qspectre cmake code (#736)
[33m6cbf5bcb04[m [Minor] Enable pybind in mac build (#732)
[33m36f5d008de[m Add /Qspectre compiler flags (#671)
[33mf6a77617c1[m update test data
[33mdeaea702ff[m Bump up cmake_minimum_required to 3.13 (#722)
[33mf299104a19[m Enable constant folding in L1 transformers (#720)
[33mfb2a44f642[m Remove header_files_test.cc
[33mc35b605b8d[m Support updated opschema with functionbody (#640)
[33m83ae641425[m add documentation for custom ops (#708)
[33m77b981824a[m fix graph transformers and refactor tests (#696)
[33ma872ba7894[m Convert Unsqueeze elimination to rewrite rule + improvements in graph utils and graph transformer utils (#670)
[33ma28b42a42c[m Fix path_lib.h for Mac and refine #include in InferenceSesssion.h (#711)
[33mbcf1ce94be[m Provide an option to disable contrib ops. (#707)
[33m39fb68b761[m Refactor InferenceSession class (#654)
[33mc8f1da28c4[m tile op: make implementation type-agnostic (and support a few more types) (#688)
[33m6497f0c133[m build python only when onnxruntime_BUILD_UNIT_TESTS is ON (#694)
[33m21dacdd4d6[m fix epilogue code (#695)
[33m179afe1594[m Remove onnxruntime_USE_PREBUILT_PB (#692)
[33ma26696fb0e[m Enable LTO on Linux
[33m12ecd77ffb[m Update README.md (#686)
[33maf389593be[m Add Windows CI pipeline for TensorRT (#687)
[33m21dde6fd16[m Clang build failure in test (#683)
[33m8d782582f4[m fix build_wheel option (#684)
[33m25f45cb2db[m Introduce Rowwise/Colwise Sum to math util (#656)
[33m600dc9ecc5[m Remove licenseurl and add licensefile, to fix issue 664 (#669)
[33m9b0d56dbed[m Fix a warning in GraphTransformerManager
[33mcd52431b8f[m Custom op interface to the C API to remove shared library dependency (#668)
[33m6c40aed95c[m Rashuai/build x86 (#676)
[33m5d452b3029[m Use protobuf-lite to reduce onnxruntime.dll size. (#639)
[33ma624e1091e[m fixing clang build failure
[33m0995e853fa[m Rashuai/unify version (#653)
[33ma3499083da[m Add iterator traits aliases to ConstPointerContainer::ConstIterator (#634)
[33m2f1c3028b7[m add capi to set graph optimization level (#657)
[33m819457dd45[m Added netframework test (#658)
[33m17af8e9ba7[m Add subgraph check/update to node removal logic. Fix a few minor issues with Graph that came up during testing of the changes. (#651)
[33mc366647262[m Add missing probit function for treeregressor (#619)
[33m9e323901b2[m Upgrade mkldnn to 0.18 (#650)
[33m1aa24cbbf3[m executable size reduction: cleaned up slice op to get savings (#621)
[33m3f52de07c7[m Add missing include to status.h
[33m4cc7121368[m Fixes #626, remove posix option for regular expression in Tokenizer operator (#627)
[33mda9af592d9[m Remove OrtAppendCustomOpLibPath (#642)
[33m481eb971ec[m graph transformers update (#608)
[33m541b3149dd[m Minor fix to disallow an execution provider registering a nullptr.  This matches the expected behavior of GetKernelRegistriesByProviderType to not return any nullptrs. (#646)
[33m971058fc38[m Avoid copy of pre-existing value to subgraph output (#637)
[33m14d9a2bdc7[m Remove an unnecessary check in GetDirNameFromFilePath function (#616)
[33m8faccfcd92[m Remove parallel logic for backward and forward GPU (#641)
[33m4c2b1c3018[m Rework Transpose as a generic type agnostic implementation (#561)
[33m4bd8463228[m Update docs (#633)
[33mbdc2bbb207[m Build details for TensorRT execution provider. (#632)
[33ma362c3bbdf[m Fix node def replacement by checking memory location (#623)
[33m5c09aa863c[m python binding test updates for TensorRT (#635)
[33m639aa6d97a[m Update run_dockerbuild.sh (#631)
[33m71b6445967[m Large Model: Support offset (#615)
[33me8b0ae8923[m Trt execution provider (#382)
[33m37f7ed156e[m renaming utils namespace related to graph operations to graph_utils (#618)
[33mfba98bb4de[m Rework tokenexp to match tokens instead of separators. (#617)
[33m2ae83c580c[m Constant folding (#168)
[33mab734ec5a6[m Fix a bug in ExternalDataInfo
[33mcfb08c4848[m TopK op: Promote onnx to a newer commit and handle changed TopK spec for opset 10 (#611)
[33m7dd9bc4d78[m Restore changes removed by PR #571 (numpy version) (#603)
[33meab1f5463c[m Disable benign warning that shows up in Windows cross-compiled ARM builds (#607)
[33m5bb842538d[m sync onnx and maintain old version history for removed exp ops (#588)
[33mc6d39b60cd[m remove OnnxTransformer (#554)
[33mbf43ac41aa[m fix version number for tarball packages (#600)
[33mb452151baf[m Rashuai/restore yml2 (#604)
[33m3f507fa9f8[m fix a shape inference bug. (#605)
[33mde9f1ff1ff[m Add new C function OrtOnnxTypeFromTypeInfo (#585)
[33mf048fc5fb0[m cross compile x86 linux (#562)
[33m3ef273b84b[m Support memory mapping on Linux
[33m7218be4f1f[m support protoc version < 3.2.0 (#594)
[33m59cfafbb9e[m Restore tolerance fix and make test_gru_seq_length_cpu run (#595)
[33m02ad7daa8b[m Add component detection (#592)
[33m93bbb42e75[m Change the way of linking dl lib
[33mb183df7143[m Remove InsertFusedRules from CPUExecutionProvider (#573)
[33m867eda5262[m Support Windows cross-compiling for ARM(64) in ORT build scripts (#549)
[33m6136efc0c0[m Promote to ONNX commit that has StringNormalizer (#499)
[33m530748ad5c[m Fix the broken link.
[33md23edeb8c5[m Fix a warning in env.cc (#568)
[33mb7298a6deb[m Add python script to export subgraphs from Scan/Loop/If nodes in an ONNX model. (#583)
[33mfb6f091073[m Create derived class from onnx BackendTest so we can use the same tolerance values as in onnx_test_runner. Enable GRU test that was failing. (#584)
[33mb742c3a965[m Fix for Scan 8 bug where the sequence length was > 2 (#580)
[33mc785fe26d3[m Update CreateExecutionProviderFactory_BrainSlice() definition.
[33m44cb4c4f74[m Handle x86_64 -fPIC relocations correctly (#566)
[33m9fa7b570da[m Fix publishing of Linux and MacOSX artifacts. (#579)
[33m1180c60035[m Add link to custom ops (#576)
[33m51273b48f6[m Use cuda9 1 in c api packaging (#571)
[33m3cd448e05a[m Fix: IExecutionProvider::GetCapability returns redundant subgraphs
[33me272feb60d[m Readme updates (#570)
[33ma79c09388f[m Fix GPu package testing for CAPI (#569)
[33md40a9f894f[m Enable Component Detection (#559)
[33mb4ffcf8258[m Fixes #31, add option numpy_version, skip_keras_test to the parser of build.py, add flag PRIVATE for the python bindings (#544)
[33m4635bcc624[m Updating C_API end-to-end test and user samples (#564)
[33mb68079fe5d[m Support int32_t for Split op (#563)
[33maf9c554dd3[m Ryanunderhill/custom op (#550)
[33m0b143d0703[m Fix parentheses and commas (#560)
[33mb247fced3b[m Linux and MacOS C api packaging (#555)
[33m98a9c0e715[m Fix json error (#557)
[33m0e65bfe7ae[m Remove caching from InferenceSession::Run (#547)
[33m54eeb7394a[m Implement Scatter. (#523)
[33mcf41f76d79[m Fix some warnings (#551)
[33m714d4100bd[m Update documentation to include openmp dependency. (#545)
[33m8e0fff7b8d[m Support large model(>2GB) (#520)
[33ma4a459477a[m Windows packaging build pipeline for C-api packages (CPU and GPU) (#535)
[33m3a2f6c6964[m Update cgmanifest and TPN  (#529)
[33m94bd74190a[m Revert to cuda 9.1 for package release (#546)
[33m47a9abd212[m minor change for validating input types (#532)
[33mbfa21c0b9f[m Re-enable the tests disabled during C API renaming
[33m1288a8caed[m Initial check-in to support non-tensor (sequence/map) types (#527)
[33m1d3fcc525a[m deps: update onnx to a newer commit and update test exclusions (#542)
[33m30be4c1ef8[m Fix a bug in test data (#539)
[33mf5dfbba655[m Clarify numpy version requirement (#537)
[33m7aba5fe523[m perf_test_runner: support specifying thread number (#538)
[33m4c684a133a[m bump up version to 0.3.0 (#536)
[33m8a59287c46[m  Create OptimizerExecutionFrame for graph optimization (#526)
[33m290c472839[m remove mkldnn from linux packages (#533)
[33ma697e0b710[m Implement Shrink operator (#485)
[33m9fb80ea927[m Fix cast optimizer (#524)
[33m2e6ec07d9a[m Check some return status values that were ignored and add logging of any error messages in onnxruntime_perf_test. (#525)
[33m6c7099a18e[m Break dependency on SessionState for ExecutionFrame and OpKernelContext so optimizers can execute a node with a minimal setup (#498)
[33mdfa21af302[m Update C API to allow user to enable caching of feeds and fetches info across calls to Run (#522)
[33m96d5211869[m Update cgmanifest (#502)
[33m6e79c93dd2[m replaced onnx namespace with ONNX_NAMESPACE (#519)
[33mbdf72ad5e3[m Update C-API with working example (#503)
[33m0b841c3bd4[m Fix various issues with murmurhash. (#514)
[33mf9bae489bd[m cleanup extra header from c api and sanitize C api test (#517)
[33m668fcf22d8[m Update InferenceTestCapi.cpp (#516)
[33m2f1e883c71[m Don't use mkldnn and tvm for release pkgs. (#511)
[33m4c7fd49949[m Add a few benchmarks (#512)
[33m5171e8b129[m Make IExecutionProvider::Type return const std::string& instead of a new string. (#506)
[33md6a70470dd[m Update build.md to say CUDA 10 should work with any VS2017 version. (#507)
[33m9d14cbdb1a[m Throw friendly error message when Linux distribution has libc version < 2.23 (#493)
[33m62bbe8de40[m fix downcast errors in 32-bit build (#501)
[33mc2b8ac0154[m MatMul op: Support new integer types and double type as part of opset V9 compliance (#482)
[33mb69c834c06[m Optimize graph partition
[33m0e687a2c90[m Implement tokenex regular expression matching and add tests. (#480)
[33mb02c1d80d4[m Fix an SAL annotation in the C API
[33mfc7185f060[m Various optimizations to reduce the setup and device copying cost outside of the call to ExecuteGraph. (#470)
[33m4408342f0b[m Fix a issue for cuda reduce Max Min (#474)
[33m9bc6503463[m Support non-tensor types in the C API. (#489)
[33mda1cf8fff0[m Remove exclusions for Sign operator model tests. (#490)
[33m54acfc0432[m TPN update and link fix (#483)
[33mee702bd288[m patched the logic of removing the ._*.onnx file, in case it comes in position other than the first in listdir (#484)
[33m1f1dcc352f[m Add Native C API test from NuGet (#481)
[33m2a9a924c23[m Add float16 support for fusion (#476)
[33m9add0e9a9f[m random generator to continue generate random numbers (#477)
[33mf6ffa1280a[m Updated endtoendtests to not copy model files (#479)
[33m62532ec1b0[m Minor cleanup in TopK operator (#478)
[33mf2510127a2[m Optimize pad performance (#472)
[33m0a23d23266[m Initial implementation of Where op. (#412)
[33md05b74b1b7[m Delete Tensor::ShallowCopy
[33mfc90a9b2fc[m allocator refactor (#467)
[33m0c4fef9ac2[m Jignparm/removemodelcopies (#471)
[33mec8ac04f30[m Update cast op to support string <-> numeric (#379)
[33mf72474c24b[m Updated System requirements in README.md (#466)
[33me7c1b774e8[m Move build dependencies like setuptools wheel numpy into docker image (#468)
[33m892c0653cc[m TopK Op: Include support for valid `axis` attribute in implementation  (#461)
[33mfdd71574d6[m misc: Fix comment in op_node_proto_helper (#460)
[33m88949485ff[m removed MklDnn dependency from C# (#455)
[33me57b5116d6[m BrainSlice parameter represents the IP.  Update parameter name to match
[33maac711ab2f[m Implement Sign operator. (#456)
[33m360fc32db4[m compute forward and backward parallel for MLAS and not use_openmp (#457)
[33m5d00b8b375[m Fix docker gpu test for csharp package cuda 9.1 and 10 (#432)
[33m7b37dc6105[m Enable USE_MKLML_FOR_BLAS (#387)
[33mdb0fde9add[m Make USE_MLAS macro conditional on cmake flag for consistency with other options and make it ON by default. It was already enabled by default today. (#454)
[33m4cdb0cbf6e[m A tiny fix in KernelCreateInfo
[33mfb04940ad3[m Initial implementation of NonZero op. (#437)
[33m7c70d9349a[m Fix a bug in execution_provider.cc
[33m657d46fb3c[m Output empty shape scalar for empty input. (#451)
[33mf20258e9ed[m Delete dead code
[33m8a8d1b0cea[m Fix MacOS shared library build (#447)
[33mf14b258a5c[m Fix float 16 type support for some CUDA kernels (#436)
[33m5866e853c4[m Add dev notes
[33m7cd393d697[m Fix 3.7 build; Add cuda version in README (#427)
[33mb29c6e48b4[m The files of graph_transformer.h and rewrite_rule.h has been moved. (#446)
[33m405c4bacbc[m Fix a bug in SessionState
[33mc932ab8e99[m Implement ConstantOfShape (#443)
[33m4038db14e2[m update trt due to removing reference counting API changes (#444)
[33m851e291f22[m Make OpKernelInfo not depend on SessionState. (#442)
[33m9faac70dae[m Delete Tensor's copy constructor
[33md35409f58e[m Support uint8 datatype for Upsample op in CPU and CUDA providers (#440)
[33m2062c49033[m Rashuai/fix dilation (#415)
[33m696ab8a194[m Create a separate component for graph optimization. (#421)
[33m737700f94f[m fixed the win10 runtime paths to win (#435)
[33m214c1b88e3[m fix brainslice break
[33m3b061d60a9[m Updating new protobuf generated C# file (#430)
[33m5cac965471[m Copy input tensors (#395)
[33mebfed60741[m Resync protobuf def
[33mf85cd520c0[m Recurse into subgraphs in transformers and session initialization (#368)
[33m93bcd9beb6[m Type and Shape inference for QuantizeLinear and DeQuantizeLinear Ops (#408)
[33m60cdb79204[m Enable tests for EyeLike and enable datatypes present in tests (#424)
[33m9f0298261d[m Fix a build warning in onnxruntime python extension (#416)
[33md369ff945d[m Re-enable python tests (#419)
[33m011a784eaa[m Merge back from rel-0.2.1 (#422)
[33m6ae6853519[m Update test data md5
[33mefb72540be[m Separate out constant node index information from ExecutionFrame (#410)
[33mfb7be27096[m Update test dataset
[33m266201de0a[m limit thread pool size when running mkldnn model tests
[33m70985fa803[m Update BUILD.md
[33m91ffb980a2[m Addl TPN updates (#403)
[33mc76725da2d[m Slice elimination rewrite rule; re-implementation of identity elimination using new Graph API (#87)
[33m59955da188[m Add test case for pre-allocated output
[33m925b3f059c[m Update cgmanifest.json
[33mea94cbf14b[m Docker containers for CPU and GPU quickstart (#332)
[33m583631adf5[m Add cgmanifest.json
[33m6fc48c60de[m Add win-ci-pipeline-cg.yml
[33m20ef8b43a6[m Change GEMM kernels to natively handle broader range of row counts (#406)
[33md75bdc5194[m updated C# API doc (#405)
[33m09806625cf[m Rename OrtInitialize to OrtCreateEnv in preparation for future. (#399)
[33m2f73d7abf8[m compile with GL/LTCG (#391)
[33mf13b9ac429[m Refine word_conv_embedding (#388)
[33m439dbbada9[m Adds OnnxTransformer to plug onnxruntime in sckit-learn's pipeline (#389)
[33m7c21c15732[m Jignparm/addcsharptestgpu (#393)
[33m68881fadcd[m Delay load cudart64 for cpu execution
[33md4d3270891[m Update transpose logic for Scan 9 outputs so it's the inverse of the input transpose logic. (#401)
[33mb194b7df0d[m Add the ability to use a custom allocator for fetches to avoid unnecessary copies in control flow operators. (#377)
[33mb194d79dfb[m Third party attribution updates (#398)
[33m8f215b44e0[m Refactor InferenceSession::Impl::Load code to remove duplication. (#248)
[33mb92bc99861[m QLinearConv (#370)
[33m5ef4c90f1d[m Make the return  namedonnxvalue objects disposable in C# API (#392)
[33m571e1e9a6c[m Jignparm/updateversion 2.0 (#394)
[33m7c0a6f3d9c[m CI: Enable C# tests
[33m8e03560dbb[m Fix -e option for runtest-docker.sh (#385)
[33md875ab2acd[m C API - Remove reference counting (#344)
[33m6349114583[m Revert "Rashuai/link with ltcg (#378)" (#383)
[33mab730cc58d[m passed the OnnxRuntimeBuildDirectory to the docker for the dotnet linux test (#381)
[33mccca1e9402[m Update property file for Nuget Linux package (#369)
[33mf53cc032db[m Rashuai/link with ltcg (#378)
[33m373177ddd3[m gemm with empty input (#350)
[33mf922d427d3[m Improve VerifyKernelDef() performance when op has many inputs/outputs/type constraints. (#347)
[33m644c13050b[m Handle negative axes for reduce ops (#365)
[33mf94fdad861[m Fixes on the dotnet end-to-end test scripts to get it running on linux (#376)
[33m829b2a5e81[m Promote TfIdfvectorizer to ONNX ver 9 (#373)
[33m89f643f04b[m add new types to shape op (#362)
[33m61bbf4bfcc[m Fix redundant population of output_indices_ in the execution frame and reserve memory for it in advance. (#375)
[33m82b4ec3d42[m Fix a bug in KernelRegistry::Register function
[33mbca8daf762[m Update ONNX. Implement Scan 9 changes (#366)
[33m8ea7197b82[m trt (#361)
[33m904d7c6ec8[m Add --cuda_version option to enable manually specifying cuda version
[33md040b452cb[m Expand: add additional supported types. (#364)
[33mea816615eb[m remove use_tvm from base script. Put it in yaml configuration (#363)
[33m647cc2dced[m use gemm to replace matmul + add (#234)
[33m8b55596dfe[m The CUDA compiler doesn't support gsl::suppress so disable when __NVCC__ is defined. (#358)
[33mc87929e949[m Use nsync for implementing condition variable
[33m1653ba9fcc[m Optimizing Upsample op (#352)
[33m22337bb641[m fix linaro build (#355)
[33m0a21226b09[m comment out 16-bit float models in C# (#351)
[33m6f30bec040[m Implement MLAS convolution+activation fusion (#354)
[33m6831fc16ed[m Kezhan/kernel registry refine (#346)
[33m948cc03490[m upgrade onnx
[33m21713b7a41[m Reduce test parallelism for cuda model tests
[33m36c62d84b4[m remove ConstantLike OP
[33m9f3ae4279f[m Handle copy to/from non-CPU devices across control flow nodes (#339)
[33mc2704b5afb[m cleanup code (#343)
[33mb3f0d0b659[m added unit test to guard against native API changes (#337)
[33m790cda6ea7[m Fix the issue which causes wrong output. (#342)
[33m5d0e024284[m Askhade/add quantized matmul (#295)
[33m34afa0a598[m Delete onnxruntime_exec
[33md23f01dcd9[m Suppress warnings for gemmlowp
[33m95b8941e9d[m Fix Seg fault when repeats input contain a 0 (#336)
[33mf678f58750[m Revert to ignoring optional subgraph inputs (#306)
[33m6225d5fe1e[m Update test data (#334)
[33m492d9fd6cc[m Use Eigen ThreadPool in OnnxRuntime (#323)
[33m139abda393[m convinteger implementation based on gemmlowp (#294)
[33m835b511fa8[m cuda fix to unblock the tf model tests (#333)
[33m7977871740[m Split build pipeline
[33m7e3923b9b3[m Fix for non-wide characters in strings for linux - for c#-native interop (#326)
[33m779123cf55[m Upsample opset 9 cuda implementation (#330)
[33m0efc48a11a[m Install dotnet sdk on linux ci (#320)
[33m677918cd9a[m Added generation of C# project properties file containing actual build directory.
[33mc955cd8278[m changed csharp runtime folder name to win from win10
[33m25c1e68988[m Fix: roi_pool operator implementation error about FLT_MIN
[33mef5679949a[m Fix a c# build issue when mkldnn is not enabled (#321)
[33m3b83f062fc[m remove delayload from mkldnn (#276)
[33m260639c327[m Add missing EXCLUDE_FROM_ALL keyword to nsync submodule
[33m2d067ec65c[m Update with link for C# GPU Nuget package
[33m4735bb1ccb[m Add onnx protobuf format that supports large model (#313)
[33m05b9440fce[m mkldnn:Conv weight optimization (#256)
[33m8c40313e28[m Update documentation to reflect the latest changes (#311)
[33m7641ee9a2b[m suppress a warning.
[33md22429c5b2[m Update compare_mlvalue for tests (#290)
[33m02962ce9d8[m Update ABI.md (#299)
[33m02852a0881[m Remove OperatorParser tool (#279)
[33m223773d278[m Implement ROI Align for object detection. (#308)
[33m6b3044ddd3[m Update AddingExecutionProvider.md
[33mfa0ea9a273[m implement dynamic slice cuda (#286)
[33m98a92547bf[m Ryanunderhill/c api 8 (#297)
[33m751eb60819[m Fix a build issue in onnxruntime_unittests.cmake (#307)
[33md342147255[m Add test for truncated sequence inference (#99)
[33m34bcc92554[m Added test data URL and checksum arguments to build.py. (#302)
[33m55433abecb[m Enable build_shared_lib if build_csharp
[33m84be07114b[m Disable nsync test
[33m22b5bfdf35[m update label for build badges (#301)
[33me318c7317b[m update
[33m8cfe8d33a3[m Add nsync (#292)
[33m57421504b1[m Add tensorflow license (#296)
[33m31bbb4598e[m Enable tvm in CI builds. (#285)
[33m386b60e35a[m update gemmlowp which carries a windows build break fix. (#291)
[33m4929ddde43[m update tvm submodule (#287)
[33m059cfdc13a[m Opset 9 Scan implementation (#274)
[33m5e113661a9[m Build system upgrades (#281)
[33m85ec13f58d[m fix tvm break (#282)
[33mec2cf59baa[m Enable building python37 packages (#283)
[33mde383d93be[m Fix inconsistency in enum names in the C API (#277)
[33m251d4bbb23[m adjust the quantization ops' definitions (#278)
[33m8a7b6761de[m changed nativeLib name from onnxruntime.dll to onnxruntime, for cross platform (#275)
[33m75934af896[m have Im2ColNd support all types and allow customized padding value. (#273)
[33m058803086d[m Implement N-gram (#180)
[33m8fba324678[m Hyperbolic inv ops (#272)
[33md0fa974976[m interface change to code-generated kernels (#192)
[33m5b6f1823af[m Use CUDA libraries found by CMake. (#190)
[33mfc76076e29[m Rashuai/dynamic slice refactored (#264)
[33mbd2ace7619[m Tweak linker flags to minimize the binary size. (#270)
[33me7e90c0322[m Implement OneHot op.  (#213)
[33mbddeb3d001[m Fix "invalid escape" issue when eigen_SOURCE_PATH contains "\". (#258)
[33meb67eadbc6[m add initializer for sub-graph. (#269)
[33m8f3a492682[m Remove static linked cuda libs (#239)
[33me2746513ab[m Avoid to run profiling code completely if there is no need (#245)
[33m1e9be01a49[m Fix a bug in Conv+Activation fusion (#236)
[33m4f49a4ab1b[m Maxpool_With_Mask (#267)
[33mb508835e7a[m Update CUDA Gemm to opset 9 (#266)
[33m126c1fd3df[m do replacement based on node arg usage, instead of provider type (#263)
[33m6a090985fb[m More C API changes (#259)
[33m29d03ffb08[m Add end-to-end test to run on the nuget package (#252)
[33m8380e56409[m Optimizing Gather op. (#262)
[33m928acc32f1[m Minor formatting proposals
[33m698ebf13a1[m Add a missing header (#243)
[33m79c623bece[m Add more test models
[33mf3df7e5d32[m nullptr
[33mb93eba17c7[m mkldnn: relu, sum and batch norm (#238)
[33m3875511f9e[m Fix inefficiencies in the mkldnn kernels. Some of these were (unfortunately) getting replicated in the new kernels. (#241)
[33m7af1887b33[m Introduce basic BFloat16 runtime support (#235)
[33m4e74ffba91[m Add word conv embedding custom op (#229)
[33ma37887cfa1[m More intuitive ordering to the API functions (#233)
[33mc453b48b71[m update kernel memory type interface (#225)
[33ma43382e390[m Jignparm/csharp gpu (#221)
[33ma19b624302[m MaxUnpool Operator - CPU Implementation (#177)
[33meb867be331[m update mkldnn to 0.17.2 (#231)
[33mabce6041c1[m Print hex value for float compare when test failed (#228)
[33m0dca080238[m remove useless internal schema file (#226)
[33m1d95c93987[m [optimization] avoid vector copy and reduce allocation. (#203)
[33m255ee39af6[m Fix memory leak by improper handling of std::string typed (#227)
[33me97caa7787[m change mkldnn so path (#210)
[33m84231ba003[m support hyperbolic ops (#223)
[33me63572c1f3[m Updated ArrayFeatureExtractor op to retain old output shape behavior.
[33m94f8f2b05c[m placeholder for internal contrib ops (#219)
[33mb9cc134576[m Make sure tensor sizes are 64-byte aligned (#222)
[33m4d010fb1ea[m Add null check before calling node.op_->Deprecated(). (#211)
[33mac3a081ec5[m Enable release build in Windows CI pipelines (#220)
[33m0248390e4d[m Add support for checking for F16C support (https://en.wikipedia.org/wiki/F16C). (#212)
[33mab350fa4c7[m Re-structure the inference session initialization to (#217)
[33m334e329642[m Increment/decrement UseCount for outputs so that we don't prematurely free a re-used output that is used for a dead output (output with zero users). (#214)
[33m39f47f86ee[m Adding the include folder for the C Windows pkg. (#198)
[33mbeb326f00e[m Simplify logic around creating relationship between nodes for implicit NodeArg usage. Allows using an initializer from multiple levels up to not fail. We would need to accumulate a list of initializers from all levels up otherwise, and doing so doesn't add any value. (#200)
[33mdc8b37f4c4[m update onnx (#209)
[33m37b74c771a[m add gemmlowp as submodule. (#206)
[33mc0ec7d56c4[m Clean up garbage files (#208)
[33md4131a31d9[m Disable csharp pretrained tests temporarily (#207)
[33m0aa1b54aaa[m Updated build.py to support relative CMake/CTest paths and did some minor cleanup. (#205)
[33m773114a4f1[m More C header naming changes (#202)
[33m0287019c1d[m C# Gpu : Minor updates to exception message (#201)
[33m71c56b6d7c[m Fix array feature extractor out of bounds access issue (#194)
[33m8c5d105557[m fix typo
[33mb0f27ba0a7[m Allow using MKLML header/libs when use_mklml is specified (#178)
[33md0544a8082[m Rashuai/gathernd op (#170)
[33m82d04412a0[m Kezhan/partition logic update (#164)
[33m5a8acd7da8[m directly updating dst arg with src arg when adding an edge. no need updating the type and shape info. (#195)
[33m5fd9024139[m [WIP] Initial checking for CSharp GPU support (#176)
[33mb418adff42[m Disable test data downloading by default (#193)
[33m383315a7e0[m Upgrade Eigen to 3.3.7 (#185)
[33m16b3a9fd63[m onnxruntime_CUDA_HOME should only be used when available.
[33m6cd935e184[m Duli/fusedconv (#183)
[33m7560538c94[m Revert "Adding missing attribute *alpha* to FusedConv schema." (#182)
[33m3f4e62a49c[m Adding missing attribute *alpha* to FusedConv schema.
[33m55a0527640[m Fix a warning in gcc 7
[33m11b369a864[m Abbreviate ONNXRuntime as Ort in all of our public APIs (#175)
[33m47551da994[m Optimize Tanh/Sigmoid activations (#162)
[33mafd831ae9e[m Remove unnecessary const
[33md6abc38182[m MurmurHash3 operator (#174)
[33mfb021b9002[m delete azure-pipelines.yml
[33m2ffaa8a185[m optimize unordered_map (#166)
[33m0aaaf4663d[m Update data download script (#171)
[33md419170c7b[m Rename ONNXRUNTIME_API_STATUSCALL to ONNXRUNTIME_API_CALL since it's â€¦ (#165)
[33mc5a0119d42[m Added Environment::IsInitialized() and added check to InferenceSession constructor. (#169)
[33m34175826df[m Ryanunderhill/pad fix (#151)
[33m1d32aa98f8[m add int16/uint16 in quantization for cntk quantized speech model. (#163)
[33m30ab01e7be[m Ryanunderhill/concat neg axis (#152)
[33mcfd3b4c606[m remove extra const (#159)
[33med98d3d653[m Add some nullptr checks (#160)
[33m618cc51754[m Update onnx_backend_test_series.py (#146)
[33mec71f363f7[m Fix a bug in parallel executor and enable test for it in CI (#157)
[33m1ed72251d0[m A tiny change to onnxruntime::Model (#158)
[33m9baaf5e956[m Kezhan/change edge api to use index (#138)
[33m2e79597531[m Revert "mkldnn Relu/Sum/BatchNormalization kernels" (#147)
[33m2230e5b431[m Conv+Activation fusion for CPU (#105)
[33m7f0e5269bd[m Removing from broken tests since this failure cannot be reproduced any more. (#154)
[33mf189b76f9a[m Some small edits and renaming. (#153)
[33m0ae9354db1[m Delete unused files in onnx_test_runner (#149)
[33m396e95bc4b[m Reduce whitespace at top of readme for easier reading (#148)
[33m60c6b9dfd0[m Kezhan/separate op def from kernels (#143)
[33me2a90ab747[m Add unique identifier in function subgraph node (#129)
[33m1beeccb89d[m Enable data cache (#144)
[33m8510ccdfe7[m Update performance_runner.cc (#142)
[33mb054646ddd[m Askhade/implement erf (#137)
[33m7d79bfef71[m Move isnan out of contrib_ops and add float16 support for it as per the spec. (#141)
[33m9bf78e1f3e[m Update BUILD.md (#140)
[33m7fb44b9d9e[m Add missing #include (#139)
[33mc5a691d67d[m update onnx to latest commit (#132)
[33m69a5ff3300[m Upsample opset 9 support for CPU provider (#135)
[33md71376010b[m Implement Dynamic Range Operator with shape inference
[33mbdd5e58546[m MKLDNN Sum and Batch Normalizaton kernels (#115)
[33m6bfb195184[m Jignparm/csharp test difftypes (#126)
[33m50ed36290c[m Use windows specific C-runtime based solution for lowercasing/uppercasing (#131)
[33med5abc8b94[m mkldnn conv 1d, 3d support. (#130)
[33ma09a3d3aa5[m Add build targets and props file for legacy csharp project support (#127)
[33m19c630b87f[m [TVM] Bugfix. (#117)
[33m23e122f304[m Run backward gru in main thread for bidirection (#118)
[33m6169f3c619[m First Draft EyeLike CPU OP9 (#121)
[33m5cec70df4b[m added the redirected URL to nuget package icon (#125)
[33mc5cbdd5a55[m Miscellaneous fixes (#123)
[33ma53d617b7a[m added the icon and logo resources (#124)
[33m9b9cb32f88[m Jignparm/csharp test difftypes (#122)
[33m830c341c19[m remove graph editor since it's not designed as expected to restrict graph access for rewrite rule. (#119)
[33m194d0a98d1[m Add domain and version check for ops fusion. (#108)
[33m3c7c1068e7[m refactor threading (#110)
[33m6d80253502[m mkldnn activations.relu (#86)
[33mc52636e187[m Implement Tokenizer op (#31)
[33ma68f5ccfd9[m Upgrade gpu build to CUDA 10 + cudnn 7.3 (#112)
[33m4801e67104[m Hecli/cuda10 upgrade (#111)
[33meea7618d53[m Ryanunderhill/c api (#85)
[33mdd1b16dd58[m add brainslice change in common folder (#109)
[33m3dcf344f09[m switch build agents to the CUDA 10 pool (#106)
[33m0573952499[m Update the documentation, run all examples during the generation of the documentation (replace #89) (#103)
[33meeb862ab1a[m Update Dockerfile for ARM build and the build instruction (#93)
[33mc8ae91251e[m Eliminate the confusing double negative (#92)
[33m358be0653c[m Delete logo as per marketing requirements (#98)
[33m996d6ea4cd[m Revert Softmax optimizations using openmp. (#97)
[33m7f0e947f96[m Add the split build badges (#96)
[33m3b08c6665a[m Split the CI pipelines (#94)
[33mfbb23a9ed0[m Implement StringNormalizer (#69)
[33m005f9dca96[m Kezhan/renaming graph_base.h to graph.h (#95)
[33ma78acb2d2c[m rename graph.h to graph_viewer.h (#84)
[33m980e8aa270[m Update BUILD.md (#90)
[33m744ec28c88[m (de)quantize_linear optimizations (#76)
[33m37385ec029[m Add Dockerfile and page for ARM builds. (#83)
[33m1e59b6f1c2[m Minor fixes to CI definitions (#80)
[33m47a6992e1b[m update mkldnn to 0.17.1 and address assumptions related to tensor padding that come with new mkldnn version. (#79)
[33m900e69ceae[m User lower case while comparing the activation method as it's not clear in the spec. (#77)
[33mf1c66a4aae[m Updated CSharp package description (#75)
[33m1c9d0b2729[m Add missing types for Slice op (#74)
[33maa549cd194[m Support fusing 3D Conv with Add/Mul. (#23)
[33mb7cc611563[m Minor documentation changes (#78)
[33m07253fd647[m Faxu patch 1 (#63)
[33m21dad1780b[m Add logo and link to C# pkg. (#73)
[33m28bb96be2a[m use std::copy to avoid gsl::span overhead (#71)
[33mfd0d7c5fc0[m Add the mac python packaging script (#72)
[33m31780cae32[m Add NonMaxSupression op to contribution ops (#60)
[33m6624dd2778[m Rel 0.1.5 (#70)
[33m21044846ee[m use #pragma parallel for properly (#68)
[33mc55663860e[m fixed metadata element -- use PackageProjectUrl instead of ProjectUrl (#67)
[33mb534f9fa5f[m Square and Cube optimization for Pow<float>() operator. (#30)
[33mbcc8f621ea[m updated nuget package metadata for MS compliance (#66)
[33medbe19d22f[m Include output name with mismatch error message so it's clearer where the failure comes from. (#65)
[33m9b1bc06c34[m Merge pull request #64 from Microsoft/kezhan/remove_const_cast
[33me9de9abc96[m update
[33mfbd7b9b8f0[m Merge branch 'master' of https://github.com/Microsoft/onnxruntime into kezhan/remove_const_cast
[33m56811d10af[m remove const cast in transformer_memcpy
[33me00c956254[m update the comments.
[33m39ebccbc8b[m Fix sample example documentation for python pkg (#61)
[33mafe3fb5c1d[m Merge branch 'master' of https://github.com/Microsoft/onnxruntime into kezhan/remove_const_cast
[33m35f94cac27[m remove const cast from conv related fusion.
[33m1ea32a097a[m Update pythin bindings for options (#14)
[33m728c3c078e[m Update issue templates (#62)
[33mcd1042c94f[m Merge pull request #36 from Microsoft/zhalei/softmax_optimize
[33mfafc48bf94[m Merge pull request #59 from Microsoft/kezhan/qlinearmatmul
[33m91c860bec4[m fix description
[33m34aa545b64[m add QLinearMatMul
[33me8db06ed44[m[33m ([m[1;33mtag: v0.1.4[m[33m, [m[1;31morigin/rel-0.1.4[m[33m)[m Merge pull request #32 from Microsoft/kezhan/op_spec_fix
[33m7780fd6cd9[m fix bug -- failing on non float tensor output types (#58)
[33m8980cbbfad[m Merge pull request #52 from Microsoft/scmckay/UpdateCudaInfoInBuildMd
[33ma4bcb1121b[m Merge pull request #57 from Microsoft/scmckay/FixInferenceSessionInputValidationHandlingOfOptionalInputs
[33m97dc949e3f[m Fix some more C# unit test issues. Ignore bin and obj directories under /csharp
[33mf3fb1d5ff8[m Merge remote-tracking branch 'origin/master' into scmckay/FixInferenceSessionInputValidationHandlingOfOptionalInputs
[33m2486336355[m Update error messages C# tests check for.
[33md263d6734e[m Adjust test. valid input names aren't deterministically ordered in error message.
[33m4dd1e50aa7[m Merge remote-tracking branch 'origin/master' into scmckay/UpdateCudaInfoInBuildMd
[33mca86d8f17c[m Merge pull request #55 from Microsoft/jywu/incr_fixup
[33mea1ad0aaf5[m Merge remote-tracking branch 'origin/master' into scmckay/FixInferenceSessionInputValidationHandlingOfOptionalInputs
[33m989b00321e[m Update session state initializer to support overriding initializers. Update test
[33m3feeb9de3e[m Merge branch 'master' of https://github.com/Microsoft/onnxruntime into jywu/incr_fixup
[33m846044e282[m [Mac] support mkldnn for macOS (#56)
[33m7523e76649[m Minor wording changes to design doc (#51)
[33m6371025860[m Add flag for mac compliance (#45)
[33md60507d2e9[m [Mac] fix python binding (#54)
[33m91f1866b64[m Only check for 'bin' folder in cudnn path on windows.
[33mbfaade660b[m Initial changes. Optional inputs aren't being handled properly in SaveInputOutputNamesToNodeMapping
[33m6179ddb2a1[m fix for possible incremental build breaks.
[33mcb1781927f[m Remove mklml in Linux python wheel packagaing (#53)
[33m21cabe3ead[m Merge pull request #35 from Microsoft/zhalei/reduce_mean_optimize
[33m2f61926390[m Update build.md section on CUDA builds to clarify and add CUDA 10.0 info. Add --msvc_toolset param to build.py Tweak CMakeLists.txt to set the CUDA toolset path from onnxruntime_CUDA_HOME.
[33m2f234e4e78[m Minor fixes to nuget README.md file (#49)
[33m564907fa1a[m remove the non ascii char (#48)
[33m16ef49c51b[m Merge pull request #47 from Microsoft/dev/shahasad/some-cosmetic-fixes-in-the-build-script
[33m0540d8e5f7[m Better name for read.
[33m7cb3dfc18a[m Optimize ReduceMean/ReduceSum when all reduce axises located at the tail of the input tensor's dims by do not make extra copy. And use openmp to parallel the reduce on results.
[33m6f65a03939[m some cleanup
[33mc1613aa28e[m Fixes in the NuGet package meatada. Include sourcelink
[33m17b72b2e7d[m Merge pull request #46 from Microsoft/tracysh/mergemaster
[33m39fc17281c[m merge from internal master
[33m6b00e6bb4d[m Simpler unused parameter in #if defined() switch.
[33mc530064ebe[m Better opemmp parallel group count calculation in Softmax parallel running.
[33mbd50598d17[m Document the Graph header files and cleanup some issues. (#42)
[33m4fbd345732[m Merge pull request #44 from Microsoft/fix_codeowners_file
[33m75d329d845[m Merge pull request #25 from Microsoft/dev/shahasad/merge-latest-few-changes-on-csharp-api
[33m6e2a1ceb41[m merged from master
[33mbe1be9fa94[m explicitly specify outputpath in the test project
[33mf638031f02[m make test explicitly anyCPU
[33m1a03f44938[m make the test project explicitly x64 platform to get working
[33m6038ba21fd[m Fix codeowners file
[33m1b3efc36c1[m Add pipeline for building python wheels (#41)
[33m3f4589ced5[m Add remaining build options and make minor changes in documentation (#39)
[33m29f9e89226[m merged the latest csharp folder changes from VSTS repo @313681f9
[33md7d43bc13f[m merged from master
[33m3b1140954e[m Bug bash (#43)
[33ma9b52f399d[m Add pre-release notice to c_api (#38)
[33mc07b4aff5e[m Merge pull request #37 from Microsoft/ryanunderhill/hide_leak
[33m047ca7e57e[m Merge branch 'master' into ryanunderhill/hide_leak
[33mdf1d01f853[m Update CI configs to test mkldnn
[33mdcd4e0cb8f[m Change debug_alloc to not exit(-1) on the command line so that our build tests pass
[33m9c4020678c[m Merge pull request #21 from Microsoft/duli/shape_inference
[33m725a262ceb[m Merge branch 'duli/shape_inference' of github.com:Microsoft/onnxruntime into duli/shape_inference
[33me75bde2e97[m Accomodating PR comments.
[33me7bdfa00db[m Optimize softmax cpu by parallel using openmp.
[33m408fd21a7f[m Windows CI: enable pybind (#34)
[33m4fe7045214[m Faxu documentation (#16)
[33mab4d4e1ae0[m fix  output type specification for ConvInteger
[33m0bb5cb7a30[m Accomodating PR comments.
[33m573a9aba3c[m Merge pull request #29 from Microsoft/RyanUnderhill-patch-1
[33m6982325b29[m Merge pull request #22 from Microsoft/scmckay/SupportUnknownDimensionInScanSubgraphOutputs
[33m3ccb0876fd[m Merge
[33m3761d2d718[m Update C_API.md
[33m194cc1539c[m Merge pull request #24 from Microsoft/scmckay/Scan_SupportScalarInputs
[33m930145f2d2[m add mkldnn and openmp on windows CI build. C# package binary includes mkldnn
[33m84fa1018a3[m Create CODEOWNERS (#27)
[33mb9dc153106[m Merge pull request #20 from linkerzhang/kezhan/quantize_ops
[33me477e7563b[m typo in last commit
[33m4f0ec77f6e[m Merge branch 'dev/shahasad/enable-dll-and-csharp-in-windows-ci-build' into dev/shahasad/merge-latest-few-changes-on-csharp-api
[33m33537055cb[m make mkldnn.dll optional
[33md8cf3f0e33[m enabled shared-lib and csharp build in windows CI
[33mba6123db57[m fix the exceptions
[33m41e1ed8e01[m added the CSHarp doc
[33mf454826b93[m updated the files with the latest ones from Lotus VSTS repo
[33meef4db37f3[m Fix a couple of warnings from the linux and VC 14.11 toolset builds
[33m03d7d25989[m Support scalars (zero dimensions) in Scan by allowing the parameters to Scan to have no dimension for the input data.
[33m720aca581a[m Update comments
[33meef36d2fbf[m Update some comments
[33me7e801b45e[m Adding shaper inference for Op expand_dims
[33m5d3992f999[m Handle the Scan subgraph producing outputs with a symbolic dimension.
[33mc7513e676f[m Merge pull request #19 from Microsoft/fix_build_status_badge
[33ma82a0907e0[m add ops for quantization support.
[33md35bea7455[m Fix build status badge.
[33mfaa06d3516[m Merge pull request #17 from Microsoft/scmckay/AllowForOptionalInputsInSessionPy
[33macf9aea4aa[m Merge pull request #13 from Microsoft/chasun/p1
[33mb3c5da5b97[m Merge pull request #18 from Microsoft/sync_internal_master
[33m7aef8a1cca[m Sync with internal master.
[33m0ee3ad32d2[m Allow for optional graph inputs in InferenceSession.run
[33mba470c2180[m Merge pull request #12 from Microsoft/update_onnx_commit
[33mf4ea04870e[m delete extra code in onnxruntime_unittests.cmake
[33m9fbcb7fa51[m Update onnx to commit to pickup shape inference fix for broadcast, concat and scan
[33m35b43cfebc[m Merge pull request #10 from Microsoft/hecli/cuda9.1
[33md2a8b0e65b[m update the cuda cudnn version information
[33mc2d5b7e368[m update linux gpu to use cuda 9.1 + cudnn 7.1.2
[33m8f716cb4fc[m Switch GPU build to use CUDA 9.1 + cudnn 7.0.5
[33m0f96064e70[m Merge pull request #9 from Microsoft/mac-ci
[33m53ce3e7b55[m Enable Mac pipeline
[33m89618e8f1e[m Initial bootstrap commit.
